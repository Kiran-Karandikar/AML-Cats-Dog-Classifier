<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>8f7abd9514d045a79ad58674ee56be8f</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="project-abstract" class="cell markdown" id="BdJvxZJOKqIv">
<h2>Project Abstract</h2>
<p>Cats’ vs dogs object detection is one of the projects which can be done under computer vision. The main motto of this data set is to process the images of cats and dogs and predict their labels as cat or dog using few machine learning functional metrics (RMSE and MSE). These types of object detection problems come under computer vision. In this phase we will try to classify the images to predict whether it is cat or dog. Humans can easily say that the given image is a cat or a dog but for a machine it is difficult to predict it. This data set was firstly used in a Kaggle competition held in 2013. There are about 13,000 images of varying shapes and aspect ratios. They are all RGB pictures and have bounding box organizes put away in a .csv record. For this object classification and detection, we will be using convolution Neural Network (CNN) and using machine learning algorithms we will be able to classify these images for achieving this we will be using logistic regression to classify the images on top of that we will be implementing stochastic gradient descent and an adaptive learning rate. As we are using bounding boxes, the best way to predict bounding boxes is to use linear regression and again on top of that we will use gradient descent. We will be using SKLearn’s and Pytorch models to implement all the above functionalities.</p>
</section>
<section id="project-description" class="cell markdown" id="ZbU8NYezKqIv">
<h2>Project Description</h2>
<p>The goal of this project is to create object identification pipelines for cats and dogs images using Python, OpenCV, SKLearn, and PyTorch. We import image catalog data, run exploratory data analysis on it, and derive metrics and baseline models from it. To make a detector, we'll need to preprocess the pictures so that they're all of the same form, then take their RGB intensity values and flatten them to from a 3D array to a 2D array. Then predict labels and bounding boxes, we'll pass this array through a linear classifier and a linear regressor.Build an image classification SKLearn model and a regression SKLearn model. Create a Logistic Regression model from scratch and extend the CXE loss function to CXE + MSE. Create a PyTorch baseline pipeline for object classification and localization.</p>
<p>Build a specific object classifier and detector using a convolutional neural network network.</p>
</section>
<section id="data-description--analysis" class="cell markdown" id="fotTwx6uKqIv">
<h3>Data Description &amp; Analysis</h3>
<p>###Cats vs Dogs Detector (CaDoD)</p>
<p><strong>Traning Data</strong> - This contains about images of cats and dogs in jpg format. The images are of various resolution and are RGB scale.</p>
<p><strong>Test Data</strong> - Test data contains images of cats and dogs.</p>
<p>####Data preprocessing</p>
<ul>
<li>The data has to be rescaled to a specific aspect ratio.</li>
<li>Shuffling the train set can be benificial option.</li>
<li>Rescaled training data is saved for easy load in the future.</li>
</ul>
<p>The image archive <code>cadod.tar.gz</code> is a subset <a href="https://storage.googleapis.com/openimages/web/download.html">Open Images V6</a>. It contains a total of 12,966 images of dogs and cats.</p>
<p>Image bounding boxes are stored in the csv file <code>cadod.csv</code>. The following describes whats contained inside the csv.</p>
<ul>
<li>ImageID: the image this box lives in.</li>
<li>Source: indicates how the box was made:
<ul>
<li>xclick are manually drawn boxes using the method presented in [1], were the annotators click on the four extreme points of the object. In V6 we release the actual 4 extreme points for all xclick boxes in train (13M), see below.</li>
<li>activemil are boxes produced using an enhanced version of the method [2]. These are human verified to be accurate at IoU&gt;0.7.</li>
</ul></li>
<li>LabelName: the MID of the object class this box belongs to.</li>
<li>Confidence: a dummy value, always 1.</li>
<li>XMin, XMax, YMin, YMax: coordinates of the box, in normalized image coordinates. XMin is in [0,1], where 0 is the leftmost pixel, and 1 is the rightmost pixel in the image. Y coordinates go from the top pixel (0) to the bottom pixel (1).</li>
<li>XClick1X, XClick2X, XClick3X, XClick4X, XClick1Y, XClick2Y, XClick3Y, XClick4Y: normalized image coordinates (as XMin, etc.) of the four extreme points of the object that produced the box using [1] in the case of xclick boxes. Dummy values of -1 in the case of activemil boxes.</li>
</ul>
<p>The attributes have the following definitions:</p>
<ul>
<li>IsOccluded: Indicates that the object is occluded by another object in the image.</li>
<li>IsTruncated: Indicates that the object extends beyond the boundary of the image.</li>
<li>IsGroupOf: Indicates that the box spans a group of objects (e.g., a bed of flowers or a crowd of people). We asked annotators to use this tag for cases with more than 5 instances which are heavily occluding each other and are physically touching.</li>
<li>IsDepiction: Indicates that the object is a depiction (e.g., a cartoon or drawing of the object, not a real physical instance).</li>
<li>IsInside: Indicates a picture taken from the inside of the object (e.g., a car interior or inside of a building). For each of them, value 1 indicates present, 0 not present, and -1 unknown.</li>
</ul>
</section>
<div class="cell code" data-execution_count="1" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="g51Nn2hiKqIv" data-outputId="a68b604b-14e6-4b75-9b7d-4f79a3eee9d1">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.image <span class="im">as</span> mpimg</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.exceptions <span class="im">import</span> ConvergenceWarning</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier, SGDRegressor</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, mean_squared_error, roc_auc_score</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tarfile</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive,files</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">&#39;/content/gdrive&#39;</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Google collab dir: Account: kikarand@iu.edu</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>DATA_DIR<span class="op">=</span><span class="st">&quot;gdrive/MyDrive/data/&quot;</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>extract_path <span class="op">=</span> <span class="st">&#39;images/&#39;</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>image_file_name <span class="op">=</span> <span class="st">&#39;cadod.tar.gz&#39;</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>bounding_box_file_name <span class="op">=</span> <span class="st">&#39;cadod.csv&#39;</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> os.path.join(DATA_DIR, image_file_name)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>bounding_box_path <span class="op">=</span> os.path.join(DATA_DIR, bounding_box_file_name)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mounted at /content/gdrive
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="2" id="4cR4zJlub3zC">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>extract_path <span class="op">=</span> <span class="st">&#39;images/&#39;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>image_file_name <span class="op">=</span> <span class="st">&#39;cadod.tar.gz&#39;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>bounding_box_file_name <span class="op">=</span> <span class="st">&#39;cadod.csv&#39;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> os.path.join(DATA_DIR, image_file_name)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>bounding_box_path <span class="op">=</span> os.path.join(DATA_DIR, bounding_box_file_name)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>resize_path <span class="op">=</span> os.path.join(extract_path, <span class="st">&quot;resized&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3" id="l8K2yNqkb4wi">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p $resize_path</span></code></pre></div>
</div>
<section id="import-data" class="cell markdown" id="xzBxhYtlKqIv">
<h1>Import Data</h1>
</section>
<section id="unarchive-data" class="cell markdown" id="2nYG7CZAKqIv">
<h3>Unarchive data</h3>
</section>
<div class="cell code" data-execution_count="4" id="i8Wiyjp_KqIv">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_tar(<span class="bu">file</span>, path):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">    function to extract tar.gz files to specified location</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">        file (str): path where the file is located</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">        path (str): path where you want to extract</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> tarfile.<span class="bu">open</span>(<span class="bu">file</span>) <span class="im">as</span> tar:</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        files_extracted <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> member <span class="kw">in</span> tqdm(tar.getmembers()):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> os.path.isfile(path <span class="op">+</span> member.name[<span class="dv">1</span>:]):</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>                tar.extract(member, path)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>                files_extracted <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        tar.close()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> files_extracted <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Files already exist&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="5" data-colab="{&quot;height&quot;:49,&quot;referenced_widgets&quot;:[&quot;267ae04c024d4562975ac43a4db60996&quot;,&quot;89cb8d1c6bdf42b59fb5e8bdb64e04c3&quot;,&quot;8881160212ac4feb93861895573df84b&quot;,&quot;15555c8f0a9e4db6a2f7732e409417cd&quot;,&quot;ea748b2167a2416baf1e367aa8e7b30a&quot;,&quot;c5c3a4ad66c64416b8c67893ebb8944a&quot;,&quot;4fd32fcfa0b44d87854c079ef68108bc&quot;,&quot;7cf38a0678f8400b9c4b7c6a0dd72e0e&quot;,&quot;fe30737a3c1542bc9a302c7486e9c4a3&quot;,&quot;434975fa2451452c8495277ee139b2f9&quot;,&quot;152c5d1dbb43450bbc135eff020af24e&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="GZu1vXurKqIv" data-outputId="1a15be8b-8334-4b6d-9cde-ab7a88e1bd80">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>extract_tar(image_path, extract_path)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb7"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;267ae04c024d4562975ac43a4db60996&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="load-bounding-box-meta-data" class="cell markdown" id="5qlEn0eCKqIw">
<h3>Load bounding box meta data</h3>
</section>
<div class="cell code" data-execution_count="6" id="ymxqFlviKqIw">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(bounding_box_path)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="7" data-colab="{&quot;height&quot;:299,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="lTpXPcJ5KqIw" data-outputId="3bcfc4d7-875a-4e59-8aaf-fe8a0590e1b8">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="7">

  <div id="df-52932fa0-3235-4bb3-882e-f56a93aba307">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ImageID</th>
      <th>Source</th>
      <th>LabelName</th>
      <th>Confidence</th>
      <th>XMin</th>
      <th>XMax</th>
      <th>YMin</th>
      <th>YMax</th>
      <th>IsOccluded</th>
      <th>IsTruncated</th>
      <th>...</th>
      <th>IsDepiction</th>
      <th>IsInside</th>
      <th>XClick1X</th>
      <th>XClick2X</th>
      <th>XClick3X</th>
      <th>XClick4X</th>
      <th>XClick1Y</th>
      <th>XClick2Y</th>
      <th>XClick3Y</th>
      <th>XClick4Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0000b9fcba019d36</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.165000</td>
      <td>0.903750</td>
      <td>0.268333</td>
      <td>0.998333</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.636250</td>
      <td>0.903750</td>
      <td>0.748750</td>
      <td>0.165000</td>
      <td>0.268333</td>
      <td>0.506667</td>
      <td>0.998333</td>
      <td>0.661667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0000cb13febe0138</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.000000</td>
      <td>0.651875</td>
      <td>0.000000</td>
      <td>0.999062</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.312500</td>
      <td>0.000000</td>
      <td>0.317500</td>
      <td>0.651875</td>
      <td>0.000000</td>
      <td>0.410882</td>
      <td>0.999062</td>
      <td>0.999062</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0005a9520eb22c19</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.094167</td>
      <td>0.611667</td>
      <td>0.055626</td>
      <td>0.998736</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.487500</td>
      <td>0.611667</td>
      <td>0.243333</td>
      <td>0.094167</td>
      <td>0.055626</td>
      <td>0.226296</td>
      <td>0.998736</td>
      <td>0.305942</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0006303f02219b07</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.000000</td>
      <td>0.999219</td>
      <td>0.000000</td>
      <td>0.998824</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.508594</td>
      <td>0.999219</td>
      <td>0.000000</td>
      <td>0.478906</td>
      <td>0.000000</td>
      <td>0.375294</td>
      <td>0.720000</td>
      <td>0.998824</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00064d23bf997652</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.240938</td>
      <td>0.906183</td>
      <td>0.000000</td>
      <td>0.694286</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.678038</td>
      <td>0.906183</td>
      <td>0.240938</td>
      <td>0.522388</td>
      <td>0.000000</td>
      <td>0.370000</td>
      <td>0.424286</td>
      <td>0.694286</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-52932fa0-3235-4bb3-882e-f56a93aba307')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-52932fa0-3235-4bb3-882e-f56a93aba307 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-52932fa0-3235-4bb3-882e-f56a93aba307');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<section id="phase-1" class="cell markdown" id="KMSrY72Kdo0d">
<h1><strong><em>Phase 1</em></strong></h1>
</section>
<section id="exploratory-data-analysis" class="cell markdown" id="wXKyhM8UKqIw">
<h1>Exploratory Data Analysis</h1>
</section>
<section id="statistics" class="cell markdown" id="J-xnieyzKqIw">
<h2>Statistics</h2>
</section>
<div class="cell code" data-execution_count="12" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="KwJIA9VzKqIw" data-outputId="5375f112-7ac8-44ce-b9a5-5b09deb46ef9">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;There are a total of </span><span class="sc">{</span><span class="bu">len</span>(glob.glob1(extract_path, <span class="st">&#39;*.jpg&#39;</span>))<span class="sc">}</span><span class="ss"> images&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>There are a total of 12966 images
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="13" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="9qkXCriaKqIw" data-outputId="826963b5-c812-4fa9-bd21-d9049bc787e9">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;The total size is </span><span class="sc">{os.</span>path<span class="sc">.</span>getsize(extract_path)<span class="op">/</span><span class="dv">1000</span><span class="sc">}</span><span class="ss"> MB&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The total size is 1105.92 MB
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="14" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="hYun4h7BKqIw" data-outputId="ab68cddb-18e1-4e62-dab3-245b9b71a7a5">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="14">
<pre><code>(12966, 21)</code></pre>
</div>
</div>
<div class="cell markdown" id="qFTDI0VDKqIw">
<p>Replace <code>LabelName</code> with human readable labels</p>
</div>
<div class="cell code" data-execution_count="15" id="Y6h99f0IKqIw">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df.LabelName.replace({<span class="st">&#39;/m/01yrx&#39;</span>:<span class="st">&#39;cat&#39;</span>, <span class="st">&#39;/m/0bt9lr&#39;</span>:<span class="st">&#39;dog&#39;</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="16" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="gledr531KqIw" data-outputId="6995a775-b2ba-4c4b-8040-74baa521eceb">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df.LabelName.value_counts()</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<pre><code>dog    6855
cat    6111
Name: LabelName, dtype: int64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17" data-colab="{&quot;height&quot;:290,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="fqVuuodiKqIw" data-outputId="6921e354-4b93-4237-93c0-bd7d5a2fd717">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df.LabelName.value_counts().plot(kind<span class="op">=</span><span class="st">&#39;bar&#39;</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Image Class Count&#39;</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_1.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="18" data-colab="{&quot;height&quot;:364,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="3YQ1tYdeKqIw" data-outputId="12cf915f-842e-4b01-c4ab-61cd0e435e6a">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="18">

  <div id="df-2257af45-abf2-4225-8cc6-c2f4c51b8d54">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Confidence</th>
      <th>XMin</th>
      <th>XMax</th>
      <th>YMin</th>
      <th>YMax</th>
      <th>IsOccluded</th>
      <th>IsTruncated</th>
      <th>IsGroupOf</th>
      <th>IsDepiction</th>
      <th>IsInside</th>
      <th>XClick1X</th>
      <th>XClick2X</th>
      <th>XClick3X</th>
      <th>XClick4X</th>
      <th>XClick1Y</th>
      <th>XClick2Y</th>
      <th>XClick3Y</th>
      <th>XClick4Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>12966.0</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
      <td>12966.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.0</td>
      <td>0.099437</td>
      <td>0.901750</td>
      <td>0.088877</td>
      <td>0.945022</td>
      <td>0.464754</td>
      <td>0.738470</td>
      <td>0.013651</td>
      <td>0.045427</td>
      <td>0.001157</td>
      <td>0.390356</td>
      <td>0.424582</td>
      <td>0.494143</td>
      <td>0.506689</td>
      <td>0.275434</td>
      <td>0.447448</td>
      <td>0.641749</td>
      <td>0.582910</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.0</td>
      <td>0.113023</td>
      <td>0.111468</td>
      <td>0.097345</td>
      <td>0.081500</td>
      <td>0.499239</td>
      <td>0.440011</td>
      <td>0.118019</td>
      <td>0.209354</td>
      <td>0.040229</td>
      <td>0.358313</td>
      <td>0.441751</td>
      <td>0.405033</td>
      <td>0.462281</td>
      <td>0.415511</td>
      <td>0.401580</td>
      <td>0.448054</td>
      <td>0.403454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.408125</td>
      <td>0.000000</td>
      <td>0.451389</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.830625</td>
      <td>0.000000</td>
      <td>0.910000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.221292</td>
      <td>0.096875</td>
      <td>0.285071</td>
      <td>0.130000</td>
      <td>0.024323</td>
      <td>0.218333</td>
      <td>0.405816</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.0</td>
      <td>0.061250</td>
      <td>0.941682</td>
      <td>0.059695</td>
      <td>0.996875</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.435625</td>
      <td>0.415625</td>
      <td>0.531919</td>
      <td>0.623437</td>
      <td>0.146319</td>
      <td>0.480838</td>
      <td>0.825000</td>
      <td>0.646667</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.0</td>
      <td>0.167500</td>
      <td>0.998889</td>
      <td>0.144853</td>
      <td>0.999062</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.609995</td>
      <td>0.820000</td>
      <td>0.787500</td>
      <td>0.917529</td>
      <td>0.561323</td>
      <td>0.729069</td>
      <td>0.998042</td>
      <td>0.882500</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.0</td>
      <td>0.592500</td>
      <td>1.000000</td>
      <td>0.587088</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.999375</td>
      <td>0.999375</td>
      <td>1.000000</td>
      <td>0.999375</td>
      <td>0.999375</td>
      <td>0.999375</td>
      <td>1.000000</td>
      <td>0.999375</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-2257af45-abf2-4225-8cc6-c2f4c51b8d54')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-2257af45-abf2-4225-8cc6-c2f4c51b8d54 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-2257af45-abf2-4225-8cc6-c2f4c51b8d54');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<section id="sample-of-images" class="cell markdown" id="lZQIgpr4KqIx">
<h2>Sample of Images</h2>
</section>
<div class="cell code" data-execution_count="19" data-colab="{&quot;height&quot;:682,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="EfuFMCZxKqIx" data-outputId="5631dff5-8f55-46df-e2e9-ece1b3468e58">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot random 6 images</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">3</span>, sharex<span class="op">=</span><span class="va">False</span>, sharey<span class="op">=</span><span class="va">False</span>,figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax.flatten()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,j <span class="kw">in</span> <span class="bu">enumerate</span>(np.random.choice(df.shape[<span class="dv">0</span>], size<span class="op">=</span><span class="dv">6</span>, replace<span class="op">=</span><span class="va">False</span>)):</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> mpimg.imread(extract_path <span class="op">+</span> df.ImageID.values[j] <span class="op">+</span> <span class="st">&#39;.jpg&#39;</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    h, w <span class="op">=</span> img.shape[:<span class="dv">2</span>]</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    coords <span class="op">=</span> df.iloc[j,<span class="dv">4</span>:<span class="dv">8</span>]</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(img)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    ax[i].set_title(df.LabelName[j])</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    ax[i].add_patch(plt.Rectangle((coords[<span class="dv">0</span>]<span class="op">*</span>w, coords[<span class="dv">2</span>]<span class="op">*</span>h), </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>                                  coords[<span class="dv">1</span>]<span class="op">*</span>w<span class="op">-</span>coords[<span class="dv">0</span>]<span class="op">*</span>w, coords[<span class="dv">3</span>]<span class="op">*</span>h<span class="op">-</span>coords[<span class="dv">2</span>]<span class="op">*</span>h, </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>                                  edgecolor<span class="op">=</span><span class="st">&#39;red&#39;</span>, facecolor<span class="op">=</span><span class="st">&#39;none&#39;</span>))</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_2.png" /></p>
</div>
</div>
<section id="image-shapes-and-sizes" class="cell markdown" id="U2h2mz57KqIx">
<h2>Image shapes and sizes</h2>
</section>
<div class="cell markdown" id="BHMe4upKKqIx">
<p>Go through all images and record the shape of the image in pixels and the memory size</p>
</div>
<div class="cell code" data-execution_count="20" data-colab="{&quot;height&quot;:49,&quot;referenced_widgets&quot;:[&quot;e9a11205b96a481fb174a144be15a7c1&quot;,&quot;ab02c3ff94684288bb7d657761773a55&quot;,&quot;9480498f85624f9a8849f0d4be99d36c&quot;,&quot;a77d0c1a530f4e36b0c8dc18645e48fc&quot;,&quot;a8f1749f9ecd430f8ee0c97de8899dad&quot;,&quot;7b05b61419784e0e86f61162c99285e8&quot;,&quot;395eb3091c9b4873af1047b29a2169c1&quot;,&quot;9b34d7198f3441b69df2b5bdf7b4b066&quot;,&quot;ebec5a69f7254744bfb78f138d3b5b9b&quot;,&quot;798b47059f4f424d9d872ee43022a0be&quot;,&quot;c0bd268d656a47589c8178f96daf1994&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="UKAAFJO5KqIx" data-outputId="da066891-da60-4d39-c967-e1b7deee25ba">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>img_shape <span class="op">=</span> []</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> np.zeros((df.shape[<span class="dv">0</span>], <span class="dv">1</span>))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,f <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(glob.glob1(extract_path, <span class="st">&#39;*.jpg&#39;</span>))):</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">file</span> <span class="op">=</span> extract_path<span class="op">+</span><span class="st">&#39;/&#39;</span><span class="op">+</span>f</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="bu">file</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    img_shape.append(<span class="ss">f&quot;</span><span class="sc">{</span>img<span class="sc">.</span>size[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">x</span><span class="sc">{</span>img<span class="sc">.</span>size[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    img_size[i] <span class="op">+=</span> os.path.getsize(<span class="bu">file</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb23"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e9a11205b96a481fb174a144be15a7c1&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell markdown" id="qr2S2dc5KqIx">
<p>Count all the different image shapes</p>
</div>
<div class="cell code" data-execution_count="21" id="IRXhcBpeKqIx">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>img_shape_count <span class="op">=</span> Counter(img_shape)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="22" id="0ZNoo-KHKqIx">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a dataframe for image shapes</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>img_df <span class="op">=</span> pd.DataFrame(<span class="bu">set</span>(img_shape_count.items()), columns<span class="op">=</span>[<span class="st">&#39;img_shape&#39;</span>,<span class="st">&#39;img_count&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="23" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="--duAh4QKqIx" data-outputId="d23ed825-a5b8-4ca4-b17b-a3066c57be08">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>img_df.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="23">
<pre><code>(594, 2)</code></pre>
</div>
</div>
<div class="cell markdown" id="u2aW_Og6KqIx">
<p>There are a ton of different image shapes. Let's narrow this down by getting a sum of any image shape that has a cout less than 100 and put that in a category called <code>other</code></p>
</div>
<div class="cell code" data-execution_count="24" id="AY4rMz8BKqIx">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>img_df <span class="op">=</span> img_df.append({<span class="st">&#39;img_shape&#39;</span>: <span class="st">&#39;other&#39;</span>,<span class="st">&#39;img_count&#39;</span>: img_df[img_df.img_count <span class="op">&lt;</span> <span class="dv">100</span>].img_count.<span class="bu">sum</span>()}, </span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>                       ignore_index<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="c9MrBPnpKqIx">
<p>Drop all image shapes</p>
</div>
<div class="cell code" data-execution_count="25" id="734FWg_-KqIx">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>img_df <span class="op">=</span> img_df[img_df.img_count <span class="op">&gt;=</span> <span class="dv">100</span>]</span></code></pre></div>
</div>
<div class="cell markdown" id="Ef0krmACKqIx">
<p>Check if the count sum matches the number of images</p>
</div>
<div class="cell code" data-execution_count="26" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="RKmzEAeXKqIx" data-outputId="1c10ba39-8c1f-4562-eec4-f15f37e2ca8b">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>img_df.img_count.<span class="bu">sum</span>() <span class="op">==</span> df.shape[<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="26">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell markdown" id="zmjcmC_dKqIx">
<p>Plot</p>
<h2 id="todo-plot-aspect-ratio">TODO plot aspect ratio</h2>
</div>
<div class="cell code" data-execution_count="27" data-colab="{&quot;height&quot;:499,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Y2IlLcUlKqIx" data-outputId="1ec9ee1e-0df4-4b0a-9a9e-88474f6f0944">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>img_df.sort_values(<span class="st">&#39;img_count&#39;</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>img_df.plot(x<span class="op">=</span><span class="st">&#39;img_shape&#39;</span>, y<span class="op">=</span><span class="st">&#39;img_count&#39;</span>, kind<span class="op">=</span><span class="st">&#39;barh&#39;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>), legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Image Shape Counts&#39;</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_3.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="28" id="7mUlTd5sKqIx">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to megabytes</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>img_size <span class="op">=</span> img_size <span class="op">/</span> <span class="dv">1000</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="29" data-colab="{&quot;height&quot;:370,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="T7zSxLyVKqIx" data-outputId="573be693-b7cc-48fc-912a-5d91026bbe80">
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">5</span>))</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">&#39;Image Size Distribution&#39;</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].hist(img_size, bins<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">&#39;Histogram&#39;</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;Image Size (MB)&#39;</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].boxplot(img_size, vert<span class="op">=</span><span class="va">False</span>, widths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">&#39;Boxplot&#39;</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;Image Size (MB)&#39;</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;Images&#39;</span>)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_4.png" /></p>
</div>
</div>
<section id="preprocess" class="cell markdown" id="PTTZ4sCoKqIx">
<h1>Preprocess</h1>
</section>
<section id="rescale-the-images" class="cell markdown" id="oFsCU74pKqIx">
<h2>Rescale the images</h2>
</section>
<div class="cell code" data-execution_count="30" id="L6TvNcb4csn_">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>files <span class="op">=</span> glob.glob(<span class="ss">f&#39;</span><span class="sc">{</span>resize_path<span class="sc">}</span><span class="ss">/*&#39;</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> files:</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    os.remove(f)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="31" data-colab="{&quot;height&quot;:84,&quot;referenced_widgets&quot;:[&quot;7a35ffbc0bd04c04963d37e67016b505&quot;,&quot;f8f6fb5733e84e0daae6124206a29ca5&quot;,&quot;4bd9ca23e93a4ad48499ea10fe0fc1bf&quot;,&quot;033ff8ebecd046a08a8816ab683445bd&quot;,&quot;4c709cad17204f4599d0dd39690abc3a&quot;,&quot;fc8c9d7afa71455e91638e9c358ee295&quot;,&quot;a2ef1f6327944fb3b83c545db66098cb&quot;,&quot;599e1b5b91f9404e9516a78a5b5a1ac3&quot;,&quot;82e0ef79ee454b29b81cd145f620ddc3&quot;,&quot;074320ba1f9f406d8522fd8e7733f101&quot;,&quot;9b5a5f6221554c0f834b79b153bacd8f&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="IaOsqiCvKqIx" data-outputId="89ebdfc2-4c21-4b2f-b9ce-c2bd0bfc7248">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># resize image and save, convert to numpy</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>img_arr <span class="op">=</span> np.zeros((df.shape[<span class="dv">0</span>],<span class="dv">32</span><span class="op">*</span><span class="dv">32</span><span class="op">*</span><span class="dv">3</span>)) <span class="co"># initialize np.array</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, f <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(df.ImageID)):</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(extract_path<span class="op">+</span>f<span class="op">+</span><span class="st">&#39;.jpg&#39;</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    img_resized <span class="op">=</span> img.resize((<span class="dv">32</span>,<span class="dv">32</span>))</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    img_resized.save(os.path.join(resize_path,<span class="ss">f&quot;</span><span class="sc">{f}</span><span class="ss">.jpg&quot;</span>), <span class="st">&quot;JPEG&quot;</span>, optimize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    img_arr[i] <span class="op">=</span> np.asarray(img_resized, dtype<span class="op">=</span>np.uint8).flatten()</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb37"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;7a35ffbc0bd04c04963d37e67016b505&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>CPU times: user 1min, sys: 1.87 s, total: 1min 1s
Wall time: 1min 3s
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="32" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="aB2Ti_63thTA" data-outputId="e30fd5f9-6a0a-402e-b16f-cb839eda6957">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(img_arr[<span class="dv">0</span>]))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>3072
</code></pre>
</div>
</div>
<div class="cell markdown" id="btnSYzvnKqIx">
<p>Plot the resized and filtered images</p>
</div>
<div class="cell code" data-execution_count="33" data-colab="{&quot;height&quot;:730,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="XwmJ1ItWKqIx" data-outputId="c8b40800-c5cb-4477-d46b-47dad26eaaad">
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot random 6 images</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">3</span>, sharex<span class="op">=</span><span class="va">False</span>, sharey<span class="op">=</span><span class="va">False</span>,figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax.flatten()</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,j <span class="kw">in</span> <span class="bu">enumerate</span>(np.random.choice(df.shape[<span class="dv">0</span>], size<span class="op">=</span><span class="dv">6</span>, replace<span class="op">=</span><span class="va">False</span>)):</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> mpimg.imread(<span class="ss">f&quot;</span><span class="sc">{</span>resize_path<span class="sc">}</span><span class="ss">/&quot;</span><span class="op">+</span>df.ImageID.values[j]<span class="op">+</span><span class="st">&#39;.jpg&#39;</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    h, w <span class="op">=</span> img.shape[:<span class="dv">2</span>]</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    coords <span class="op">=</span> df.iloc[j,<span class="dv">4</span>:<span class="dv">8</span>]</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(img)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    ax[i].set_title(df.iloc[j,<span class="dv">2</span>])</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    ax[i].add_patch(plt.Rectangle((coords[<span class="dv">0</span>]<span class="op">*</span>w, coords[<span class="dv">2</span>]<span class="op">*</span>h), </span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>                                  coords[<span class="dv">1</span>]<span class="op">*</span>w<span class="op">-</span>coords[<span class="dv">0</span>]<span class="op">*</span>w, coords[<span class="dv">3</span>]<span class="op">*</span>h<span class="op">-</span>coords[<span class="dv">2</span>]<span class="op">*</span>h, </span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>                                  edgecolor<span class="op">=</span><span class="st">&#39;red&#39;</span>, facecolor<span class="op">=</span><span class="st">&#39;none&#39;</span>))</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_5.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="34" id="15Ty8q3AKqIx">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># encode labels</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;Label&#39;</span>] <span class="op">=</span> (df.LabelName <span class="op">==</span> <span class="st">&#39;dog&#39;</span>).astype(np.uint8)</span></code></pre></div>
</div>
<section id="comparing-images-before-and-after" class="cell markdown" id="ZCvWSjo5thTB">
<h3>Comparing Images Before and After</h3>
</section>
<div class="cell code" data-execution_count="35" data-colab="{&quot;height&quot;:719,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="85RtHYRcthTB" data-outputId="3a871930-a911-4a93-820e-a102ea29658f">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot first 6 images</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">3</span>, sharex<span class="op">=</span><span class="va">False</span>, sharey<span class="op">=</span><span class="va">False</span>,figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax.flatten()</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,j <span class="kw">in</span> <span class="bu">enumerate</span>(df.index[<span class="dv">5584</span>:<span class="dv">5590</span>].to_numpy()):</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> mpimg.imread(extract_path <span class="op">+</span> df.ImageID.values[j] <span class="op">+</span> <span class="st">&#39;.jpg&#39;</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    h, w <span class="op">=</span> img.shape[:<span class="dv">2</span>]</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    coords <span class="op">=</span> df.iloc[j,<span class="dv">4</span>:<span class="dv">8</span>]</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(img)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    ax[i].set_title(df.LabelName[j])</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    ax[i].add_patch(plt.Rectangle((coords[<span class="dv">0</span>]<span class="op">*</span>w, coords[<span class="dv">2</span>]<span class="op">*</span>h), </span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>                                  coords[<span class="dv">1</span>]<span class="op">*</span>w<span class="op">-</span>coords[<span class="dv">0</span>]<span class="op">*</span>w, coords[<span class="dv">3</span>]<span class="op">*</span>h<span class="op">-</span>coords[<span class="dv">2</span>]<span class="op">*</span>h, </span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>                                  edgecolor<span class="op">=</span><span class="st">&#39;red&#39;</span>, facecolor<span class="op">=</span><span class="st">&#39;none&#39;</span>))</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_6.png" /></p>
</div>
</div>
<section id="checkpoint-and-save-data" class="cell markdown" id="H8nKwWglKqIx">
<h2>Checkpoint and Save data</h2>
</section>
<div class="cell code" data-execution_count="36" id="LM_pJn7rKqIx">
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>mkdir <span class="op">-</span>p <span class="op">\</span>data</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="37" id="Qfr2fyTaKqIx">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>np.save(<span class="st">&#39;data/img.npy&#39;</span>, img_arr.astype(np.uint8))</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>np.save(<span class="st">&#39;data/y_label.npy&#39;</span>, df.Label.values)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>np.save(<span class="st">&#39;data/y_bbox.npy&#39;</span>, df[[<span class="st">&#39;XMin&#39;</span>, <span class="st">&#39;YMin&#39;</span>, <span class="st">&#39;XMax&#39;</span>, <span class="st">&#39;YMax&#39;</span>]].values.astype(np.float32))</span></code></pre></div>
</div>
<section id="baseline-in-sklearn" class="cell markdown" id="pJiQLlj0KqIx">
<h1>Baseline in SKLearn</h1>
</section>
<section id="load-data" class="cell markdown" id="ItsLzaLvKqIy">
<h2>Load data</h2>
</section>
<div class="cell code" data-execution_count="38" id="QK3aLIQNKqIy">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.load(<span class="st">&#39;data/img.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>y_label <span class="op">=</span> np.load(<span class="st">&#39;data/y_label.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>y_bbox <span class="op">=</span> np.load(<span class="st">&#39;data/y_bbox.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="39" id="V4aY5eoyKqIy">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>idx_to_label <span class="op">=</span> {<span class="dv">1</span>:<span class="st">&#39;dog&#39;</span>, <span class="dv">0</span>:<span class="st">&#39;cat&#39;</span>} <span class="co"># encoder</span></span></code></pre></div>
</div>
<div class="cell markdown" id="IgBJ8W6VKqIy">
<p>Double check that it loaded correctly</p>
</div>
<div class="cell code" data-execution_count="40" data-colab="{&quot;height&quot;:730,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ODilTJB3KqIy" data-outputId="a7fe2e70-8094-44aa-ece9-efceefad7939">
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot random 6 images</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">3</span>, sharex<span class="op">=</span><span class="va">False</span>, sharey<span class="op">=</span><span class="va">False</span>,figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">10</span>))</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax.flatten()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,j <span class="kw">in</span> <span class="bu">enumerate</span>(np.random.choice(X.shape[<span class="dv">0</span>], size<span class="op">=</span><span class="dv">6</span>, replace<span class="op">=</span><span class="va">False</span>)):</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    coords <span class="op">=</span> y_bbox[j] <span class="op">*</span> <span class="dv">32</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(X[j].reshape(<span class="dv">32</span>,<span class="dv">32</span>,<span class="dv">3</span>))</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    ax[i].set_title(idx_to_label[y_label[j]])</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    ax[i].add_patch(plt.Rectangle((coords[<span class="dv">0</span>], coords[<span class="dv">1</span>]), </span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>                                  coords[<span class="dv">2</span>]<span class="op">-</span>coords[<span class="dv">0</span>], coords[<span class="dv">3</span>]<span class="op">-</span>coords[<span class="dv">1</span>], </span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>                                  edgecolor<span class="op">=</span><span class="st">&#39;red&#39;</span>, facecolor<span class="op">=</span><span class="st">&#39;none&#39;</span>))</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_7.png" /></p>
</div>
</div>
<section id="classification" class="cell markdown" id="4FJPGN8MKqIy">
<h2>Classification</h2>
</section>
<section id="split-data" class="cell markdown" id="XcCIbe4aKqIy">
<h3>Split data</h3>
<p>Create training and testing sets</p>
</section>
<div class="cell code" data-execution_count="41" id="erJMSqFVKqIy">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test_label <span class="op">=</span> train_test_split(X, y_label, test_size<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span></code></pre></div>
</div>
<section id="train" class="cell markdown" id="sTcYcYGpKqIy">
<h3>Train</h3>
<p>I'm choosing <code>SGDClassifier</code> because the data is large and I want to be able to perform stochastic gradient descent and also its ability to early stop. With this many parameters, a model can easily overfit so it's important to try and find the point of where it begins to overfit and stop for optimal results.</p>
</section>
<div class="cell code" data-execution_count="42" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="vL4PEsXzKqIy" data-outputId="8dc57bbb-ee64-41db-9975-1ec382adbb4b">
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SGDClassifier(loss<span class="op">=</span><span class="st">&#39;log&#39;</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">27</span>, learning_rate<span class="op">=</span><span class="st">&#39;adaptive&#39;</span>, eta0<span class="op">=</span><span class="fl">1e-10</span>, </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>                      early_stopping<span class="op">=</span><span class="va">True</span>, validation_fraction<span class="op">=</span><span class="fl">0.1</span>, n_iter_no_change<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.2 validation </span><span class="al">TODO</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>CPU times: user 924 ms, sys: 416 ms, total: 1.34 s
Wall time: 930 ms
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="43" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="bxGIEvbzKqIy" data-outputId="ec62ee0b-9dde-475a-bb5b-a0a925f8f539">
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>model.n_iter_</span></code></pre></div>
<div class="output execute_result" data-execution_count="43">
<pre><code>4</code></pre>
</div>
</div>
<div class="cell markdown" id="7U7C5XMxKqIy">
<p>Did it stop too early? Let's retrain with a few more iterations to see. Note that <code>SGDClassifier</code> has a parameter called <code>validation_fraction</code> which splits a validation set from the training data to determine when it stops.</p>
</div>
<div class="cell code" data-execution_count="44" id="fJkfwivcKqIy">
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>X_train, X_valid, y_train, y_valid <span class="op">=</span> train_test_split(X_train, y_train, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="45" data-colab="{&quot;height&quot;:49,&quot;referenced_widgets&quot;:[&quot;afb86137182d4aab80a93c663215be2a&quot;,&quot;89739b6cddcf4a8abc7a0d1ee0492ed6&quot;,&quot;72fb0200ace34be69692a32dd26ca316&quot;,&quot;c0570699fbc8414d8a7c4aec0f2b4efb&quot;,&quot;c0ce9a51f85842a3ab669793bf97c0b4&quot;,&quot;b287e12ad29c4617a9fa8c7782ed483f&quot;,&quot;6ec48b4284364d4aa086fe2809a8b898&quot;,&quot;555ff93124fb40a48b84f497d3037917&quot;,&quot;aad3df6b23f241168d7bce674b8b6c10&quot;,&quot;fc586aeb21054df2b29407a1358d2c52&quot;,&quot;f116eaba9f27426382c7ebf066374ecb&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="vgRZscLjKqIy" data-outputId="da4c795c-3b95-4d7e-ca59-ad5f27f6cd1e">
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> SGDClassifier(loss<span class="op">=</span><span class="st">&#39;log&#39;</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">27</span>, learning_rate<span class="op">=</span><span class="st">&#39;adaptive&#39;</span>, eta0<span class="op">=</span><span class="fl">1e-10</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>train_acc <span class="op">=</span> np.zeros(epochs)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>valid_acc <span class="op">=</span> np.zeros(epochs)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>    model2.partial_fit(X_train, y_train, np.unique(y_train))</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#log</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>    train_acc[i] <span class="op">+=</span> np.<span class="bu">round</span>(accuracy_score(y_train, model2.predict(X_train)),<span class="dv">3</span>)</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>    valid_acc[i] <span class="op">+=</span> np.<span class="bu">round</span>(accuracy_score(y_valid, model2.predict(X_valid)),<span class="dv">3</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb56"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;afb86137182d4aab80a93c663215be2a&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell code" data-execution_count="46" data-colab="{&quot;height&quot;:295,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="kYz1N8lVKqIy" data-outputId="3ce2b556-5534-4f90-e9bd-dcbda24cf3f0">
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>plt.plot(train_acc, label<span class="op">=</span><span class="st">&#39;train&#39;</span>)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>plt.plot(valid_acc, label<span class="op">=</span><span class="st">&#39;valid&#39;</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;CaDoD Training&#39;</span>)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epochs&#39;</span>)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_8.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="47" id="kSF3hSPCKqIy">
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> model2</span></code></pre></div>
</div>
<section id="evaluation" class="cell markdown" id="naRFdrZiKqIy">
<h3>Evaluation</h3>
</section>
<div class="cell code" data-execution_count="48" id="LwxNrGjBKqIy">
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>expLog <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&quot;exp_name&quot;</span>, </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;Train Acc&quot;</span>, </span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;Valid Acc&quot;</span>,</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;Test  Acc&quot;</span>,</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;Train MSE&quot;</span>, </span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;Valid MSE&quot;</span>,</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;Test  MSE&quot;</span>,</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>                              ])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="49" id="nYnhJU-ZKqIy">
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="ss">f&quot;Baseline: Linear Model&quot;</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>expLog.loc[<span class="dv">0</span>,:<span class="dv">4</span>] <span class="op">=</span> [<span class="ss">f&quot;</span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss">&quot;</span>] <span class="op">+</span> <span class="bu">list</span>(np.<span class="bu">round</span>(</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>               [accuracy_score(y_train, model.predict(X_train)), </span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>                accuracy_score(y_valid, model.predict(X_valid)),</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>                accuracy_score(y_test_label, model.predict(X_test))],<span class="dv">3</span>))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="50" data-colab="{&quot;height&quot;:81,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="7PHpvx6gKqIy" data-outputId="7356ca9e-67a6-4a0a-f8f4-2ecced2bbff2">
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>expLog</span></code></pre></div>
<div class="output execute_result" data-execution_count="50">

  <div id="df-692cd7ce-be7e-45c1-bbc6-7c04b4a7dcbe">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train MSE</th>
      <th>Valid MSE</th>
      <th>Test  MSE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline: Linear Model</td>
      <td>0.565</td>
      <td>0.557</td>
      <td>0.615</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-692cd7ce-be7e-45c1-bbc6-7c04b4a7dcbe')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-692cd7ce-be7e-45c1-bbc6-7c04b4a7dcbe button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-692cd7ce-be7e-45c1-bbc6-7c04b4a7dcbe');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<div class="cell code" data-execution_count="51" data-colab="{&quot;height&quot;:445,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="OsxLqjPlKqIy" data-outputId="0748ae93-4c98-4042-9f97-fb11071c3ceb">
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>y_pred_label <span class="op">=</span> model.predict(X_test)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>y_pred_label_proba <span class="op">=</span> model.predict_proba(X_test)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, ncols<span class="op">=</span><span class="dv">5</span>, sharex<span class="op">=</span><span class="va">False</span>, sharey<span class="op">=</span><span class="va">False</span>,figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">6</span>))</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> ax.flatten()</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> X_test[i].reshape(<span class="dv">32</span>,<span class="dv">32</span>,<span class="dv">3</span>)</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(img)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    ax[i].set_title(<span class="st">&quot;Ground Truth: </span><span class="sc">{0}</span><span class="st"> </span><span class="ch">\n</span><span class="st"> Prediction: </span><span class="sc">{1}</span><span class="st"> | </span><span class="sc">{2:.2f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(idx_to_label[y_test_label[i]],</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>                                                                   idx_to_label[y_pred_label[i]],</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>                                                                   y_pred_label_proba[i][y_pred_label[i]]),</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>                   color<span class="op">=</span>(<span class="st">&quot;green&quot;</span> <span class="cf">if</span> y_pred_label[i]<span class="op">==</span>y_test_label[i] <span class="cf">else</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="assets/img_9.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="52" id="Ecobz01jthTD">
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># imports</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>warnings.simplefilter(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, TransformerMixin</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> ShuffleSplit</span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier</span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span></code></pre></div>
</div>
<section id="regression" class="cell markdown" id="LDM0aGUnKqIy">
<h2>Regression</h2>
</section>
<section id="split-data" class="cell markdown" id="13nnDLu3KqIy">
<h3>Split data</h3>
</section>
<div class="cell code" data-execution_count="53" id="KRcbazqXthTD">
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>d1 <span class="op">=</span> []</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i1 <span class="kw">in</span> img_arr:</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    d1.append(i1)</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>temp_image_data<span class="op">=</span>[]</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(df)):</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    temp_image_data.append(pd.Series(data <span class="op">=</span> d1).iloc[i])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="54" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="zZErIgYtthTD" data-outputId="c020c2b2-9517-481e-9bed-347246190916">
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(temp_image_data)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(img_arr[<span class="dv">0</span>])</span></code></pre></div>
<div class="output execute_result" data-execution_count="54">
<pre><code>3072</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="55" id="0KJHdOJfthTD">
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(np.array(temp_image_data), y_bbox, test_size<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>X_train, X_valid, y_train, y_valid <span class="op">=</span> train_test_split(X_train, y_train, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span></code></pre></div>
</div>
<section id="train" class="cell markdown" id="B0fCNF2UKqIy">
<h3>Train</h3>
</section>
<div class="cell code" data-execution_count="56" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="a6t0-pvIKqIy" data-outputId="f51d02d9-b326-4c3c-983d-de0d8dcdf7e1">
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co"> closed loop solution, could use Lasso Ridge</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression() <span class="co">#fill in </span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="co"># might take a few minutes to train</span></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co">#CPU times: user 1h 26min 40s, sys: 5min 53s, total: 1h 32min 34s</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Wall time: 17min 24s</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>CPU times: user 35.9 s, sys: 1.11 s, total: 37 s
Wall time: 19.3 s
</code></pre>
</div>
</div>
<section id="baseline-linear-regression-with-lasso-and-ridge" class="cell markdown" id="sKDfM07zthTE">
<h3>Baseline Linear regression with lasso and ridge</h3>
</section>
<section id="evaluation" class="cell markdown" id="aHqKrEDWKqIy">
<h3>Evaluation</h3>
</section>
<div class="cell code" data-execution_count="57" data-colab="{&quot;height&quot;:81,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="kfUPQ0B_KqIy" data-outputId="7a5a5991-5114-4332-a417-e7bdfa6f3879">
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>expLog.iloc[<span class="dv">0</span>,<span class="dv">4</span>:] <span class="op">=</span> <span class="bu">list</span>(np.<span class="bu">round</span>([mean_squared_error(y_train, model.predict(X_train)), </span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>          mean_squared_error(y_valid, model.predict(X_valid)), </span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>          mean_squared_error(y_test, model.predict(X_test))],<span class="dv">3</span>))</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>expLog</span></code></pre></div>
<div class="output execute_result" data-execution_count="57">

  <div id="df-983022c7-a976-4bb1-aa55-5512496e6991">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train MSE</th>
      <th>Valid MSE</th>
      <th>Test  MSE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline: Linear Model</td>
      <td>0.565</td>
      <td>0.557</td>
      <td>0.615</td>
      <td>0.007</td>
      <td>0.015</td>
      <td>0.015</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-983022c7-a976-4bb1-aa55-5512496e6991')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-983022c7-a976-4bb1-aa55-5512496e6991 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-983022c7-a976-4bb1-aa55-5512496e6991');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<div class="cell code" data-execution_count="58" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="4p4JK9dNthTE" data-outputId="4dd7d523-6af5-45b1-9a52-4bc56b9d71c2">
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The below code is refered from Hw5</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>estimators <span class="op">=</span> [(<span class="st">&#39;ridge&#39;</span>, Ridge()),</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>              (<span class="st">&#39;lasso&#39;</span>, Lasso())]</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>best_score <span class="op">=</span> []</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>best_param <span class="op">=</span> []</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> estimator <span class="kw">in</span> estimators:</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {estimator[<span class="dv">0</span>]<span class="op">+</span><span class="st">&#39;__alpha&#39;</span>:[<span class="fl">.01</span>, <span class="fl">.05</span>, <span class="fl">.1</span>, <span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">5</span>]}</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set up the pipeline using the standard scaler and estimator</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and grid search with pipeline, params, </span></span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and correct scoring parameter (scoring parameter has to be a utility- where bigger is better </span></span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># such as neg_mean_squared_error, explained_variance etc. )</span></span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for more information see the following - </span></span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter</span></span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Please use neg_mean_squared_error here.</span></span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#==================================================#</span></span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#               Your code starts here              #</span></span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">#==================================================#</span></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co"> - change above to</span></span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>    pipe <span class="op">=</span> Pipeline([(<span class="st">&#39;scalar&#39;</span>, StandardScaler()), estimator])</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>    gs <span class="op">=</span> GridSearchCV(pipe, params, scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>,cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#==================================================#</span></span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#               Your code ends here                #</span></span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">#==================================================#</span></span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a>    gs.fit(X_train, y_train)</span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a>    best_score.append(gs.best_score_)</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a>    best_param.append(gs.best_params_)</span>
<span id="cb71-35"><a href="#cb71-35" aria-hidden="true" tabindex="-1"></a>best_idx <span class="op">=</span> np.argmax(best_score)</span>
<span id="cb71-36"><a href="#cb71-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Best model is:&#39;</span>, estimators[best_idx][<span class="dv">0</span>], <span class="st">&#39;with parameter&#39;</span>, best_param[best_idx])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Best model is: lasso with parameter {&#39;lasso__alpha&#39;: 0.01}
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="59" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="RoOOhfTsthTE" data-outputId="6ac26828-43c4-4d9c-f0c5-6132953cc541">
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(best_param[best_idx].values())[<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="59">
<pre><code>0.01</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="60" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="jGyjP6mfthTE" data-outputId="6ec3b43d-f39c-4e9c-b505-515e4d964b4b">
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co">#estimator = estimators[best_idx][0], list(best_param[best_idx].values())[0])</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>estimator <span class="op">=</span> [Ridge, Lasso][best_idx]</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>param <span class="op">=</span> <span class="bu">list</span>(gs.best_params_.values())[<span class="dv">0</span>]</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (param)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co"># set up the pipeline using the best estimator</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> Pipeline([(<span class="st">&#39;scalar&#39;</span>, StandardScaler()), (<span class="st">&#39;estimator&#39;</span>, estimator(alpha<span class="op">=</span>param))])</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>pipe.fit(X_train, y_train)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0.01
</code></pre>
</div>
<div class="output execute_result" data-execution_count="60">
<pre><code>Pipeline(steps=[(&#39;scalar&#39;, StandardScaler()), (&#39;estimator&#39;, Lasso(alpha=0.01))])</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="61" data-colab="{&quot;height&quot;:112,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="I8vhiGk9thTE" data-outputId="cccf9791-d36c-491d-e577-eac051d5bb6b">
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>exp_name <span class="op">=</span> <span class="ss">f&quot;Linear Regression(best regularization and alpha)&quot;</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>expLog.loc[<span class="dv">1</span>,:<span class="dv">4</span>] <span class="op">=</span> [<span class="ss">f&quot;</span><span class="sc">{</span>exp_name<span class="sc">}</span><span class="ss">&quot;</span>] <span class="op">+</span><span class="bu">list</span>(np.<span class="bu">round</span>([<span class="dv">0</span>, </span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>          <span class="dv">0</span>, </span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>          <span class="dv">0</span>],<span class="dv">3</span>))</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>expLog.loc[<span class="dv">1</span>,<span class="dv">4</span>:] <span class="op">=</span> <span class="bu">list</span>(np.<span class="bu">round</span>([mean_squared_error(y_train, pipe.predict(X_train)), </span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>          mean_squared_error(y_valid, pipe.predict(X_valid)), </span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>          mean_squared_error(y_test, pipe.predict(X_test))],<span class="dv">3</span>))</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>expLog</span></code></pre></div>
<div class="output execute_result" data-execution_count="61">

  <div id="df-12248a4b-46e1-400e-9b01-7735ddbbc440">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exp_name</th>
      <th>Train Acc</th>
      <th>Valid Acc</th>
      <th>Test  Acc</th>
      <th>Train MSE</th>
      <th>Valid MSE</th>
      <th>Test  MSE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline: Linear Model</td>
      <td>0.565</td>
      <td>0.557</td>
      <td>0.615</td>
      <td>0.007</td>
      <td>0.015</td>
      <td>0.015</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Linear Regression(best regularization and alpha)</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.01</td>
      <td>0.011</td>
      <td>0.009</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-12248a4b-46e1-400e-9b01-7735ddbbc440')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-12248a4b-46e1-400e-9b01-7735ddbbc440 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-12248a4b-46e1-400e-9b01-7735ddbbc440');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<div class="cell markdown" id="9FSGqi3HthTE">
<h3 id="modelling-pipelines">Modelling Pipelines</h3>
<h3 id="baseline">Baseline</h3>
</div>
<div class="cell code" data-execution_count="62" id="Qfs9ea_GthTF">
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Below code is refered from HW13, Hw7,Hw2</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV, PredefinedSplit</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.load(<span class="st">&#39;data/img.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>y_label <span class="op">=</span> np.load(<span class="st">&#39;data/y_label.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>y_bbox <span class="op">=</span> np.load(<span class="st">&#39;data/y_bbox.npy&#39;</span>, allow_pickle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>idx_to_label <span class="op">=</span> {<span class="dv">1</span>:<span class="st">&#39;dog&#39;</span>, <span class="dv">0</span>:<span class="st">&#39;cat&#39;</span>}</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>X_train_class, X_test_class, y_train_label, y_test_label <span class="op">=</span> train_test_split(X, y_label, stratify<span class="op">=</span>y_label, shuffle<span class="op">=</span><span class="va">True</span>, test_size<span class="op">=</span><span class="fl">0.50</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.astype(np.float32) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>y_label<span class="op">=</span>y_label.astype(<span class="bu">int</span>)</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>X_train_class, X_test_class, y_train_label, y_test_label <span class="op">=</span> train_test_split(X, y_label, stratify<span class="op">=</span>y_label, shuffle<span class="op">=</span><span class="va">True</span>, test_size<span class="op">=</span><span class="fl">0.20</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>X_train_full <span class="op">=</span> X_train_class</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>y_train_full <span class="op">=</span> y_train_label</span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>X_test_full <span class="op">=</span> X_test_class</span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>y_test_full <span class="op">=</span> y_test_label</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>X_train, _, y_train, _ <span class="op">=</span> train_test_split(X_train_class, y_train_label, stratify<span class="op">=</span>y_train_label, train_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a>X_test, _, y_test, _ <span class="op">=</span> train_test_split(X_test_class, y_test_label, stratify<span class="op">=</span>y_test_label, train_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="63" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="r8ExmVqmthTF" data-outputId="a1decd73-fff2-4318-bc2c-5530b56e2c70">
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use full pipeline above to build full pipeline with predictor</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>full_pipeline_with_predictor <span class="op">=</span> Pipeline([</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&quot;linear&quot;</span>, LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>))</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>full_pipeline_with_predictor.fit(X_train, y_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="63">
<pre><code>Pipeline(steps=[(&#39;linear&#39;, LogisticRegression(random_state=42))])</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="64" id="BNz11PTgthTF">
<div class="sourceCode" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>full_pipeline_with_predictor.fit(X_train, y_train)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cross validation scores </span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Use ShuffleSplit() with 30 splits, 30% test_size </span></span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a><span class="co"># and a random seed of 0</span></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a><span class="co">#==================================================#</span></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="co">#               Your code starts here              #</span></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a><span class="co">#==================================================#</span></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>cv3Splits <span class="op">=</span> ShuffleSplit(n_splits<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">0</span>, test_size<span class="op">=</span><span class="fl">0.30</span>, train_size<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>logit_scores <span class="op">=</span> cross_val_score(full_pipeline_with_predictor, X_train, y_train, cv<span class="op">=</span>cv3Splits)     </span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a><span class="co">#==================================================#</span></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a><span class="co">#               Your code ends here                #</span></span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a><span class="co">#               Please don&#39;t add code below here   #</span></span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a><span class="co">#==================================================#</span></span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>logit_score_train <span class="op">=</span> logit_scores.mean()</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>train_time <span class="op">=</span> np.<span class="bu">round</span>(time() <span class="op">-</span> start, <span class="dv">4</span>)</span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Time and score test predictions</span></span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time()</span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a>logit_score_test  <span class="op">=</span> full_pipeline_with_predictor.score(X_test, y_test)</span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a>test_time <span class="op">=</span> np.<span class="bu">round</span>(time() <span class="op">-</span> start, <span class="dv">4</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="65" data-colab="{&quot;height&quot;:81,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="4jp4t_lcthTF" data-outputId="25603f69-6df1-4e92-a828-7bac6f7f52be">
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&quot;Expname&quot;</span>, <span class="st">&quot;Train accuracy&quot;</span>, <span class="st">&quot;Test Accuracy&quot;</span>])</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>results.loc[<span class="dv">0</span>] <span class="op">=</span> [<span class="st">&quot;Baseline&quot;</span>, np.<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>logit_score_train,<span class="dv">1</span>), np.<span class="bu">round</span>(np.<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>logit_score_test,<span class="dv">1</span>),<span class="dv">3</span>)]</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<div class="output execute_result" data-execution_count="65">

  <div id="df-eba01c77-b2fc-4ba8-9212-8c2887bb7ff4">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Expname</th>
      <th>Train accuracy</th>
      <th>Test Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline</td>
      <td>54.0</td>
      <td>55.2</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-eba01c77-b2fc-4ba8-9212-8c2887bb7ff4')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-eba01c77-b2fc-4ba8-9212-8c2887bb7ff4 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-eba01c77-b2fc-4ba8-9212-8c2887bb7ff4');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<div class="cell code" data-execution_count="66" id="9UpQ9f8_thTF">
<div class="sourceCode" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="co"># A Function to execute the grid search and record the results.</span></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ConductGridSearch(X_train, y_train, X_test, y_test, i<span class="op">=</span><span class="dv">0</span>, prefix<span class="op">=</span><span class="st">&#39;&#39;</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>,verbose<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a list of classifiers for our grid search experiment</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>    classifiers <span class="op">=</span> [</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Logistic Regression&#39;</span>, LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>)),</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;K-Nearest Neighbors&#39;</span>, KNeighborsClassifier()),</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Naive Bayes&#39;</span>, GaussianNB()),</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Support Vector&#39;</span>, SVC(random_state<span class="op">=</span><span class="dv">42</span>)),</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&#39;Stochastic GD&#39;</span>, SGDClassifier(loss<span class="op">=</span><span class="st">&#39;log&#39;</span>,</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>                                        penalty<span class="op">=</span><span class="st">&#39;l2&#39;</span>,</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>                                        early_stopping<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>                                        max_iter<span class="op">=</span><span class="dv">10000</span>, tol<span class="op">=</span><span class="fl">1e-5</span>,</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>                                        random_state<span class="op">=</span><span class="dv">42</span>)),</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Arrange grid search parameters for each classifier</span></span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>    params_grid <span class="op">=</span> {</span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Logistic Regression&#39;</span>: {</span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;penalty&#39;</span>: (<span class="st">&#39;l1&#39;</span>, <span class="st">&#39;l2&#39;</span>),</span>
<span id="cb84-23"><a href="#cb84-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;tol&#39;</span>: (<span class="fl">0.0001</span>, <span class="fl">0.00001</span>, <span class="fl">0.0000001</span>), </span>
<span id="cb84-24"><a href="#cb84-24" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;C&#39;</span>: (<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>),</span>
<span id="cb84-25"><a href="#cb84-25" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb84-26"><a href="#cb84-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;K-Nearest Neighbors&#39;</span>: {</span>
<span id="cb84-27"><a href="#cb84-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;n_neighbors&#39;</span>: (<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">11</span>),</span>
<span id="cb84-28"><a href="#cb84-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;p&#39;</span>: (<span class="dv">1</span>,<span class="dv">2</span>),</span>
<span id="cb84-29"><a href="#cb84-29" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb84-30"><a href="#cb84-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Naive Bayes&#39;</span>: {},</span>
<span id="cb84-31"><a href="#cb84-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Support Vector&#39;</span> : {</span>
<span id="cb84-32"><a href="#cb84-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;kernel&#39;</span>: (<span class="st">&#39;rbf&#39;</span>, <span class="st">&#39;poly&#39;</span>),     </span>
<span id="cb84-33"><a href="#cb84-33" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;degree&#39;</span>: (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>),</span>
<span id="cb84-34"><a href="#cb84-34" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;C&#39;</span>: (<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>),</span>
<span id="cb84-35"><a href="#cb84-35" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb84-36"><a href="#cb84-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Stochastic GD&#39;</span>: {</span>
<span id="cb84-37"><a href="#cb84-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;tol&#39;</span>: (<span class="fl">0.0001</span>, <span class="fl">0.0000001</span>), </span>
<span id="cb84-38"><a href="#cb84-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;alpha&#39;</span>: (<span class="fl">0.1</span>, <span class="fl">0.001</span>, <span class="fl">0.0001</span>), </span>
<span id="cb84-39"><a href="#cb84-39" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb84-40"><a href="#cb84-40" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb84-41"><a href="#cb84-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb84-42"><a href="#cb84-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (name, classifier) <span class="kw">in</span> classifiers:</span>
<span id="cb84-43"><a href="#cb84-43" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb84-44"><a href="#cb84-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print classifier and parameters</span></span>
<span id="cb84-45"><a href="#cb84-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&#39;****** START&#39;</span>,prefix, name,<span class="st">&#39;*****&#39;</span>)</span>
<span id="cb84-46"><a href="#cb84-46" aria-hidden="true" tabindex="-1"></a>        parameters <span class="op">=</span> params_grid[name]</span>
<span id="cb84-47"><a href="#cb84-47" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Parameters:&quot;</span>)</span>
<span id="cb84-48"><a href="#cb84-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> <span class="bu">sorted</span>(parameters.keys()):</span>
<span id="cb84-49"><a href="#cb84-49" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span><span class="op">+</span><span class="bu">str</span>(p)<span class="op">+</span><span class="st">&quot;: &quot;</span><span class="op">+</span> <span class="bu">str</span>(parameters[p]))</span>
<span id="cb84-50"><a href="#cb84-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-51"><a href="#cb84-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># generate the pipeline</span></span>
<span id="cb84-52"><a href="#cb84-52" aria-hidden="true" tabindex="-1"></a>        full_pipeline_with_predictor <span class="op">=</span> Pipeline([</span>
<span id="cb84-53"><a href="#cb84-53" aria-hidden="true" tabindex="-1"></a>        (<span class="st">&quot;predictor&quot;</span>, classifier)</span>
<span id="cb84-54"><a href="#cb84-54" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb84-55"><a href="#cb84-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-56"><a href="#cb84-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Execute the grid search</span></span>
<span id="cb84-57"><a href="#cb84-57" aria-hidden="true" tabindex="-1"></a>        params <span class="op">=</span> {}</span>
<span id="cb84-58"><a href="#cb84-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters.keys():</span>
<span id="cb84-59"><a href="#cb84-59" aria-hidden="true" tabindex="-1"></a>            pipe_key <span class="op">=</span> <span class="st">&#39;predictor__&#39;</span><span class="op">+</span><span class="bu">str</span>(p)</span>
<span id="cb84-60"><a href="#cb84-60" aria-hidden="true" tabindex="-1"></a>            params[pipe_key] <span class="op">=</span> parameters[p] </span>
<span id="cb84-61"><a href="#cb84-61" aria-hidden="true" tabindex="-1"></a>        grid_search <span class="op">=</span> GridSearchCV(full_pipeline_with_predictor, params, scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>, cv<span class="op">=</span><span class="dv">5</span>, </span>
<span id="cb84-62"><a href="#cb84-62" aria-hidden="true" tabindex="-1"></a>                                   n_jobs<span class="op">=</span>n_jobs, verbose<span class="op">=</span>verbose)</span>
<span id="cb84-63"><a href="#cb84-63" aria-hidden="true" tabindex="-1"></a>        grid_search.fit(X_train, y_train)</span>
<span id="cb84-64"><a href="#cb84-64" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb84-65"><a href="#cb84-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Best estimator score</span></span>
<span id="cb84-66"><a href="#cb84-66" aria-hidden="true" tabindex="-1"></a>        best_train <span class="op">=</span> np.<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>grid_search.best_score_,<span class="dv">1</span>)</span>
<span id="cb84-67"><a href="#cb84-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-68"><a href="#cb84-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Best estimator fitting time</span></span>
<span id="cb84-69"><a href="#cb84-69" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> time()</span>
<span id="cb84-70"><a href="#cb84-70" aria-hidden="true" tabindex="-1"></a>        grid_search.best_estimator_.fit(X_train, y_train)</span>
<span id="cb84-71"><a href="#cb84-71" aria-hidden="true" tabindex="-1"></a>        train_time <span class="op">=</span> <span class="bu">round</span>(time() <span class="op">-</span> start, <span class="dv">4</span>)</span>
<span id="cb84-72"><a href="#cb84-72" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-73"><a href="#cb84-73" aria-hidden="true" tabindex="-1"></a><span class="co"># #         plt.barh([&#39;Age&#39;, &#39;Parch&#39;, &#39;SibSp&#39;,&#39;Fare&#39;,&#39;x0_C&#39; ,&#39;x0_Q&#39; ,&#39;x0_S&#39; ,&#39;x1_female&#39;, &#39;x1_male&#39; ,&#39;x2_1&#39; ,&#39;x2_2&#39;, &#39;x2_3&#39;], grid_search.best_estimator_.named_steps[&quot;predictor&quot;].feature_importances_)</span></span>
<span id="cb84-74"><a href="#cb84-74" aria-hidden="true" tabindex="-1"></a><span class="co"># #         plt.show()</span></span>
<span id="cb84-75"><a href="#cb84-75" aria-hidden="true" tabindex="-1"></a><span class="co">#         features = [&#39;Age&#39;, &#39;Parch&#39;, &#39;SibSp&#39;,&#39;Fare&#39;,&#39;x0_C&#39; ,&#39;x0_Q&#39; ,&#39;x0_S&#39; ,&#39;x1_female&#39;, &#39;x1_male&#39; ,&#39;x2_1&#39; ,&#39;x2_2&#39;, &#39;x2_3&#39;]</span></span>
<span id="cb84-76"><a href="#cb84-76" aria-hidden="true" tabindex="-1"></a><span class="co">#         importances = grid_search.best_estimator_.named_steps[&quot;predictor&quot;].feature_importances_</span></span>
<span id="cb84-77"><a href="#cb84-77" aria-hidden="true" tabindex="-1"></a><span class="co">#         indices = np.argsort(importances)</span></span>
<span id="cb84-78"><a href="#cb84-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-79"><a href="#cb84-79" aria-hidden="true" tabindex="-1"></a><span class="co">#         plt.title(&#39;Feature Importances&#39;)</span></span>
<span id="cb84-80"><a href="#cb84-80" aria-hidden="true" tabindex="-1"></a><span class="co">#         plt.barh(range(len(indices)), importances[indices], color=&#39;b&#39;, align=&#39;center&#39;)</span></span>
<span id="cb84-81"><a href="#cb84-81" aria-hidden="true" tabindex="-1"></a><span class="co">#         plt.yticks(range(len(indices)), [features[i] for i in indices])</span></span>
<span id="cb84-82"><a href="#cb84-82" aria-hidden="true" tabindex="-1"></a><span class="co">#         plt.xlabel(&#39;Relative Importance&#39;)</span></span>
<span id="cb84-83"><a href="#cb84-83" aria-hidden="true" tabindex="-1"></a><span class="co">#         plt.grid()</span></span>
<span id="cb84-84"><a href="#cb84-84" aria-hidden="true" tabindex="-1"></a><span class="co">#         plt.show();</span></span>
<span id="cb84-85"><a href="#cb84-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Best estimator prediction time</span></span>
<span id="cb84-86"><a href="#cb84-86" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> time()</span>
<span id="cb84-87"><a href="#cb84-87" aria-hidden="true" tabindex="-1"></a>        best_test_accuracy <span class="op">=</span> np.<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>grid_search.best_estimator_.score(X_test, y_test),<span class="dv">1</span>)</span>
<span id="cb84-88"><a href="#cb84-88" aria-hidden="true" tabindex="-1"></a>        test_time <span class="op">=</span> <span class="bu">round</span>(time() <span class="op">-</span> start, <span class="dv">4</span>)</span>
<span id="cb84-89"><a href="#cb84-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-90"><a href="#cb84-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate 30 training accuracy scores with the best estimator and 30-split CV</span></span>
<span id="cb84-91"><a href="#cb84-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># To calculate the best_train_accuracy use the pct() and mean() methods</span></span>
<span id="cb84-92"><a href="#cb84-92" aria-hidden="true" tabindex="-1"></a>        <span class="co">#==================================================#</span></span>
<span id="cb84-93"><a href="#cb84-93" aria-hidden="true" tabindex="-1"></a>        <span class="co">#               Your code starts here              #</span></span>
<span id="cb84-94"><a href="#cb84-94" aria-hidden="true" tabindex="-1"></a>        <span class="co">#==================================================#</span></span>
<span id="cb84-95"><a href="#cb84-95" aria-hidden="true" tabindex="-1"></a>        best_train_scores <span class="op">=</span> cross_val_score(grid_search.best_estimator_, X_train, y_train, cv<span class="op">=</span>cv3Splits)</span>
<span id="cb84-96"><a href="#cb84-96" aria-hidden="true" tabindex="-1"></a>        best_train_accuracy <span class="op">=</span> np.<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>best_train_scores.mean(),<span class="dv">1</span>)</span>
<span id="cb84-97"><a href="#cb84-97" aria-hidden="true" tabindex="-1"></a>        <span class="co">#==================================================#</span></span>
<span id="cb84-98"><a href="#cb84-98" aria-hidden="true" tabindex="-1"></a>        <span class="co">#               Your code ends here                #</span></span>
<span id="cb84-99"><a href="#cb84-99" aria-hidden="true" tabindex="-1"></a>        <span class="co">#               Please don&#39;t add code below here   #</span></span>
<span id="cb84-100"><a href="#cb84-100" aria-hidden="true" tabindex="-1"></a>        <span class="co">#==================================================#    </span></span>
<span id="cb84-101"><a href="#cb84-101" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb84-102"><a href="#cb84-102" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Conduct t-test with baseline logit (control) and best estimator (experiment)</span></span>
<span id="cb84-103"><a href="#cb84-103" aria-hidden="true" tabindex="-1"></a>        (t_stat, p_value) <span class="op">=</span> stats.ttest_rel(logit_scores, best_train_scores)</span>
<span id="cb84-104"><a href="#cb84-104" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-105"><a href="#cb84-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Collect the best parameters found by the grid search</span></span>
<span id="cb84-106"><a href="#cb84-106" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Best Parameters:&quot;</span>)</span>
<span id="cb84-107"><a href="#cb84-107" aria-hidden="true" tabindex="-1"></a>        best_parameters <span class="op">=</span> grid_search.best_estimator_.get_params()</span>
<span id="cb84-108"><a href="#cb84-108" aria-hidden="true" tabindex="-1"></a>        param_dump <span class="op">=</span> []</span>
<span id="cb84-109"><a href="#cb84-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param_name <span class="kw">in</span> <span class="bu">sorted</span>(params.keys()):</span>
<span id="cb84-110"><a href="#cb84-110" aria-hidden="true" tabindex="-1"></a>            param_dump.append((param_name, best_parameters[param_name]))</span>
<span id="cb84-111"><a href="#cb84-111" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span><span class="op">+</span><span class="bu">str</span>(param_name)<span class="op">+</span><span class="st">&quot;: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(best_parameters[param_name]))</span>
<span id="cb84-112"><a href="#cb84-112" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;****** FINISH&quot;</span>,prefix,name,<span class="st">&quot; *****&quot;</span>)</span>
<span id="cb84-113"><a href="#cb84-113" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;&quot;</span>)</span>
<span id="cb84-114"><a href="#cb84-114" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-115"><a href="#cb84-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Record the results</span></span>
<span id="cb84-116"><a href="#cb84-116" aria-hidden="true" tabindex="-1"></a>        results.loc[i] <span class="op">=</span> [prefix<span class="op">+</span>name, best_train_accuracy, best_test_accuracy]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="67" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="hwUoj0HTthTF" data-outputId="3a7fa481-d6b4-4463-e8af-0c2f977a3433">
<div class="sourceCode" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>ConductGridSearch(X_train, y_train, X_test, y_test, <span class="dv">0</span>, <span class="st">&quot;Best Model:&quot;</span>,  n_jobs<span class="op">=-</span><span class="dv">1</span>,verbose<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>****** START Best Model: Logistic Regression *****
Parameters:
	C: (10, 1, 0.1, 0.01)
	penalty: (&#39;l1&#39;, &#39;l2&#39;)
	tol: (0.0001, 1e-05, 1e-07)
Fitting 5 folds for each of 24 candidates, totalling 120 fits
Best Parameters:
	predictor__C: 0.01
	predictor__penalty: l2
	predictor__tol: 0.0001
****** FINISH Best Model: Logistic Regression  *****

****** START Best Model: K-Nearest Neighbors *****
Parameters:
	n_neighbors: (3, 5, 7, 8, 11)
	p: (1, 2)
Fitting 5 folds for each of 10 candidates, totalling 50 fits
Best Parameters:
	predictor__n_neighbors: 11
	predictor__p: 2
****** FINISH Best Model: K-Nearest Neighbors  *****

****** START Best Model: Naive Bayes *****
Parameters:
Fitting 5 folds for each of 1 candidates, totalling 5 fits
Best Parameters:
****** FINISH Best Model: Naive Bayes  *****

****** START Best Model: Support Vector *****
Parameters:
	C: (10, 1, 0.1, 0.01)
	degree: (1, 2, 3, 4, 5)
	kernel: (&#39;rbf&#39;, &#39;poly&#39;)
Fitting 5 folds for each of 40 candidates, totalling 200 fits
Best Parameters:
	predictor__C: 1
	predictor__degree: 1
	predictor__kernel: poly
****** FINISH Best Model: Support Vector  *****

****** START Best Model: Stochastic GD *****
Parameters:
	alpha: (0.1, 0.001, 0.0001)
	tol: (0.0001, 1e-07)
Fitting 5 folds for each of 6 candidates, totalling 30 fits
Best Parameters:
	predictor__alpha: 0.1
	predictor__tol: 0.0001
****** FINISH Best Model: Stochastic GD  *****

</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="68" data-colab="{&quot;height&quot;:237,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="R7SQrYgHthTF" data-outputId="05676981-3a2f-40c1-c050-20dfe25720cd">
<div class="sourceCode" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<div class="output execute_result" data-execution_count="68">

  <div id="df-3ff45490-af63-4c97-adb9-dd209753ddd7">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Expname</th>
      <th>Train accuracy</th>
      <th>Test Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Baseline</td>
      <td>54.0</td>
      <td>55.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Best Model:Logistic Regression</td>
      <td>56.9</td>
      <td>53.3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Best Model:K-Nearest Neighbors</td>
      <td>53.0</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Best Model:Naive Bayes</td>
      <td>54.0</td>
      <td>55.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Best Model:Support Vector</td>
      <td>56.1</td>
      <td>52.9</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Best Model:Stochastic GD</td>
      <td>52.9</td>
      <td>57.9</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-3ff45490-af63-4c97-adb9-dd209753ddd7')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-3ff45490-af63-4c97-adb9-dd209753ddd7 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-3ff45490-af63-4c97-adb9-dd209753ddd7');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<section id="results--discussion" class="cell markdown" id="wAFAXE6wKqIy">
<h1>Results / Discussion</h1>
</section>
<div class="cell markdown" id="rV15sPwGKqIy">
<p>Cats and Dogs Classification is a popular ML problem, which can be solved using various techniques. We performed algorithms like logistic regression, KNN, Naive Baye’s, Support Vector, Stochastic Gradient Descent, to find out how well these algorithms can predict class for the cat and dog image set.</p>
<ul>
<li>Among all the models Gradient Descent proved to be better, with accuracy of 57.9 and the runner up is KNN.</li>
<li>We have also implemented Baseline linear regression along with Baseline LR with Lasso and Ridge(with alpha and best parameters). Lasso and Ridge metrics performed better.</li>
</ul>
</div>
<section id="challenges-" class="cell markdown" id="4prSe22SthTF">
<h1>Challenges :</h1>
<p>The main challenges was to work with a huge dataset. Hence we decreased image size from 128x128 to 32x32.</p>
</section>
<section id="conclusion" class="cell markdown" id="NSMGGEQpKqIy">
<h1>Conclusion</h1>
</section>
<div class="cell markdown" id="9sL2DDOzKqIy">
<p>In phase 1, we have focused on the SKLearn Baseline models for logistic regression, SGDClassifier to classify the images into cats and dogs and Linear regression for making the bounding boxes around the cats and dogs inside the image. Well, Test Accuracy alone can’t tell how good an algorithm predicts the classes in general on various data set. We hope to experiment more by implementing homegrown logistic regression model and CNN in the next phase.</p>
</div>
<section id="phase-2" class="cell markdown" id="_DSH8bwCdd8N">
<h1><strong><em>Phase 2</em></strong></h1>
</section>
<section id="homegrown-implementation" class="cell markdown" id="wm9n1D-0T4ze">
<h1>Homegrown implementation</h1>
<p>Implement a Homegrown Logistic Regression model. Extend the loss function from CXE to CXE + MSE, i.e., make it a complex multitask loss function the resulting model predicts the class and bounding box coordinates at the same time.</p>
</section>
<div class="cell code" id="0TMGAaZh06mh">
<div class="sourceCode" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Below lines of code is taken from HW7 and labs</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="69" id="JskMv3lDxcq-">
<div class="sourceCode" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>X_train_r, X_test_r, y_train_r, y_test_r <span class="op">=</span> train_test_split(np.array(temp_image_data), y_bbox, test_size<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>X_train_r, X_valid_r, y_train_r, y_valid_r <span class="op">=</span> train_test_split(X_train_r, y_train_r, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="70" id="BeL1Mq7SxjU2">
<div class="sourceCode" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>X_train_c, X_test_c, y_train_c, y_test_c <span class="op">=</span> train_test_split(np.array(temp_image_data), y_label, test_size<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>X_train_c, X_valid_c, y_train_c, y_valid_c <span class="op">=</span> train_test_split(X_train_c, y_train_c, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">27</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="71" id="9SnCYarGxlLI">
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># scale data for classification</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.<span class="bu">max</span>(X_train_c) <span class="op">&gt;</span> <span class="fl">4.</span>:</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    X_train_c <span class="op">=</span> X_train_c.astype(np.float32) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.<span class="bu">max</span>(X_valid_c) <span class="op">&gt;</span> <span class="fl">4.</span>:</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>    X_valid_c <span class="op">=</span> X_valid_c.astype(np.float32) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>y_train_c<span class="op">=</span>y_train_c.astype(<span class="bu">int</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>y_valid_c<span class="op">=</span>y_valid_c.astype(<span class="bu">int</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="72" id="OtSBz3v6xnMH">
<div class="sourceCode" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># scale data for reg</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.<span class="bu">max</span>(X_train_r) <span class="op">&gt;</span> <span class="fl">4.</span>:</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    X_train_r <span class="op">=</span> X_train_r.astype(np.float32) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.<span class="bu">max</span>(X_valid_r) <span class="op">&gt;</span> <span class="fl">4.</span>:</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    X_valid_r <span class="op">=</span> X_valid_r.astype(np.float32) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>y_train_r<span class="op">=</span>y_train_r.astype(<span class="bu">int</span>)</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>y_valid_r<span class="op">=</span>y_valid_r.astype(<span class="bu">int</span>)</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>main_loss <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>main_loss_1 <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="73" id="K7peepdtxtHf">
<div class="sourceCode" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogisticRegressionHomegrown1(<span class="bu">object</span>):</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a><span class="co">        Constructor for the homgrown Logistic Regression</span></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.coef_ <span class="op">=</span> <span class="va">None</span>       <span class="co"># weight vector</span></span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.intercept_ <span class="op">=</span> <span class="va">None</span>  <span class="co"># bias term</span></span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._theta <span class="op">=</span> <span class="va">None</span>      <span class="co"># augmented weight vector, i.e., bias + weights</span></span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a>                                <span class="co"># this allows to treat all decision variables homogeneously</span></span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.history <span class="op">=</span> {<span class="st">&quot;cxe+mse&quot;</span>: [], </span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;mse&quot;</span>: [], </span>
<span id="cb93-19"><a href="#cb93-19" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;cxe&quot;</span>:[], </span>
<span id="cb93-20"><a href="#cb93-20" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;val_cxe+mse&quot;</span>: [],</span>
<span id="cb93-21"><a href="#cb93-21" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;val_cxe&quot;</span>:[],</span>
<span id="cb93-22"><a href="#cb93-22" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&quot;val_mse&quot;</span>:[]}</span>
<span id="cb93-23"><a href="#cb93-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-24"><a href="#cb93-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _grad(<span class="va">self</span>, X, y):</span>
<span id="cb93-25"><a href="#cb93-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-26"><a href="#cb93-26" aria-hidden="true" tabindex="-1"></a><span class="co">        Calculates the gradient of the Logistic Regression </span></span>
<span id="cb93-27"><a href="#cb93-27" aria-hidden="true" tabindex="-1"></a><span class="co">        objective function</span></span>
<span id="cb93-28"><a href="#cb93-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-29"><a href="#cb93-29" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-30"><a href="#cb93-30" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):    train objects</span></span>
<span id="cb93-31"><a href="#cb93-31" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):    answers for train objects</span></span>
<span id="cb93-32"><a href="#cb93-32" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb93-33"><a href="#cb93-33" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-34"><a href="#cb93-34" aria-hidden="true" tabindex="-1"></a><span class="co">            grad(ndarray): gradient</span></span>
<span id="cb93-35"><a href="#cb93-35" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-36"><a href="#cb93-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># number of training examples</span></span>
<span id="cb93-37"><a href="#cb93-37" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb93-38"><a href="#cb93-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-39"><a href="#cb93-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get scores for each class and example</span></span>
<span id="cb93-40"><a href="#cb93-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2D matrix</span></span>
<span id="cb93-41"><a href="#cb93-41" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb93-42"><a href="#cb93-42" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> np.dot(X.T, scores) <span class="op">/</span> n</span>
<span id="cb93-43"><a href="#cb93-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-44"><a href="#cb93-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> gradient</span>
<span id="cb93-45"><a href="#cb93-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb93-46"><a href="#cb93-46" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _gd(<span class="va">self</span>, X, y, max_iter, alpha, X_val, y_val):</span>
<span id="cb93-47"><a href="#cb93-47" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-48"><a href="#cb93-48" aria-hidden="true" tabindex="-1"></a><span class="co">        Runs Full GD and logs error, weigths, gradient at every step</span></span>
<span id="cb93-49"><a href="#cb93-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-50"><a href="#cb93-50" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-51"><a href="#cb93-51" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      train objects</span></span>
<span id="cb93-52"><a href="#cb93-52" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for train objects</span></span>
<span id="cb93-53"><a href="#cb93-53" aria-hidden="true" tabindex="-1"></a><span class="co">            max_iter(int):   number of weight updates</span></span>
<span id="cb93-54"><a href="#cb93-54" aria-hidden="true" tabindex="-1"></a><span class="co">            alpha(floar):    step size in direction of gradient</span></span>
<span id="cb93-55"><a href="#cb93-55" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb93-56"><a href="#cb93-56" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-57"><a href="#cb93-57" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb93-58"><a href="#cb93-58" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-59"><a href="#cb93-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb93-60"><a href="#cb93-60" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb93-61"><a href="#cb93-61" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> <span class="va">self</span>.score(X, y)</span>
<span id="cb93-62"><a href="#cb93-62" aria-hidden="true" tabindex="-1"></a>            metrics[<span class="st">&quot;cxe+mse&quot;</span>] <span class="op">=</span> metrics[<span class="st">&quot;cxe+mse&quot;</span>]<span class="op">+</span>np.<span class="bu">round</span>(np.mean(main_loss[i]),decimals<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb93-63"><a href="#cb93-63" aria-hidden="true" tabindex="-1"></a>            metrics[<span class="st">&quot;cxe&quot;</span>] <span class="op">=</span>  metrics[<span class="st">&quot;cxe&quot;</span>]<span class="op">+</span>np.<span class="bu">round</span>(np.mean(main_loss[i]),decimals<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb93-64"><a href="#cb93-64" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;Epoch: &quot;</span>,i<span class="op">+</span><span class="dv">1</span>,<span class="st">&quot;- &quot;</span>, metrics)</span>
<span id="cb93-65"><a href="#cb93-65" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.history[<span class="st">&quot;cxe+mse&quot;</span>].append(metrics[<span class="st">&quot;cxe+mse&quot;</span>])</span>
<span id="cb93-66"><a href="#cb93-66" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.history[<span class="st">&quot;cxe&quot;</span>].append(metrics[<span class="st">&quot;cxe&quot;</span>])</span>
<span id="cb93-67"><a href="#cb93-67" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.history[<span class="st">&quot;mse&quot;</span>].append(metrics[<span class="st">&quot;mse&quot;</span>])</span>
<span id="cb93-68"><a href="#cb93-68" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb93-69"><a href="#cb93-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> X_val <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb93-70"><a href="#cb93-70" aria-hidden="true" tabindex="-1"></a>                metrics_val <span class="op">=</span> <span class="va">self</span>.score(X_val, y_val)</span>
<span id="cb93-71"><a href="#cb93-71" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.history[<span class="st">&quot;val_cxe+mse&quot;</span>].append(metrics_val[<span class="st">&quot;cxe+mse&quot;</span>])</span>
<span id="cb93-72"><a href="#cb93-72" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.history[<span class="st">&quot;val_cxe&quot;</span>].append(metrics_val[<span class="st">&quot;cxe&quot;</span>])</span>
<span id="cb93-73"><a href="#cb93-73" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.history[<span class="st">&quot;val_mse&quot;</span>].append(metrics_val[<span class="st">&quot;mse&quot;</span>])</span>
<span id="cb93-74"><a href="#cb93-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-75"><a href="#cb93-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># calculate gradient</span></span>
<span id="cb93-76"><a href="#cb93-76" aria-hidden="true" tabindex="-1"></a>            grad <span class="op">=</span> <span class="va">self</span>._grad(X, y)</span>
<span id="cb93-77"><a href="#cb93-77" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb93-78"><a href="#cb93-78" aria-hidden="true" tabindex="-1"></a>            <span class="co"># do gradient step</span></span>
<span id="cb93-79"><a href="#cb93-79" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._theta <span class="op">-=</span> alpha <span class="op">*</span> grad</span>
<span id="cb93-80"><a href="#cb93-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb93-81"><a href="#cb93-81" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y, max_iter<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.05</span>, val_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb93-82"><a href="#cb93-82" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-83"><a href="#cb93-83" aria-hidden="true" tabindex="-1"></a><span class="co">        Public API to fit Logistic regression model</span></span>
<span id="cb93-84"><a href="#cb93-84" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-85"><a href="#cb93-85" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-86"><a href="#cb93-86" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      train objects</span></span>
<span id="cb93-87"><a href="#cb93-87" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for train objects</span></span>
<span id="cb93-88"><a href="#cb93-88" aria-hidden="true" tabindex="-1"></a><span class="co">            max_iter(int):   number of weight updates</span></span>
<span id="cb93-89"><a href="#cb93-89" aria-hidden="true" tabindex="-1"></a><span class="co">            alpha(floar):    step size in direction of gradient</span></span>
<span id="cb93-90"><a href="#cb93-90" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb93-91"><a href="#cb93-91" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-92"><a href="#cb93-92" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb93-93"><a href="#cb93-93" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-94"><a href="#cb93-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Augment the data with the bias term.</span></span>
<span id="cb93-95"><a href="#cb93-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># So we can treat the the input variables and the bias term homogeneously </span></span>
<span id="cb93-96"><a href="#cb93-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># from a vectorization perspective</span></span>
<span id="cb93-97"><a href="#cb93-97" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> np.c_[np.ones(X.shape[<span class="dv">0</span>]), X]</span>
<span id="cb93-98"><a href="#cb93-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_data <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb93-99"><a href="#cb93-99" aria-hidden="true" tabindex="-1"></a>            X_val, y_val <span class="op">=</span> val_data</span>
<span id="cb93-100"><a href="#cb93-100" aria-hidden="true" tabindex="-1"></a>            X_val <span class="op">=</span> np.c_[np.ones(X_val.shape[<span class="dv">0</span>]), X_val]</span>
<span id="cb93-101"><a href="#cb93-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb93-102"><a href="#cb93-102" aria-hidden="true" tabindex="-1"></a>            X_val <span class="op">=</span> <span class="va">None</span></span>
<span id="cb93-103"><a href="#cb93-103" aria-hidden="true" tabindex="-1"></a>            y_val <span class="op">=</span> <span class="va">None</span></span>
<span id="cb93-104"><a href="#cb93-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize if the first step</span></span>
<span id="cb93-105"><a href="#cb93-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>._theta <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb93-106"><a href="#cb93-106" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._theta <span class="op">=</span> np.random.rand(X.shape[<span class="dv">1</span>], <span class="dv">4</span>)</span>
<span id="cb93-107"><a href="#cb93-107" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-108"><a href="#cb93-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># do full gradient descent</span></span>
<span id="cb93-109"><a href="#cb93-109" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._gd(X, y, max_iter, alpha, X_val, y_val)</span>
<span id="cb93-110"><a href="#cb93-110" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-111"><a href="#cb93-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get final weigths and bias</span></span>
<span id="cb93-112"><a href="#cb93-112" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.intercept_ <span class="op">=</span> <span class="va">self</span>._theta[<span class="dv">0</span>]</span>
<span id="cb93-113"><a href="#cb93-113" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.coef_ <span class="op">=</span> <span class="va">self</span>._theta[<span class="dv">1</span>:]</span>
<span id="cb93-114"><a href="#cb93-114" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-115"><a href="#cb93-115" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> score(<span class="va">self</span>, X, y):</span>
<span id="cb93-116"><a href="#cb93-116" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-117"><a href="#cb93-117" aria-hidden="true" tabindex="-1"></a><span class="co">        Computes logloss and accuracy for (X, y)</span></span>
<span id="cb93-118"><a href="#cb93-118" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-119"><a href="#cb93-119" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-120"><a href="#cb93-120" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb93-121"><a href="#cb93-121" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for objects</span></span>
<span id="cb93-122"><a href="#cb93-122" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb93-123"><a href="#cb93-123" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-124"><a href="#cb93-124" aria-hidden="true" tabindex="-1"></a><span class="co">            metrics(dict):   python dictionary which</span></span>
<span id="cb93-125"><a href="#cb93-125" aria-hidden="true" tabindex="-1"></a><span class="co">                             contains two fields: for accuracy </span></span>
<span id="cb93-126"><a href="#cb93-126" aria-hidden="true" tabindex="-1"></a><span class="co">                             and for objective function</span></span>
<span id="cb93-127"><a href="#cb93-127" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-128"><a href="#cb93-128" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb93-129"><a href="#cb93-129" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {<span class="st">&quot;cxe+mse&quot;</span>: np.<span class="bu">round</span>(mean_squared_error(y, scores),decimals<span class="op">=</span><span class="dv">10</span>), <span class="st">&quot;cxe&quot;</span>: <span class="dv">0</span>,<span class="st">&quot;mse&quot;</span>:np.<span class="bu">round</span>(mean_squared_error(y, scores),decimals<span class="op">=</span><span class="dv">10</span>)}</span>
<span id="cb93-130"><a href="#cb93-130" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-131"><a href="#cb93-131" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> metrics</span>
<span id="cb93-132"><a href="#cb93-132" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb93-133"><a href="#cb93-133" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _predict_raw(<span class="va">self</span>, X):</span>
<span id="cb93-134"><a href="#cb93-134" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-135"><a href="#cb93-135" aria-hidden="true" tabindex="-1"></a><span class="co">        Computes scores for each class and each object in X</span></span>
<span id="cb93-136"><a href="#cb93-136" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-137"><a href="#cb93-137" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-138"><a href="#cb93-138" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb93-139"><a href="#cb93-139" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-140"><a href="#cb93-140" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-141"><a href="#cb93-141" aria-hidden="true" tabindex="-1"></a><span class="co">            scores(ndarray): scores for each class and object</span></span>
<span id="cb93-142"><a href="#cb93-142" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-143"><a href="#cb93-143" aria-hidden="true" tabindex="-1"></a>        <span class="co"># check whether X has appended bias feature or not</span></span>
<span id="cb93-144"><a href="#cb93-144" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>._theta):</span>
<span id="cb93-145"><a href="#cb93-145" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> np.dot(X, <span class="va">self</span>._theta)</span>
<span id="cb93-146"><a href="#cb93-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb93-147"><a href="#cb93-147" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> np.dot(X, <span class="va">self</span>.coef_) <span class="op">+</span> <span class="va">self</span>.intercept_</span>
<span id="cb93-148"><a href="#cb93-148" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> scores</span>
<span id="cb93-149"><a href="#cb93-149" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb93-150"><a href="#cb93-150" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb93-151"><a href="#cb93-151" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb93-152"><a href="#cb93-152" aria-hidden="true" tabindex="-1"></a><span class="co">        Predicts class for each object in X</span></span>
<span id="cb93-153"><a href="#cb93-153" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-154"><a href="#cb93-154" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb93-155"><a href="#cb93-155" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb93-156"><a href="#cb93-156" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb93-157"><a href="#cb93-157" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb93-158"><a href="#cb93-158" aria-hidden="true" tabindex="-1"></a><span class="co">            pred(ndarray):   class for each object</span></span>
<span id="cb93-159"><a href="#cb93-159" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb93-160"><a href="#cb93-160" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get scores for each class</span></span>
<span id="cb93-161"><a href="#cb93-161" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb93-162"><a href="#cb93-162" aria-hidden="true" tabindex="-1"></a>        <span class="co"># choose class with maximum score</span></span>
<span id="cb93-163"><a href="#cb93-163" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> np.argmax(scores, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb93-164"><a href="#cb93-164" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pred</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="74" id="xL4jin8qxvyk">
<div class="sourceCode" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LogisticRegressionHomegrown(<span class="bu">object</span>):</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="co">        Constructor for the homgrown Logistic Regression</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.coef_ <span class="op">=</span> <span class="va">None</span>       <span class="co"># weight vector</span></span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.intercept_ <span class="op">=</span> <span class="va">None</span>  <span class="co"># bias term</span></span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._theta <span class="op">=</span> <span class="va">None</span>      <span class="co"># augmented weight vector, i.e., bias + weights</span></span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a>                                <span class="co"># this allows to treat all decision variables homogeneously</span></span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.history <span class="op">=</span> {<span class="st">&quot;cost&quot;</span>: [], </span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;acc&quot;</span>: [], </span>
<span id="cb94-19"><a href="#cb94-19" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;val_cost&quot;</span>:[], </span>
<span id="cb94-20"><a href="#cb94-20" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;val_acc&quot;</span>: []}</span>
<span id="cb94-21"><a href="#cb94-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-22"><a href="#cb94-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _grad(<span class="va">self</span>, X, y):</span>
<span id="cb94-23"><a href="#cb94-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-24"><a href="#cb94-24" aria-hidden="true" tabindex="-1"></a><span class="co">        Calculates the gradient of the Logistic Regression </span></span>
<span id="cb94-25"><a href="#cb94-25" aria-hidden="true" tabindex="-1"></a><span class="co">        objective function</span></span>
<span id="cb94-26"><a href="#cb94-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-27"><a href="#cb94-27" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-28"><a href="#cb94-28" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):    train objects</span></span>
<span id="cb94-29"><a href="#cb94-29" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):    answers for train objects</span></span>
<span id="cb94-30"><a href="#cb94-30" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb94-31"><a href="#cb94-31" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-32"><a href="#cb94-32" aria-hidden="true" tabindex="-1"></a><span class="co">            grad(ndarray): gradient</span></span>
<span id="cb94-33"><a href="#cb94-33" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-34"><a href="#cb94-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># number of training examples</span></span>
<span id="cb94-35"><a href="#cb94-35" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb94-36"><a href="#cb94-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get scores for each class and example</span></span>
<span id="cb94-37"><a href="#cb94-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2D matrix</span></span>
<span id="cb94-38"><a href="#cb94-38" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb94-39"><a href="#cb94-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># transform scores to probabilities</span></span>
<span id="cb94-40"><a href="#cb94-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># softmax</span></span>
<span id="cb94-41"><a href="#cb94-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-42"><a href="#cb94-42" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> <span class="fl">1.0</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>scores))</span>
<span id="cb94-43"><a href="#cb94-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">#probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)</span></span>
<span id="cb94-44"><a href="#cb94-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># error</span></span>
<span id="cb94-45"><a href="#cb94-45" aria-hidden="true" tabindex="-1"></a>        probs[<span class="bu">range</span>(n),y] <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb94-46"><a href="#cb94-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (1/m)*np.dot(X.T, (scores - y))</span></span>
<span id="cb94-47"><a href="#cb94-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># gradient</span></span>
<span id="cb94-48"><a href="#cb94-48" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> np.dot(X.T, probs) <span class="op">/</span> n</span>
<span id="cb94-49"><a href="#cb94-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> gradient</span>
<span id="cb94-50"><a href="#cb94-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb94-51"><a href="#cb94-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _gd(<span class="va">self</span>, X, y, max_iter, alpha, X_val, y_val):</span>
<span id="cb94-52"><a href="#cb94-52" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-53"><a href="#cb94-53" aria-hidden="true" tabindex="-1"></a><span class="co">        Runs Full GD and logs error, weigths, gradient at every step</span></span>
<span id="cb94-54"><a href="#cb94-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-55"><a href="#cb94-55" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-56"><a href="#cb94-56" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      train objects</span></span>
<span id="cb94-57"><a href="#cb94-57" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for train objects</span></span>
<span id="cb94-58"><a href="#cb94-58" aria-hidden="true" tabindex="-1"></a><span class="co">            max_iter(int):   number of weight updates</span></span>
<span id="cb94-59"><a href="#cb94-59" aria-hidden="true" tabindex="-1"></a><span class="co">            alpha(floar):    step size in direction of gradient</span></span>
<span id="cb94-60"><a href="#cb94-60" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb94-61"><a href="#cb94-61" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-62"><a href="#cb94-62" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb94-63"><a href="#cb94-63" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-64"><a href="#cb94-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb94-65"><a href="#cb94-65" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb94-66"><a href="#cb94-66" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> <span class="va">self</span>.score(X, y)</span>
<span id="cb94-67"><a href="#cb94-67" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;Epoch: &quot;</span>,i<span class="op">+</span><span class="dv">1</span>,<span class="st">&quot;- &quot;</span>, metrics)</span>
<span id="cb94-68"><a href="#cb94-68" aria-hidden="true" tabindex="-1"></a>            main_loss[i] <span class="op">=</span> metrics[<span class="st">&quot;cost&quot;</span>]</span>
<span id="cb94-69"><a href="#cb94-69" aria-hidden="true" tabindex="-1"></a>            main_loss_1[i]<span class="op">=</span> metrics[<span class="st">&quot;acc&quot;</span>]</span>
<span id="cb94-70"><a href="#cb94-70" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.history[<span class="st">&quot;cost&quot;</span>].append(metrics[<span class="st">&quot;cost&quot;</span>])</span>
<span id="cb94-71"><a href="#cb94-71" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.history[<span class="st">&quot;acc&quot;</span>].append(metrics[<span class="st">&quot;acc&quot;</span>])</span>
<span id="cb94-72"><a href="#cb94-72" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb94-73"><a href="#cb94-73" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> X_val <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb94-74"><a href="#cb94-74" aria-hidden="true" tabindex="-1"></a>                metrics_val <span class="op">=</span> <span class="va">self</span>.score(X_val, y_val)</span>
<span id="cb94-75"><a href="#cb94-75" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.history[<span class="st">&quot;val_cost&quot;</span>].append(metrics_val[<span class="st">&quot;cost&quot;</span>])</span>
<span id="cb94-76"><a href="#cb94-76" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.history[<span class="st">&quot;val_acc&quot;</span>].append(metrics_val[<span class="st">&quot;acc&quot;</span>])</span>
<span id="cb94-77"><a href="#cb94-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-78"><a href="#cb94-78" aria-hidden="true" tabindex="-1"></a>            <span class="co"># calculate gradient</span></span>
<span id="cb94-79"><a href="#cb94-79" aria-hidden="true" tabindex="-1"></a>            grad <span class="op">=</span> <span class="va">self</span>._grad(X, y)</span>
<span id="cb94-80"><a href="#cb94-80" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb94-81"><a href="#cb94-81" aria-hidden="true" tabindex="-1"></a>            <span class="co"># do gradient step</span></span>
<span id="cb94-82"><a href="#cb94-82" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._theta <span class="op">-=</span> alpha <span class="op">*</span> grad</span>
<span id="cb94-83"><a href="#cb94-83" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="bu">len</span>(main_loss))</span>
<span id="cb94-84"><a href="#cb94-84" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb94-85"><a href="#cb94-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y, max_iter<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.05</span>, val_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb94-86"><a href="#cb94-86" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-87"><a href="#cb94-87" aria-hidden="true" tabindex="-1"></a><span class="co">        Public API to fit Logistic regression model</span></span>
<span id="cb94-88"><a href="#cb94-88" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-89"><a href="#cb94-89" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-90"><a href="#cb94-90" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      train objects</span></span>
<span id="cb94-91"><a href="#cb94-91" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for train objects</span></span>
<span id="cb94-92"><a href="#cb94-92" aria-hidden="true" tabindex="-1"></a><span class="co">            max_iter(int):   number of weight updates</span></span>
<span id="cb94-93"><a href="#cb94-93" aria-hidden="true" tabindex="-1"></a><span class="co">            alpha(floar):    step size in direction of gradient</span></span>
<span id="cb94-94"><a href="#cb94-94" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb94-95"><a href="#cb94-95" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-96"><a href="#cb94-96" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb94-97"><a href="#cb94-97" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-98"><a href="#cb94-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Augment the data with the bias term.</span></span>
<span id="cb94-99"><a href="#cb94-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># So we can treat the the input variables and the bias term homogeneously </span></span>
<span id="cb94-100"><a href="#cb94-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># from a vectorization perspective</span></span>
<span id="cb94-101"><a href="#cb94-101" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> np.c_[np.ones(X.shape[<span class="dv">0</span>]), X]</span>
<span id="cb94-102"><a href="#cb94-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_data <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb94-103"><a href="#cb94-103" aria-hidden="true" tabindex="-1"></a>            X_val, y_val <span class="op">=</span> val_data</span>
<span id="cb94-104"><a href="#cb94-104" aria-hidden="true" tabindex="-1"></a>            X_val <span class="op">=</span> np.c_[np.ones(X_val.shape[<span class="dv">0</span>]), X_val]</span>
<span id="cb94-105"><a href="#cb94-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb94-106"><a href="#cb94-106" aria-hidden="true" tabindex="-1"></a>            X_val <span class="op">=</span> <span class="va">None</span></span>
<span id="cb94-107"><a href="#cb94-107" aria-hidden="true" tabindex="-1"></a>            y_val <span class="op">=</span> <span class="va">None</span></span>
<span id="cb94-108"><a href="#cb94-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize if the first step</span></span>
<span id="cb94-109"><a href="#cb94-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>._theta <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb94-110"><a href="#cb94-110" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._theta <span class="op">=</span> np.random.rand(X.shape[<span class="dv">1</span>], <span class="bu">len</span>(np.unique(y)))</span>
<span id="cb94-111"><a href="#cb94-111" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-112"><a href="#cb94-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># do full gradient descent</span></span>
<span id="cb94-113"><a href="#cb94-113" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._gd(X, y, max_iter, alpha, X_val, y_val)</span>
<span id="cb94-114"><a href="#cb94-114" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-115"><a href="#cb94-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get final weigths and bias</span></span>
<span id="cb94-116"><a href="#cb94-116" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.intercept_ <span class="op">=</span> <span class="va">self</span>._theta[<span class="dv">0</span>]</span>
<span id="cb94-117"><a href="#cb94-117" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.coef_ <span class="op">=</span> <span class="va">self</span>._theta[<span class="dv">1</span>:]</span>
<span id="cb94-118"><a href="#cb94-118" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-119"><a href="#cb94-119" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> score(<span class="va">self</span>, X, y):</span>
<span id="cb94-120"><a href="#cb94-120" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-121"><a href="#cb94-121" aria-hidden="true" tabindex="-1"></a><span class="co">        Computes logloss and accuracy for (X, y)</span></span>
<span id="cb94-122"><a href="#cb94-122" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-123"><a href="#cb94-123" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-124"><a href="#cb94-124" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb94-125"><a href="#cb94-125" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for objects</span></span>
<span id="cb94-126"><a href="#cb94-126" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb94-127"><a href="#cb94-127" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-128"><a href="#cb94-128" aria-hidden="true" tabindex="-1"></a><span class="co">            metrics(dict):   python dictionary which</span></span>
<span id="cb94-129"><a href="#cb94-129" aria-hidden="true" tabindex="-1"></a><span class="co">                             contains two fields: for accuracy </span></span>
<span id="cb94-130"><a href="#cb94-130" aria-hidden="true" tabindex="-1"></a><span class="co">                             and for objective function</span></span>
<span id="cb94-131"><a href="#cb94-131" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-132"><a href="#cb94-132" aria-hidden="true" tabindex="-1"></a>        <span class="co"># number of training samples</span></span>
<span id="cb94-133"><a href="#cb94-133" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb94-134"><a href="#cb94-134" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {}</span>
<span id="cb94-135"><a href="#cb94-135" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-136"><a href="#cb94-136" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get scores</span></span>
<span id="cb94-137"><a href="#cb94-137" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb94-138"><a href="#cb94-138" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-139"><a href="#cb94-139" aria-hidden="true" tabindex="-1"></a>        <span class="co"># trasnform scores to probabilities</span></span>
<span id="cb94-140"><a href="#cb94-140" aria-hidden="true" tabindex="-1"></a>        exp_scores <span class="op">=</span> np.exp(scores)</span>
<span id="cb94-141"><a href="#cb94-141" aria-hidden="true" tabindex="-1"></a>        exp <span class="op">=</span> <span class="fl">2.73</span></span>
<span id="cb94-142"><a href="#cb94-142" aria-hidden="true" tabindex="-1"></a>        probs <span class="op">=</span> <span class="fl">1.0</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> exp<span class="op">**</span>(<span class="op">-</span>scores))</span>
<span id="cb94-143"><a href="#cb94-143" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-144"><a href="#cb94-144" aria-hidden="true" tabindex="-1"></a>        <span class="co"># logloss per each example</span></span>
<span id="cb94-145"><a href="#cb94-145" aria-hidden="true" tabindex="-1"></a>        corect_logprobs <span class="op">=</span> probs[<span class="bu">range</span>(n),y]</span>
<span id="cb94-146"><a href="#cb94-146" aria-hidden="true" tabindex="-1"></a><span class="co">#         print(corect_logprobs)</span></span>
<span id="cb94-147"><a href="#cb94-147" aria-hidden="true" tabindex="-1"></a>        <span class="co"># total mean logloss</span></span>
<span id="cb94-148"><a href="#cb94-148" aria-hidden="true" tabindex="-1"></a>        data_loss <span class="op">=</span> np.<span class="bu">sum</span>(corect_logprobs) <span class="op">/</span> n</span>
<span id="cb94-149"><a href="#cb94-149" aria-hidden="true" tabindex="-1"></a>        <span class="co"># predictions</span></span>
<span id="cb94-150"><a href="#cb94-150" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> np.argmax(scores, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb94-151"><a href="#cb94-151" aria-hidden="true" tabindex="-1"></a>        <span class="co"># accuracy</span></span>
<span id="cb94-152"><a href="#cb94-152" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> accuracy_score(y, pred)</span>
<span id="cb94-153"><a href="#cb94-153" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb94-154"><a href="#cb94-154" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> each <span class="kw">in</span> corect_logprobs:</span>
<span id="cb94-155"><a href="#cb94-155" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (each<span class="op">!=</span><span class="dv">1</span> <span class="kw">and</span> each<span class="op">!=</span><span class="dv">0</span>):</span>
<span id="cb94-156"><a href="#cb94-156" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">+=</span>y <span class="op">*</span> (<span class="op">-</span>np.log (each))  <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>y) <span class="op">*</span> (<span class="op">-</span>np.log (<span class="dv">1</span><span class="op">-</span>each))</span>
<span id="cb94-157"><a href="#cb94-157" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-158"><a href="#cb94-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># final metrics</span></span>
<span id="cb94-159"><a href="#cb94-159" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {<span class="st">&quot;acc&quot;</span>: acc, <span class="st">&quot;cost&quot;</span>: np.<span class="bu">round</span>(np.mean(loss),decimals<span class="op">=</span><span class="dv">10</span>)}</span>
<span id="cb94-160"><a href="#cb94-160" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-161"><a href="#cb94-161" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> metrics</span>
<span id="cb94-162"><a href="#cb94-162" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb94-163"><a href="#cb94-163" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _predict_raw(<span class="va">self</span>, X):</span>
<span id="cb94-164"><a href="#cb94-164" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-165"><a href="#cb94-165" aria-hidden="true" tabindex="-1"></a><span class="co">        Computes scores for each class and each object in X</span></span>
<span id="cb94-166"><a href="#cb94-166" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-167"><a href="#cb94-167" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-168"><a href="#cb94-168" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb94-169"><a href="#cb94-169" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-170"><a href="#cb94-170" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-171"><a href="#cb94-171" aria-hidden="true" tabindex="-1"></a><span class="co">            scores(ndarray): scores for each class and object</span></span>
<span id="cb94-172"><a href="#cb94-172" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-173"><a href="#cb94-173" aria-hidden="true" tabindex="-1"></a>        <span class="co"># check whether X has appended bias feature or not</span></span>
<span id="cb94-174"><a href="#cb94-174" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>._theta):</span>
<span id="cb94-175"><a href="#cb94-175" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> np.dot(X, <span class="va">self</span>._theta)</span>
<span id="cb94-176"><a href="#cb94-176" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb94-177"><a href="#cb94-177" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> np.dot(X, <span class="va">self</span>.coef_) <span class="op">+</span> <span class="va">self</span>.intercept_</span>
<span id="cb94-178"><a href="#cb94-178" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> scores</span>
<span id="cb94-179"><a href="#cb94-179" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb94-180"><a href="#cb94-180" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb94-181"><a href="#cb94-181" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb94-182"><a href="#cb94-182" aria-hidden="true" tabindex="-1"></a><span class="co">        Predicts class for each object in X</span></span>
<span id="cb94-183"><a href="#cb94-183" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-184"><a href="#cb94-184" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb94-185"><a href="#cb94-185" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb94-186"><a href="#cb94-186" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb94-187"><a href="#cb94-187" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb94-188"><a href="#cb94-188" aria-hidden="true" tabindex="-1"></a><span class="co">            pred(ndarray):   class for each object</span></span>
<span id="cb94-189"><a href="#cb94-189" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb94-190"><a href="#cb94-190" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get scores for each class</span></span>
<span id="cb94-191"><a href="#cb94-191" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb94-192"><a href="#cb94-192" aria-hidden="true" tabindex="-1"></a>        <span class="co"># choose class with maximum score</span></span>
<span id="cb94-193"><a href="#cb94-193" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> np.argmax(scores, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb94-194"><a href="#cb94-194" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pred</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="75" id="ossbJ_3axwWQ">
<div class="sourceCode" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># reference - HW05 - Basic linear regression from scratch</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearRegressionHomegrown(<span class="bu">object</span>):</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Constructor for the homgrown Linear Regression</span></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.coef_reg <span class="op">=</span> <span class="va">None</span>       <span class="co"># weight vector</span></span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.intercept_reg <span class="op">=</span> <span class="va">None</span>  <span class="co"># bias term</span></span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.thetaReg <span class="op">=</span> <span class="va">None</span>      <span class="co"># augmented weight vector, i.e., bias + weights</span></span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a>                                <span class="co"># this allows to treat all decision variables homogeneously</span></span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.history <span class="op">=</span> {<span class="st">&quot;MSE_train&quot;</span>: [], </span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;Reg_train_MSE&quot;</span>:[],</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;val_MSE&quot;</span>:[], </span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;Reg_val_MSE&quot;</span>:[]}</span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> gradient(<span class="va">self</span>, X, y):</span>
<span id="cb95-28"><a href="#cb95-28" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb95-29"><a href="#cb95-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># total training examples</span></span>
<span id="cb95-30"><a href="#cb95-30" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb95-31"><a href="#cb95-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb95-32"><a href="#cb95-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># scores for each class and examples</span></span>
<span id="cb95-33"><a href="#cb95-33" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> <span class="va">self</span>._predict_raw(X)</span>
<span id="cb95-34"><a href="#cb95-34" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> np.dot(X.T, scores) <span class="op">/</span> n</span>
<span id="cb95-35"><a href="#cb95-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb95-36"><a href="#cb95-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> gradient</span>
<span id="cb95-37"><a href="#cb95-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-38"><a href="#cb95-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> gradientDescent(<span class="va">self</span>, X_r, y_r, max_iter, alpha, X_val_r, y_val_r):</span>
<span id="cb95-39"><a href="#cb95-39" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb95-40"><a href="#cb95-40" aria-hidden="true" tabindex="-1"></a><span class="co">        Runs Full GD and logs error, weigths, gradient at every step</span></span>
<span id="cb95-41"><a href="#cb95-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-42"><a href="#cb95-42" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb95-43"><a href="#cb95-43" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      train objects</span></span>
<span id="cb95-44"><a href="#cb95-44" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for train objects</span></span>
<span id="cb95-45"><a href="#cb95-45" aria-hidden="true" tabindex="-1"></a><span class="co">            max_iter(int):   number of weight updates</span></span>
<span id="cb95-46"><a href="#cb95-46" aria-hidden="true" tabindex="-1"></a><span class="co">            alpha(floar):    step size in direction of gradient</span></span>
<span id="cb95-47"><a href="#cb95-47" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb95-48"><a href="#cb95-48" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb95-49"><a href="#cb95-49" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb95-50"><a href="#cb95-50" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb95-51"><a href="#cb95-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb95-52"><a href="#cb95-52" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb95-53"><a href="#cb95-53" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> <span class="va">self</span>.score(X_r, y_r)</span>
<span id="cb95-54"><a href="#cb95-54" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;Epoch: &quot;</span>,i<span class="op">+</span><span class="dv">1</span>,<span class="st">&quot;- &quot;</span>, metrics)</span>
<span id="cb95-55"><a href="#cb95-55" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.history[<span class="st">&quot;Reg_train_MSE&quot;</span>].append(metrics[<span class="st">&quot;Reg_MSE&quot;</span>])</span>
<span id="cb95-56"><a href="#cb95-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb95-57"><a href="#cb95-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> X_val_r <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb95-58"><a href="#cb95-58" aria-hidden="true" tabindex="-1"></a>                metrics_val <span class="op">=</span> <span class="va">self</span>.score(X_val_r, y_val_r)</span>
<span id="cb95-59"><a href="#cb95-59" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.history[<span class="st">&quot;Reg_val_MSE&quot;</span>].append(metrics_val[<span class="st">&quot;Reg_MSE&quot;</span>])</span>
<span id="cb95-60"><a href="#cb95-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-61"><a href="#cb95-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># calculate gradient for regression</span></span>
<span id="cb95-62"><a href="#cb95-62" aria-hidden="true" tabindex="-1"></a>            gradient <span class="op">=</span> <span class="va">self</span>.gradient(X_r, y_r)</span>
<span id="cb95-63"><a href="#cb95-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-64"><a href="#cb95-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># do gradient descent step</span></span>
<span id="cb95-65"><a href="#cb95-65" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.thetaReg <span class="op">-=</span> alpha <span class="op">*</span> gradient</span>
<span id="cb95-66"><a href="#cb95-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-67"><a href="#cb95-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-68"><a href="#cb95-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X_r,y_r, max_iter<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.05</span>, val_data_r<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb95-69"><a href="#cb95-69" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb95-70"><a href="#cb95-70" aria-hidden="true" tabindex="-1"></a><span class="co">        Public API to fit Logistic regression model</span></span>
<span id="cb95-71"><a href="#cb95-71" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb95-72"><a href="#cb95-72" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      train objects</span></span>
<span id="cb95-73"><a href="#cb95-73" aria-hidden="true" tabindex="-1"></a><span class="co">            y(ndarray):      answers for train objects</span></span>
<span id="cb95-74"><a href="#cb95-74" aria-hidden="true" tabindex="-1"></a><span class="co">            max_iter(int):   number of weight updates</span></span>
<span id="cb95-75"><a href="#cb95-75" aria-hidden="true" tabindex="-1"></a><span class="co">            alpha(floar):    step size in direction of gradient</span></span>
<span id="cb95-76"><a href="#cb95-76" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb95-77"><a href="#cb95-77" aria-hidden="true" tabindex="-1"></a><span class="co">            None</span></span>
<span id="cb95-78"><a href="#cb95-78" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb95-79"><a href="#cb95-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Augment the data with the bias term.</span></span>
<span id="cb95-80"><a href="#cb95-80" aria-hidden="true" tabindex="-1"></a>        <span class="co"># to treat the the input variables and the bias term homogeneously(vectorization perspective)</span></span>
<span id="cb95-81"><a href="#cb95-81" aria-hidden="true" tabindex="-1"></a>        X_r <span class="op">=</span> np.c_[np.ones(X_r.shape[<span class="dv">0</span>]), X_r]</span>
<span id="cb95-82"><a href="#cb95-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_data_r <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb95-83"><a href="#cb95-83" aria-hidden="true" tabindex="-1"></a>            X_val_r, y_val_r <span class="op">=</span> val_data_r</span>
<span id="cb95-84"><a href="#cb95-84" aria-hidden="true" tabindex="-1"></a>            X_val_r <span class="op">=</span> np.c_[np.ones(X_val_r.shape[<span class="dv">0</span>]), X_val_r]</span>
<span id="cb95-85"><a href="#cb95-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb95-86"><a href="#cb95-86" aria-hidden="true" tabindex="-1"></a>            X_val_r <span class="op">=</span> <span class="va">None</span></span>
<span id="cb95-87"><a href="#cb95-87" aria-hidden="true" tabindex="-1"></a>            y_val_r <span class="op">=</span> <span class="va">None</span></span>
<span id="cb95-88"><a href="#cb95-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># initialize weights</span></span>
<span id="cb95-89"><a href="#cb95-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.thetaReg <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb95-90"><a href="#cb95-90" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.thetaReg <span class="op">=</span> np.random.rand(X_r.shape[<span class="dv">1</span>], <span class="dv">4</span>)</span>
<span id="cb95-91"><a href="#cb95-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-92"><a href="#cb95-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># do full gradient descent</span></span>
<span id="cb95-93"><a href="#cb95-93" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gradientDescent(X_r, y_r, max_iter, alpha, X_val_r, y_val_r)</span>
<span id="cb95-94"><a href="#cb95-94" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb95-95"><a href="#cb95-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get final weigths and bias</span></span>
<span id="cb95-96"><a href="#cb95-96" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.intercept_reg <span class="op">=</span> <span class="va">self</span>.thetaReg[<span class="dv">0</span>]</span>
<span id="cb95-97"><a href="#cb95-97" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.coef_reg <span class="op">=</span> <span class="va">self</span>.thetaReg[<span class="dv">1</span>:]</span>
<span id="cb95-98"><a href="#cb95-98" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb95-99"><a href="#cb95-99" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> score(<span class="va">self</span>, X_r, y_r):</span>
<span id="cb95-100"><a href="#cb95-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># number of training samples</span></span>
<span id="cb95-101"><a href="#cb95-101" aria-hidden="true" tabindex="-1"></a>        n1 <span class="op">=</span> X_r.shape[<span class="dv">0</span>]</span>
<span id="cb95-102"><a href="#cb95-102" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get scores</span></span>
<span id="cb95-103"><a href="#cb95-103" aria-hidden="true" tabindex="-1"></a>        scores_r <span class="op">=</span> <span class="va">self</span>._predict_raw(X_r)</span>
<span id="cb95-104"><a href="#cb95-104" aria-hidden="true" tabindex="-1"></a>        pred_r<span class="op">=</span>scores_r</span>
<span id="cb95-105"><a href="#cb95-105" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb95-106"><a href="#cb95-106" aria-hidden="true" tabindex="-1"></a>        metrics <span class="op">=</span> {<span class="st">&quot;Reg_MSE&quot;</span>: np.<span class="bu">round</span>(mean_squared_error(y_r, pred_r),decimals<span class="op">=</span><span class="dv">10</span>)}</span>
<span id="cb95-107"><a href="#cb95-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-108"><a href="#cb95-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> metrics</span>
<span id="cb95-109"><a href="#cb95-109" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb95-110"><a href="#cb95-110" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _predict_raw(<span class="va">self</span>, X):</span>
<span id="cb95-111"><a href="#cb95-111" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb95-112"><a href="#cb95-112" aria-hidden="true" tabindex="-1"></a><span class="co">        Computes scores for each class and each object in X</span></span>
<span id="cb95-113"><a href="#cb95-113" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb95-114"><a href="#cb95-114" aria-hidden="true" tabindex="-1"></a><span class="co">            X(ndarray):      objects</span></span>
<span id="cb95-115"><a href="#cb95-115" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb95-116"><a href="#cb95-116" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb95-117"><a href="#cb95-117" aria-hidden="true" tabindex="-1"></a><span class="co">            scores(ndarray): scores for each class and object</span></span>
<span id="cb95-118"><a href="#cb95-118" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb95-119"><a href="#cb95-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-120"><a href="#cb95-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># append bias feature if not appended already </span></span>
<span id="cb95-121"><a href="#cb95-121" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>.thetaReg):</span>
<span id="cb95-122"><a href="#cb95-122" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> np.dot(X, <span class="va">self</span>.thetaReg)</span>
<span id="cb95-123"><a href="#cb95-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb95-124"><a href="#cb95-124" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> np.dot(X, <span class="va">self</span>.coef_reg) <span class="op">+</span> <span class="va">self</span>.intercept_reg</span>
<span id="cb95-125"><a href="#cb95-125" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb95-126"><a href="#cb95-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> scores</span>
<span id="cb95-127"><a href="#cb95-127" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</div>
<div class="cell code" data-execution_count="76" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="KQ1fpNbVx2Bf" data-outputId="b6675ebd-402d-46a5-8116-f081133be26c">
<div class="sourceCode" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>model_lr_homegrown <span class="op">=</span> LogisticRegressionHomegrown()</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>model_lr_homegrown.fit(X_train_c, y_train_c, max_iter<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.00005</span>,val_data<span class="op">=</span>[X_valid_c,y_valid_c])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch:  1 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7586433006}
Epoch:  2 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7585288479}
Epoch:  3 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7584143951}
Epoch:  4 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7582999423}
Epoch:  5 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7581854895}
Epoch:  6 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7580710368}
Epoch:  7 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.757956584}
Epoch:  8 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7578421312}
Epoch:  9 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7577276785}
Epoch:  10 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7576132257}
Epoch:  11 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.757498773}
Epoch:  12 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7573843202}
Epoch:  13 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7572698675}
Epoch:  14 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7571554147}
Epoch:  15 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.757040962}
Epoch:  16 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7569265092}
Epoch:  17 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7568120565}
Epoch:  18 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7566976038}
Epoch:  19 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.756583151}
Epoch:  20 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7564686983}
Epoch:  21 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7563542456}
Epoch:  22 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7562397928}
Epoch:  23 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7561253401}
Epoch:  24 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7560108874}
Epoch:  25 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7558964347}
Epoch:  26 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7557819819}
Epoch:  27 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7556675292}
Epoch:  28 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7555530765}
Epoch:  29 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7554386238}
Epoch:  30 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7553241711}
Epoch:  31 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7552097184}
Epoch:  32 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7550952657}
Epoch:  33 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.754980813}
Epoch:  34 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7548663603}
Epoch:  35 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7547519076}
Epoch:  36 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7546374549}
Epoch:  37 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7545230022}
Epoch:  38 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7544085495}
Epoch:  39 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7542940968}
Epoch:  40 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7541796442}
Epoch:  41 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7540651915}
Epoch:  42 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7539507388}
Epoch:  43 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7538362861}
Epoch:  44 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7537218335}
Epoch:  45 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7536073808}
Epoch:  46 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7534929281}
Epoch:  47 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7533784755}
Epoch:  48 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7532640228}
Epoch:  49 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7531495701}
Epoch:  50 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7530351175}
Epoch:  51 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7529206648}
Epoch:  52 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7528062122}
Epoch:  53 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7526917595}
Epoch:  54 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7525773069}
Epoch:  55 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7524628542}
Epoch:  56 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7523484016}
Epoch:  57 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7522339489}
Epoch:  58 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7521194963}
Epoch:  59 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7520050437}
Epoch:  60 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.751890591}
Epoch:  61 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7517761384}
Epoch:  62 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7516616858}
Epoch:  63 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7515472332}
Epoch:  64 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7514327805}
Epoch:  65 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7513183279}
Epoch:  66 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7512038753}
Epoch:  67 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7510894227}
Epoch:  68 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7509749701}
Epoch:  69 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7508605175}
Epoch:  70 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7507460649}
Epoch:  71 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7506316123}
Epoch:  72 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7505171596}
Epoch:  73 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.750402707}
Epoch:  74 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7502882545}
Epoch:  75 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7501738019}
Epoch:  76 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7500593493}
Epoch:  77 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7499448967}
Epoch:  78 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7498304441}
Epoch:  79 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7497159915}
Epoch:  80 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7496015389}
Epoch:  81 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7494870863}
Epoch:  82 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7493726338}
Epoch:  83 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7492581812}
Epoch:  84 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7491437286}
Epoch:  85 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7490292761}
Epoch:  86 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7489148235}
Epoch:  87 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7488003709}
Epoch:  88 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7486859184}
Epoch:  89 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7485714658}
Epoch:  90 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7484570132}
Epoch:  91 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7483425607}
Epoch:  92 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7482281081}
Epoch:  93 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7481136556}
Epoch:  94 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.747999203}
Epoch:  95 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7478847505}
Epoch:  96 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.747770298}
Epoch:  97 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7476558454}
Epoch:  98 -  {&#39;acc&#39;: 0.5343663434903048, &#39;cost&#39;: 4.7475413929}
Epoch:  99 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7474269404}
Epoch:  100 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7473124878}
Epoch:  101 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7471980353}
Epoch:  102 -  {&#39;acc&#39;: 0.5343663434903048, &#39;cost&#39;: 4.7470835828}
Epoch:  103 -  {&#39;acc&#39;: 0.5343663434903048, &#39;cost&#39;: 4.7469691302}
Epoch:  104 -  {&#39;acc&#39;: 0.5343663434903048, &#39;cost&#39;: 4.7468546777}
Epoch:  105 -  {&#39;acc&#39;: 0.5343663434903048, &#39;cost&#39;: 4.7467402252}
Epoch:  106 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7466257727}
Epoch:  107 -  {&#39;acc&#39;: 0.5342797783933518, &#39;cost&#39;: 4.7465113202}
Epoch:  108 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7463968677}
Epoch:  109 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7462824152}
Epoch:  110 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7461679626}
Epoch:  111 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7460535101}
Epoch:  112 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7459390576}
Epoch:  113 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7458246051}
Epoch:  114 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7457101526}
Epoch:  115 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7455957002}
Epoch:  116 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7454812477}
Epoch:  117 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7453667952}
Epoch:  118 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7452523427}
Epoch:  119 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7451378902}
Epoch:  120 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7450234377}
Epoch:  121 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7449089853}
Epoch:  122 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7447945328}
Epoch:  123 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7446800803}
Epoch:  124 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7445656278}
Epoch:  125 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7444511754}
Epoch:  126 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7443367229}
Epoch:  127 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7442222704}
Epoch:  128 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.744107818}
Epoch:  129 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7439933655}
Epoch:  130 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7438789131}
Epoch:  131 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7437644606}
Epoch:  132 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7436500082}
Epoch:  133 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7435355557}
Epoch:  134 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7434211033}
Epoch:  135 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7433066508}
Epoch:  136 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7431921984}
Epoch:  137 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.743077746}
Epoch:  138 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7429632935}
Epoch:  139 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7428488411}
Epoch:  140 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7427343887}
Epoch:  141 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7426199362}
Epoch:  142 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7425054838}
Epoch:  143 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7423910314}
Epoch:  144 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.742276579}
Epoch:  145 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7421621266}
Epoch:  146 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7420476741}
Epoch:  147 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7419332217}
Epoch:  148 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7418187693}
Epoch:  149 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7417043169}
Epoch:  150 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7415898645}
Epoch:  151 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7414754121}
Epoch:  152 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7413609597}
Epoch:  153 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7412465073}
Epoch:  154 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7411320549}
Epoch:  155 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7410176025}
Epoch:  156 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7409031502}
Epoch:  157 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7407886978}
Epoch:  158 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7406742454}
Epoch:  159 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.740559793}
Epoch:  160 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7404453406}
Epoch:  161 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7403308883}
Epoch:  162 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7402164359}
Epoch:  163 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7401019835}
Epoch:  164 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7399875311}
Epoch:  165 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7398730788}
Epoch:  166 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7397586264}
Epoch:  167 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7396441741}
Epoch:  168 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7395297217}
Epoch:  169 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7394152694}
Epoch:  170 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.739300817}
Epoch:  171 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7391863647}
Epoch:  172 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7390719123}
Epoch:  173 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.73895746}
Epoch:  174 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7388430076}
Epoch:  175 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7387285553}
Epoch:  176 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7386141029}
Epoch:  177 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7384996506}
Epoch:  178 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7383851983}
Epoch:  179 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.738270746}
Epoch:  180 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7381562936}
Epoch:  181 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7380418413}
Epoch:  182 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.737927389}
Epoch:  183 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7378129367}
Epoch:  184 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7376984844}
Epoch:  185 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.737584032}
Epoch:  186 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7374695797}
Epoch:  187 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7373551274}
Epoch:  188 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7372406751}
Epoch:  189 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7371262228}
Epoch:  190 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7370117705}
Epoch:  191 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7368973182}
Epoch:  192 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7367828659}
Epoch:  193 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7366684136}
Epoch:  194 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7365539613}
Epoch:  195 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7364395091}
Epoch:  196 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7363250568}
Epoch:  197 -  {&#39;acc&#39;: 0.5334141274238227, &#39;cost&#39;: 4.7362106045}
Epoch:  198 -  {&#39;acc&#39;: 0.5334141274238227, &#39;cost&#39;: 4.7360961522}
Epoch:  199 -  {&#39;acc&#39;: 0.5334141274238227, &#39;cost&#39;: 4.7359816999}
Epoch:  200 -  {&#39;acc&#39;: 0.5333275623268698, &#39;cost&#39;: 4.7358672477}
Epoch:  201 -  {&#39;acc&#39;: 0.5333275623268698, &#39;cost&#39;: 4.7357527954}
Epoch:  202 -  {&#39;acc&#39;: 0.5333275623268698, &#39;cost&#39;: 4.7356383431}
Epoch:  203 -  {&#39;acc&#39;: 0.5333275623268698, &#39;cost&#39;: 4.7355238909}
Epoch:  204 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7354094386}
Epoch:  205 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7352949863}
Epoch:  206 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7351805341}
Epoch:  207 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7350660818}
Epoch:  208 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7349516296}
Epoch:  209 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7348371773}
Epoch:  210 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7347227251}
Epoch:  211 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7346082728}
Epoch:  212 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7344938206}
Epoch:  213 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7343793683}
Epoch:  214 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7342649161}
Epoch:  215 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7341504639}
Epoch:  216 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7340360116}
Epoch:  217 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7339215594}
Epoch:  218 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7338071072}
Epoch:  219 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.733692655}
Epoch:  220 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7335782027}
Epoch:  221 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7334637505}
Epoch:  222 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7333492983}
Epoch:  223 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7332348461}
Epoch:  224 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7331203939}
Epoch:  225 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7330059417}
Epoch:  226 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7328914895}
Epoch:  227 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7327770373}
Epoch:  228 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7326625851}
Epoch:  229 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7325481329}
Epoch:  230 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.7324336807}
Epoch:  231 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7323192285}
Epoch:  232 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7322047763}
Epoch:  233 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7320903241}
Epoch:  234 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7319758719}
Epoch:  235 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7318614197}
Epoch:  236 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7317469676}
Epoch:  237 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7316325154}
Epoch:  238 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.7315180632}
Epoch:  239 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.731403611}
Epoch:  240 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7312891589}
Epoch:  241 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.7311747067}
Epoch:  242 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7310602545}
Epoch:  243 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7309458024}
Epoch:  244 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7308313502}
Epoch:  245 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7307168981}
Epoch:  246 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7306024459}
Epoch:  247 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7304879938}
Epoch:  248 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7303735416}
Epoch:  249 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7302590895}
Epoch:  250 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7301446373}
Epoch:  251 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7300301852}
Epoch:  252 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.729915733}
Epoch:  253 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7298012809}
Epoch:  254 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7296868288}
Epoch:  255 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7295723766}
Epoch:  256 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7294579245}
Epoch:  257 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7293434724}
Epoch:  258 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7292290203}
Epoch:  259 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7291145682}
Epoch:  260 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.729000116}
Epoch:  261 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7288856639}
Epoch:  262 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7287712118}
Epoch:  263 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7286567597}
Epoch:  264 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7285423076}
Epoch:  265 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7284278555}
Epoch:  266 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7283134034}
Epoch:  267 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7281989513}
Epoch:  268 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7280844992}
Epoch:  269 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7279700471}
Epoch:  270 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.727855595}
Epoch:  271 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7277411429}
Epoch:  272 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7276266909}
Epoch:  273 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7275122388}
Epoch:  274 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7273977867}
Epoch:  275 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7272833346}
Epoch:  276 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7271688825}
Epoch:  277 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7270544305}
Epoch:  278 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7269399784}
Epoch:  279 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7268255263}
Epoch:  280 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7267110743}
Epoch:  281 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7265966222}
Epoch:  282 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7264821702}
Epoch:  283 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7263677181}
Epoch:  284 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.726253266}
Epoch:  285 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.726138814}
Epoch:  286 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.726024362}
Epoch:  287 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7259099099}
Epoch:  288 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7257954579}
Epoch:  289 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7256810058}
Epoch:  290 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7255665538}
Epoch:  291 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7254521018}
Epoch:  292 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7253376497}
Epoch:  293 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7252231977}
Epoch:  294 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7251087457}
Epoch:  295 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7249942936}
Epoch:  296 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7248798416}
Epoch:  297 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7247653896}
Epoch:  298 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7246509376}
Epoch:  299 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7245364856}
Epoch:  300 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7244220336}
Epoch:  301 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7243075816}
Epoch:  302 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7241931296}
Epoch:  303 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7240786776}
Epoch:  304 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7239642256}
Epoch:  305 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7238497736}
Epoch:  306 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7237353216}
Epoch:  307 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7236208696}
Epoch:  308 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7235064176}
Epoch:  309 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7233919656}
Epoch:  310 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7232775136}
Epoch:  311 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7231630616}
Epoch:  312 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7230486097}
Epoch:  313 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7229341577}
Epoch:  314 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7228197057}
Epoch:  315 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7227052537}
Epoch:  316 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7225908018}
Epoch:  317 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7224763498}
Epoch:  318 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7223618979}
Epoch:  319 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7222474459}
Epoch:  320 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7221329939}
Epoch:  321 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.722018542}
Epoch:  322 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.72190409}
Epoch:  323 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7217896381}
Epoch:  324 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7216751861}
Epoch:  325 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7215607342}
Epoch:  326 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7214462823}
Epoch:  327 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7213318303}
Epoch:  328 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7212173784}
Epoch:  329 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7211029265}
Epoch:  330 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7209884745}
Epoch:  331 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7208740226}
Epoch:  332 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7207595707}
Epoch:  333 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7206451188}
Epoch:  334 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7205306668}
Epoch:  335 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7204162149}
Epoch:  336 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.720301763}
Epoch:  337 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7201873111}
Epoch:  338 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7200728592}
Epoch:  339 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7199584073}
Epoch:  340 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7198439554}
Epoch:  341 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7197295035}
Epoch:  342 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7196150516}
Epoch:  343 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7195005997}
Epoch:  344 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7193861478}
Epoch:  345 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7192716959}
Epoch:  346 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.719157244}
Epoch:  347 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.7190427921}
Epoch:  348 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7189283403}
Epoch:  349 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7188138884}
Epoch:  350 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7186994365}
Epoch:  351 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7185849846}
Epoch:  352 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7184705328}
Epoch:  353 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7183560809}
Epoch:  354 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.718241629}
Epoch:  355 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7181271772}
Epoch:  356 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7180127253}
Epoch:  357 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7178982734}
Epoch:  358 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7177838216}
Epoch:  359 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7176693697}
Epoch:  360 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7175549179}
Epoch:  361 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.717440466}
Epoch:  362 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7173260142}
Epoch:  363 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7172115624}
Epoch:  364 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7170971105}
Epoch:  365 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7169826587}
Epoch:  366 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7168682069}
Epoch:  367 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.716753755}
Epoch:  368 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7166393032}
Epoch:  369 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7165248514}
Epoch:  370 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7164103996}
Epoch:  371 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7162959477}
Epoch:  372 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7161814959}
Epoch:  373 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7160670441}
Epoch:  374 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7159525923}
Epoch:  375 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7158381405}
Epoch:  376 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7157236887}
Epoch:  377 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7156092369}
Epoch:  378 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7154947851}
Epoch:  379 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7153803333}
Epoch:  380 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7152658815}
Epoch:  381 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7151514297}
Epoch:  382 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7150369779}
Epoch:  383 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7149225261}
Epoch:  384 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7148080743}
Epoch:  385 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7146936226}
Epoch:  386 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7145791708}
Epoch:  387 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.714464719}
Epoch:  388 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7143502672}
Epoch:  389 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7142358155}
Epoch:  390 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7141213637}
Epoch:  391 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7140069119}
Epoch:  392 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7138924602}
Epoch:  393 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7137780084}
Epoch:  394 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7136635567}
Epoch:  395 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7135491049}
Epoch:  396 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7134346532}
Epoch:  397 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7133202014}
Epoch:  398 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7132057497}
Epoch:  399 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7130912979}
Epoch:  400 -  {&#39;acc&#39;: 0.5341932132963989, &#39;cost&#39;: 4.7129768462}
Epoch:  401 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7128623944}
Epoch:  402 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7127479427}
Epoch:  403 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.712633491}
Epoch:  404 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7125190393}
Epoch:  405 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7124045875}
Epoch:  406 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7122901358}
Epoch:  407 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7121756841}
Epoch:  408 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7120612324}
Epoch:  409 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7119467807}
Epoch:  410 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7118323289}
Epoch:  411 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7117178772}
Epoch:  412 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7116034255}
Epoch:  413 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7114889738}
Epoch:  414 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7113745221}
Epoch:  415 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7112600704}
Epoch:  416 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7111456187}
Epoch:  417 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.711031167}
Epoch:  418 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7109167153}
Epoch:  419 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7108022637}
Epoch:  420 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.710687812}
Epoch:  421 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7105733603}
Epoch:  422 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7104589086}
Epoch:  423 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7103444569}
Epoch:  424 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7102300053}
Epoch:  425 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7101155536}
Epoch:  426 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7100011019}
Epoch:  427 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7098866503}
Epoch:  428 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7097721986}
Epoch:  429 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7096577469}
Epoch:  430 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7095432953}
Epoch:  431 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7094288436}
Epoch:  432 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.709314392}
Epoch:  433 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7091999403}
Epoch:  434 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7090854887}
Epoch:  435 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.708971037}
Epoch:  436 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7088565854}
Epoch:  437 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7087421338}
Epoch:  438 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7086276821}
Epoch:  439 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7085132305}
Epoch:  440 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7083987789}
Epoch:  441 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7082843272}
Epoch:  442 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7081698756}
Epoch:  443 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.708055424}
Epoch:  444 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7079409724}
Epoch:  445 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7078265207}
Epoch:  446 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7077120691}
Epoch:  447 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7075976175}
Epoch:  448 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7074831659}
Epoch:  449 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7073687143}
Epoch:  450 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7072542627}
Epoch:  451 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7071398111}
Epoch:  452 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7070253595}
Epoch:  453 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7069109079}
Epoch:  454 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7067964563}
Epoch:  455 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7066820047}
Epoch:  456 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7065675532}
Epoch:  457 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7064531016}
Epoch:  458 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.70633865}
Epoch:  459 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7062241984}
Epoch:  460 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7061097468}
Epoch:  461 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7059952953}
Epoch:  462 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7058808437}
Epoch:  463 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7057663921}
Epoch:  464 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7056519406}
Epoch:  465 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.705537489}
Epoch:  466 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7054230375}
Epoch:  467 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7053085859}
Epoch:  468 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7051941344}
Epoch:  469 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7050796828}
Epoch:  470 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7049652313}
Epoch:  471 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7048507797}
Epoch:  472 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7047363282}
Epoch:  473 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7046218766}
Epoch:  474 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7045074251}
Epoch:  475 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7043929736}
Epoch:  476 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.704278522}
Epoch:  477 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7041640705}
Epoch:  478 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.704049619}
Epoch:  479 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7039351675}
Epoch:  480 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7038207159}
Epoch:  481 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7037062644}
Epoch:  482 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7035918129}
Epoch:  483 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7034773614}
Epoch:  484 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7033629099}
Epoch:  485 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7032484584}
Epoch:  486 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7031340069}
Epoch:  487 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7030195554}
Epoch:  488 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7029051039}
Epoch:  489 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7027906524}
Epoch:  490 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7026762009}
Epoch:  491 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.7025617494}
Epoch:  492 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.7024472979}
Epoch:  493 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7023328465}
Epoch:  494 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.702218395}
Epoch:  495 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7021039435}
Epoch:  496 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.701989492}
Epoch:  497 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7018750406}
Epoch:  498 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7017605891}
Epoch:  499 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7016461376}
Epoch:  500 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7015316862}
Epoch:  501 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7014172347}
Epoch:  502 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7013027832}
Epoch:  503 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7011883318}
Epoch:  504 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7010738803}
Epoch:  505 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7009594289}
Epoch:  506 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.7008449774}
Epoch:  507 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.700730526}
Epoch:  508 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7006160746}
Epoch:  509 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7005016231}
Epoch:  510 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7003871717}
Epoch:  511 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7002727203}
Epoch:  512 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7001582688}
Epoch:  513 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.7000438174}
Epoch:  514 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.699929366}
Epoch:  515 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6998149146}
Epoch:  516 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6997004631}
Epoch:  517 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6995860117}
Epoch:  518 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6994715603}
Epoch:  519 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6993571089}
Epoch:  520 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6992426575}
Epoch:  521 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6991282061}
Epoch:  522 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6990137547}
Epoch:  523 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6988993033}
Epoch:  524 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6987848519}
Epoch:  525 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6986704005}
Epoch:  526 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6985559491}
Epoch:  527 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6984414977}
Epoch:  528 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6983270463}
Epoch:  529 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.698212595}
Epoch:  530 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6980981436}
Epoch:  531 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6979836922}
Epoch:  532 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6978692408}
Epoch:  533 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6977547895}
Epoch:  534 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6976403381}
Epoch:  535 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6975258867}
Epoch:  536 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6974114354}
Epoch:  537 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.697296984}
Epoch:  538 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6971825327}
Epoch:  539 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6970680813}
Epoch:  540 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.69695363}
Epoch:  541 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6968391786}
Epoch:  542 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6967247273}
Epoch:  543 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6966102759}
Epoch:  544 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6964958246}
Epoch:  545 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6963813733}
Epoch:  546 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6962669219}
Epoch:  547 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6961524706}
Epoch:  548 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6960380193}
Epoch:  549 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6959235679}
Epoch:  550 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6958091166}
Epoch:  551 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6956946653}
Epoch:  552 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.695580214}
Epoch:  553 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6954657627}
Epoch:  554 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6953513114}
Epoch:  555 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.69523686}
Epoch:  556 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6951224087}
Epoch:  557 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6950079574}
Epoch:  558 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6948935061}
Epoch:  559 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6947790548}
Epoch:  560 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6946646036}
Epoch:  561 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6945501523}
Epoch:  562 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.694435701}
Epoch:  563 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6943212497}
Epoch:  564 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6942067984}
Epoch:  565 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6940923471}
Epoch:  566 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6939778959}
Epoch:  567 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6938634446}
Epoch:  568 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6937489933}
Epoch:  569 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.693634542}
Epoch:  570 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6935200908}
Epoch:  571 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6934056395}
Epoch:  572 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6932911883}
Epoch:  573 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.693176737}
Epoch:  574 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6930622857}
Epoch:  575 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6929478345}
Epoch:  576 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6928333832}
Epoch:  577 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.692718932}
Epoch:  578 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6926044808}
Epoch:  579 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6924900295}
Epoch:  580 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6923755783}
Epoch:  581 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6922611271}
Epoch:  582 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6921466758}
Epoch:  583 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6920322246}
Epoch:  584 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6919177734}
Epoch:  585 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6918033221}
Epoch:  586 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6916888709}
Epoch:  587 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6915744197}
Epoch:  588 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6914599685}
Epoch:  589 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6913455173}
Epoch:  590 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6912310661}
Epoch:  591 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6911166149}
Epoch:  592 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6910021637}
Epoch:  593 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6908877125}
Epoch:  594 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6907732613}
Epoch:  595 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6906588101}
Epoch:  596 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6905443589}
Epoch:  597 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6904299077}
Epoch:  598 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6903154565}
Epoch:  599 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6902010053}
Epoch:  600 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6900865542}
Epoch:  601 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.689972103}
Epoch:  602 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6898576518}
Epoch:  603 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6897432006}
Epoch:  604 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6896287495}
Epoch:  605 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6895142983}
Epoch:  606 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6893998471}
Epoch:  607 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.689285396}
Epoch:  608 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6891709448}
Epoch:  609 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6890564937}
Epoch:  610 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6889420425}
Epoch:  611 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6888275914}
Epoch:  612 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6887131402}
Epoch:  613 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6885986891}
Epoch:  614 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.688484238}
Epoch:  615 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6883697868}
Epoch:  616 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6882553357}
Epoch:  617 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6881408846}
Epoch:  618 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6880264334}
Epoch:  619 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6879119823}
Epoch:  620 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6877975312}
Epoch:  621 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6876830801}
Epoch:  622 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.687568629}
Epoch:  623 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6874541778}
Epoch:  624 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6873397267}
Epoch:  625 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6872252756}
Epoch:  626 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6871108245}
Epoch:  627 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6869963734}
Epoch:  628 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6868819223}
Epoch:  629 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6867674712}
Epoch:  630 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6866530201}
Epoch:  631 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.686538569}
Epoch:  632 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.686424118}
Epoch:  633 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6863096669}
Epoch:  634 -  {&#39;acc&#39;: 0.5335006925207756, &#39;cost&#39;: 4.6861952158}
Epoch:  635 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6860807647}
Epoch:  636 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6859663136}
Epoch:  637 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6858518626}
Epoch:  638 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6857374115}
Epoch:  639 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6856229604}
Epoch:  640 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6855085094}
Epoch:  641 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6853940583}
Epoch:  642 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6852796072}
Epoch:  643 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6851651562}
Epoch:  644 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6850507051}
Epoch:  645 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6849362541}
Epoch:  646 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.684821803}
Epoch:  647 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.684707352}
Epoch:  648 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.684592901}
Epoch:  649 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6844784499}
Epoch:  650 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6843639989}
Epoch:  651 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6842495479}
Epoch:  652 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6841350968}
Epoch:  653 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6840206458}
Epoch:  654 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6839061948}
Epoch:  655 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6837917438}
Epoch:  656 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6836772927}
Epoch:  657 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6835628417}
Epoch:  658 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6834483907}
Epoch:  659 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6833339397}
Epoch:  660 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6832194887}
Epoch:  661 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6831050377}
Epoch:  662 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6829905867}
Epoch:  663 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6828761357}
Epoch:  664 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6827616847}
Epoch:  665 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6826472337}
Epoch:  666 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6825327827}
Epoch:  667 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6824183317}
Epoch:  668 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6823038808}
Epoch:  669 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6821894298}
Epoch:  670 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6820749788}
Epoch:  671 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6819605278}
Epoch:  672 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6818460769}
Epoch:  673 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6817316259}
Epoch:  674 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6816171749}
Epoch:  675 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.681502724}
Epoch:  676 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.681388273}
Epoch:  677 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6812738221}
Epoch:  678 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6811593711}
Epoch:  679 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6810449202}
Epoch:  680 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6809304692}
Epoch:  681 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6808160183}
Epoch:  682 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6807015673}
Epoch:  683 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6805871164}
Epoch:  684 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6804726654}
Epoch:  685 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6803582145}
Epoch:  686 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6802437636}
Epoch:  687 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6801293127}
Epoch:  688 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6800148617}
Epoch:  689 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6799004108}
Epoch:  690 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6797859599}
Epoch:  691 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.679671509}
Epoch:  692 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6795570581}
Epoch:  693 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6794426072}
Epoch:  694 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6793281563}
Epoch:  695 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6792137054}
Epoch:  696 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6790992545}
Epoch:  697 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6789848036}
Epoch:  698 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6788703527}
Epoch:  699 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6787559018}
Epoch:  700 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6786414509}
Epoch:  701 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.678527}
Epoch:  702 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6784125491}
Epoch:  703 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6782980982}
Epoch:  704 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6781836474}
Epoch:  705 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6780691965}
Epoch:  706 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6779547456}
Epoch:  707 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6778402947}
Epoch:  708 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6777258439}
Epoch:  709 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.677611393}
Epoch:  710 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6774969422}
Epoch:  711 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6773824913}
Epoch:  712 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6772680405}
Epoch:  713 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6771535896}
Epoch:  714 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6770391388}
Epoch:  715 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6769246879}
Epoch:  716 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6768102371}
Epoch:  717 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6766957862}
Epoch:  718 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6765813354}
Epoch:  719 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6764668846}
Epoch:  720 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6763524337}
Epoch:  721 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6762379829}
Epoch:  722 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6761235321}
Epoch:  723 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6760090813}
Epoch:  724 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6758946304}
Epoch:  725 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6757801796}
Epoch:  726 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6756657288}
Epoch:  727 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.675551278}
Epoch:  728 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6754368272}
Epoch:  729 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6753223764}
Epoch:  730 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6752079256}
Epoch:  731 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6750934748}
Epoch:  732 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.674979024}
Epoch:  733 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6748645732}
Epoch:  734 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6747501224}
Epoch:  735 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6746356716}
Epoch:  736 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6745212209}
Epoch:  737 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6744067701}
Epoch:  738 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6742923193}
Epoch:  739 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6741778685}
Epoch:  740 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6740634178}
Epoch:  741 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.673948967}
Epoch:  742 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6738345162}
Epoch:  743 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6737200655}
Epoch:  744 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6736056147}
Epoch:  745 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.673491164}
Epoch:  746 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6733767132}
Epoch:  747 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6732622625}
Epoch:  748 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6731478117}
Epoch:  749 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.673033361}
Epoch:  750 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6729189102}
Epoch:  751 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6728044595}
Epoch:  752 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6726900088}
Epoch:  753 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.672575558}
Epoch:  754 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6724611073}
Epoch:  755 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6723466566}
Epoch:  756 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6722322058}
Epoch:  757 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6721177551}
Epoch:  758 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6720033044}
Epoch:  759 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6718888537}
Epoch:  760 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.671774403}
Epoch:  761 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6716599523}
Epoch:  762 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6715455016}
Epoch:  763 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6714310509}
Epoch:  764 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6713166002}
Epoch:  765 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6712021495}
Epoch:  766 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6710876988}
Epoch:  767 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6709732481}
Epoch:  768 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6708587974}
Epoch:  769 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6707443467}
Epoch:  770 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.670629896}
Epoch:  771 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6705154454}
Epoch:  772 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6704009947}
Epoch:  773 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.670286544}
Epoch:  774 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6701720934}
Epoch:  775 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6700576427}
Epoch:  776 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.669943192}
Epoch:  777 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6698287414}
Epoch:  778 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6697142907}
Epoch:  779 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6695998401}
Epoch:  780 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6694853894}
Epoch:  781 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6693709388}
Epoch:  782 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6692564881}
Epoch:  783 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6691420375}
Epoch:  784 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6690275868}
Epoch:  785 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6689131362}
Epoch:  786 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6687986856}
Epoch:  787 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6686842349}
Epoch:  788 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6685697843}
Epoch:  789 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6684553337}
Epoch:  790 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6683408831}
Epoch:  791 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6682264324}
Epoch:  792 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6681119818}
Epoch:  793 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6679975312}
Epoch:  794 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6678830806}
Epoch:  795 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.66776863}
Epoch:  796 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6676541794}
Epoch:  797 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6675397288}
Epoch:  798 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6674252782}
Epoch:  799 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6673108276}
Epoch:  800 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.667196377}
Epoch:  801 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6670819264}
Epoch:  802 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6669674758}
Epoch:  803 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6668530253}
Epoch:  804 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6667385747}
Epoch:  805 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6666241241}
Epoch:  806 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6665096735}
Epoch:  807 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.666395223}
Epoch:  808 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6662807724}
Epoch:  809 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6661663218}
Epoch:  810 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6660518713}
Epoch:  811 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6659374207}
Epoch:  812 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6658229702}
Epoch:  813 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6657085196}
Epoch:  814 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6655940691}
Epoch:  815 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6654796185}
Epoch:  816 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.665365168}
Epoch:  817 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6652507174}
Epoch:  818 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6651362669}
Epoch:  819 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6650218164}
Epoch:  820 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6649073658}
Epoch:  821 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6647929153}
Epoch:  822 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6646784648}
Epoch:  823 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6645640143}
Epoch:  824 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6644495638}
Epoch:  825 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6643351132}
Epoch:  826 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6642206627}
Epoch:  827 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6641062122}
Epoch:  828 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6639917617}
Epoch:  829 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6638773112}
Epoch:  830 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6637628607}
Epoch:  831 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6636484102}
Epoch:  832 -  {&#39;acc&#39;: 0.5335872576177285, &#39;cost&#39;: 4.6635339597}
Epoch:  833 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6634195092}
Epoch:  834 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6633050587}
Epoch:  835 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6631906083}
Epoch:  836 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6630761578}
Epoch:  837 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6629617073}
Epoch:  838 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6628472568}
Epoch:  839 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6627328063}
Epoch:  840 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6626183559}
Epoch:  841 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6625039054}
Epoch:  842 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6623894549}
Epoch:  843 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6622750045}
Epoch:  844 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.662160554}
Epoch:  845 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6620461036}
Epoch:  846 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6619316531}
Epoch:  847 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6618172027}
Epoch:  848 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6617027522}
Epoch:  849 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6615883018}
Epoch:  850 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6614738513}
Epoch:  851 -  {&#39;acc&#39;: 0.5336738227146814, &#39;cost&#39;: 4.6613594009}
Epoch:  852 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6612449505}
Epoch:  853 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6611305001}
Epoch:  854 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6610160496}
Epoch:  855 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6609015992}
Epoch:  856 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6607871488}
Epoch:  857 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6606726984}
Epoch:  858 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6605582479}
Epoch:  859 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6604437975}
Epoch:  860 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6603293471}
Epoch:  861 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6602148967}
Epoch:  862 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6601004463}
Epoch:  863 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6599859959}
Epoch:  864 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6598715455}
Epoch:  865 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6597570951}
Epoch:  866 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6596426447}
Epoch:  867 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6595281944}
Epoch:  868 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.659413744}
Epoch:  869 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6592992936}
Epoch:  870 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6591848432}
Epoch:  871 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6590703928}
Epoch:  872 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6589559425}
Epoch:  873 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6588414921}
Epoch:  874 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6587270417}
Epoch:  875 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6586125914}
Epoch:  876 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.658498141}
Epoch:  877 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6583836907}
Epoch:  878 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6582692403}
Epoch:  879 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6581547899}
Epoch:  880 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6580403396}
Epoch:  881 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6579258893}
Epoch:  882 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6578114389}
Epoch:  883 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6576969886}
Epoch:  884 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6575825382}
Epoch:  885 -  {&#39;acc&#39;: 0.5337603878116344, &#39;cost&#39;: 4.6574680879}
Epoch:  886 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6573536376}
Epoch:  887 -  {&#39;acc&#39;: 0.5338469529085873, &#39;cost&#39;: 4.6572391873}
Epoch:  888 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6571247369}
Epoch:  889 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6570102866}
Epoch:  890 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6568958363}
Epoch:  891 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.656781386}
Epoch:  892 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6566669357}
Epoch:  893 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6565524854}
Epoch:  894 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6564380351}
Epoch:  895 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6563235848}
Epoch:  896 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6562091345}
Epoch:  897 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6560946842}
Epoch:  898 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6559802339}
Epoch:  899 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6558657836}
Epoch:  900 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6557513333}
Epoch:  901 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.655636883}
Epoch:  902 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6555224327}
Epoch:  903 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6554079825}
Epoch:  904 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6552935322}
Epoch:  905 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6551790819}
Epoch:  906 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6550646317}
Epoch:  907 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6549501814}
Epoch:  908 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6548357311}
Epoch:  909 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6547212809}
Epoch:  910 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6546068306}
Epoch:  911 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6544923804}
Epoch:  912 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6543779301}
Epoch:  913 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6542634799}
Epoch:  914 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6541490296}
Epoch:  915 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6540345794}
Epoch:  916 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6539201292}
Epoch:  917 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6538056789}
Epoch:  918 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6536912287}
Epoch:  919 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6535767785}
Epoch:  920 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6534623282}
Epoch:  921 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.653347878}
Epoch:  922 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6532334278}
Epoch:  923 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6531189776}
Epoch:  924 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6530045274}
Epoch:  925 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6528900772}
Epoch:  926 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.652775627}
Epoch:  927 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6526611768}
Epoch:  928 -  {&#39;acc&#39;: 0.5339335180055401, &#39;cost&#39;: 4.6525467266}
Epoch:  929 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6524322764}
Epoch:  930 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6523178262}
Epoch:  931 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.652203376}
Epoch:  932 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6520889258}
Epoch:  933 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6519744756}
Epoch:  934 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6518600254}
Epoch:  935 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6517455753}
Epoch:  936 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6516311251}
Epoch:  937 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6515166749}
Epoch:  938 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6514022247}
Epoch:  939 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6512877746}
Epoch:  940 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6511733244}
Epoch:  941 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6510588743}
Epoch:  942 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6509444241}
Epoch:  943 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.650829974}
Epoch:  944 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6507155238}
Epoch:  945 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6506010737}
Epoch:  946 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6504866235}
Epoch:  947 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6503721734}
Epoch:  948 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6502577232}
Epoch:  949 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6501432731}
Epoch:  950 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.650028823}
Epoch:  951 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6499143729}
Epoch:  952 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6497999227}
Epoch:  953 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6496854726}
Epoch:  954 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6495710225}
Epoch:  955 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6494565724}
Epoch:  956 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6493421223}
Epoch:  957 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6492276722}
Epoch:  958 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6491132221}
Epoch:  959 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6489987719}
Epoch:  960 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6488843218}
Epoch:  961 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6487698718}
Epoch:  962 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6486554217}
Epoch:  963 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6485409716}
Epoch:  964 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6484265215}
Epoch:  965 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6483120714}
Epoch:  966 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6481976213}
Epoch:  967 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6480831712}
Epoch:  968 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6479687212}
Epoch:  969 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6478542711}
Epoch:  970 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.647739821}
Epoch:  971 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.647625371}
Epoch:  972 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6475109209}
Epoch:  973 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6473964708}
Epoch:  974 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6472820208}
Epoch:  975 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6471675707}
Epoch:  976 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6470531207}
Epoch:  977 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6469386706}
Epoch:  978 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6468242206}
Epoch:  979 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6467097706}
Epoch:  980 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6465953205}
Epoch:  981 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6464808705}
Epoch:  982 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6463664205}
Epoch:  983 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6462519704}
Epoch:  984 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6461375204}
Epoch:  985 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6460230704}
Epoch:  986 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6459086204}
Epoch:  987 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6457941704}
Epoch:  988 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6456797204}
Epoch:  989 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6455652703}
Epoch:  990 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6454508203}
Epoch:  991 -  {&#39;acc&#39;: 0.534106648199446, &#39;cost&#39;: 4.6453363703}
Epoch:  992 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6452219203}
Epoch:  993 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6451074703}
Epoch:  994 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6449930204}
Epoch:  995 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6448785704}
Epoch:  996 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6447641204}
Epoch:  997 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6446496704}
Epoch:  998 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6445352204}
Epoch:  999 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6444207704}
Epoch:  1000 -  {&#39;acc&#39;: 0.534020083102493, &#39;cost&#39;: 4.6443063205}
1000
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="77" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="sCx2yGKCLTMx" data-outputId="95e2e43c-6f59-4731-93da-5337e42ce347">
<div class="sourceCode" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>model_lr_homegrown1 <span class="op">=</span> LogisticRegressionHomegrown1()</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>model_lr_homegrown1.fit(X_train_r, y_train_r, max_iter<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.00005</span>,val_data<span class="op">=</span>[X_valid_r,y_valid_r])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch:  1 -  {&#39;cxe+mse&#39;: 460926.7432924732, &#39;cxe&#39;: 4.7586433006, &#39;mse&#39;: 460921.9846491726}
Epoch:  2 -  {&#39;cxe+mse&#39;: 433373.3955321872, &#39;cxe&#39;: 4.7585288479, &#39;mse&#39;: 433368.6370033393}
Epoch:  3 -  {&#39;cxe+mse&#39;: 407467.348403309, &#39;cxe&#39;: 4.7584143951, &#39;mse&#39;: 407462.5899889139}
Epoch:  4 -  {&#39;cxe+mse&#39;: 383110.1165517977, &#39;cxe&#39;: 4.7582999423, &#39;mse&#39;: 383105.3582518554}
Epoch:  5 -  {&#39;cxe+mse&#39;: 360209.1026555773, &#39;cxe&#39;: 4.7581854895, &#39;mse&#39;: 360204.3444700878}
Epoch:  6 -  {&#39;cxe+mse&#39;: 338677.2454035776, &#39;cxe&#39;: 4.7580710368, &#39;mse&#39;: 338672.4873325408}
Epoch:  7 -  {&#39;cxe+mse&#39;: 318432.6885206598, &#39;cxe&#39;: 4.757956584, &#39;mse&#39;: 318427.9305640758}
Epoch:  8 -  {&#39;cxe+mse&#39;: 299398.4695801277, &#39;cxe&#39;: 4.7578421312, &#39;mse&#39;: 299393.7117379965}
Epoch:  9 -  {&#39;cxe+mse&#39;: 281502.22742088384, &#39;cxe&#39;: 4.7577276785, &#39;mse&#39;: 281497.4696932053}
Epoch:  10 -  {&#39;cxe+mse&#39;: 264675.92705686373, &#39;cxe&#39;: 4.7576132257, &#39;mse&#39;: 264671.169443638}
Epoch:  11 -  {&#39;cxe+mse&#39;: 248855.60103300138, &#39;cxe&#39;: 4.757498773, &#39;mse&#39;: 248850.8435342284}
Epoch:  12 -  {&#39;cxe+mse&#39;: 233981.1062444417, &#39;cxe&#39;: 4.7573843202, &#39;mse&#39;: 233976.3488601215}
Epoch:  13 -  {&#39;cxe+mse&#39;: 219995.89529452208, &#39;cxe&#39;: 4.7572698675, &#39;mse&#39;: 219991.1380246546}
Epoch:  14 -  {&#39;cxe+mse&#39;: 206846.8015223039, &#39;cxe&#39;: 4.7571554147, &#39;mse&#39;: 206842.0443668892}
Epoch:  15 -  {&#39;cxe+mse&#39;: 194483.8368824134, &#39;cxe&#39;: 4.757040962, &#39;mse&#39;: 194479.0798414514}
Epoch:  16 -  {&#39;cxe+mse&#39;: 182860.0019088106, &#39;cxe&#39;: 4.7569265092, &#39;mse&#39;: 182855.2449823014}
Epoch:  17 -  {&#39;cxe+mse&#39;: 171931.1070400223, &#39;cxe&#39;: 4.7568120565, &#39;mse&#39;: 171926.3502279658}
Epoch:  18 -  {&#39;cxe+mse&#39;: 161655.6046266061, &#39;cxe&#39;: 4.7566976038, &#39;mse&#39;: 161650.8479290023}
Epoch:  19 -  {&#39;cxe+mse&#39;: 151994.430982183, &#39;cxe&#39;: 4.756583151, &#39;mse&#39;: 151989.674399032}
Epoch:  20 -  {&#39;cxe+mse&#39;: 142910.8578775868, &#39;cxe&#39;: 4.7564686983, &#39;mse&#39;: 142906.1014088885}
Epoch:  21 -  {&#39;cxe+mse&#39;: 134370.3529135486, &#39;cxe&#39;: 4.7563542456, &#39;mse&#39;: 134365.596559303}
Epoch:  22 -  {&#39;cxe+mse&#39;: 126340.448241133, &#39;cxe&#39;: 4.7562397928, &#39;mse&#39;: 126335.6920013402}
Epoch:  23 -  {&#39;cxe+mse&#39;: 118790.61713082001, &#39;cxe&#39;: 4.7561253401, &#39;mse&#39;: 118785.8610054799}
Epoch:  24 -  {&#39;cxe+mse&#39;: 111692.157921018, &#39;cxe&#39;: 4.7560108874, &#39;mse&#39;: 111687.4019101306}
Epoch:  25 -  {&#39;cxe+mse&#39;: 105018.0849048032, &#39;cxe&#39;: 4.7558964347, &#39;mse&#39;: 105013.3290083685}
Epoch:  26 -  {&#39;cxe+mse&#39;: 98743.0257400954, &#39;cxe&#39;: 4.7557819819, &#39;mse&#39;: 98738.2699581135}
Epoch:  27 -  {&#39;cxe+mse&#39;: 92843.1249932477, &#39;cxe&#39;: 4.7556675292, &#39;mse&#39;: 92838.3693257185}
Epoch:  28 -  {&#39;cxe+mse&#39;: 87295.95344936459, &#39;cxe&#39;: 4.7555530765, &#39;mse&#39;: 87291.1978962881}
Epoch:  29 -  {&#39;cxe+mse&#39;: 82080.4228445813, &#39;cxe&#39;: 4.7554386238, &#39;mse&#39;: 82075.6674059575}
Epoch:  30 -  {&#39;cxe+mse&#39;: 77176.7056961433, &#39;cxe&#39;: 4.7553241711, &#39;mse&#39;: 77171.9503719722}
Epoch:  31 -  {&#39;cxe+mse&#39;: 72566.15992551329, &#39;cxe&#39;: 4.7552097184, &#39;mse&#39;: 72561.4047157949}
Epoch:  32 -  {&#39;cxe+mse&#39;: 68231.2579879509, &#39;cxe&#39;: 4.7550952657, &#39;mse&#39;: 68226.5028926852}
Epoch:  33 -  {&#39;cxe+mse&#39;: 64155.5202391356, &#39;cxe&#39;: 4.754980813, &#39;mse&#39;: 64150.7652583226}
Epoch:  34 -  {&#39;cxe+mse&#39;: 60323.4522855289, &#39;cxe&#39;: 4.7548663603, &#39;mse&#39;: 60318.6974191686}
Epoch:  35 -  {&#39;cxe+mse&#39;: 56720.4860802935, &#39;cxe&#39;: 4.7547519076, &#39;mse&#39;: 56715.7313283859}
Epoch:  36 -  {&#39;cxe+mse&#39;: 53332.924540844295, &#39;cxe&#39;: 4.7546374549, &#39;mse&#39;: 53328.1699033894}
Epoch:  37 -  {&#39;cxe+mse&#39;: 50147.8894774866, &#39;cxe&#39;: 4.7545230022, &#39;mse&#39;: 50143.1349544844}
Epoch:  38 -  {&#39;cxe+mse&#39;: 47153.2726351847, &#39;cxe&#39;: 4.7544085495, &#39;mse&#39;: 47148.5182266352}
Epoch:  39 -  {&#39;cxe+mse&#39;: 44337.6896623397, &#39;cxe&#39;: 4.7542940968, &#39;mse&#39;: 44332.9353682429}
Epoch:  40 -  {&#39;cxe+mse&#39;: 41690.436831582905, &#39;cxe&#39;: 4.7541796442, &#39;mse&#39;: 41685.6826519387}
Epoch:  41 -  {&#39;cxe+mse&#39;: 39201.4503480543, &#39;cxe&#39;: 4.7540651915, &#39;mse&#39;: 39196.6962828628}
Epoch:  42 -  {&#39;cxe+mse&#39;: 36861.268090470396, &#39;cxe&#39;: 4.7539507388, &#39;mse&#39;: 36856.5141397316}
Epoch:  43 -  {&#39;cxe+mse&#39;: 34660.993639532804, &#39;cxe&#39;: 4.7538362861, &#39;mse&#39;: 34656.2398032467}
Epoch:  44 -  {&#39;cxe+mse&#39;: 32592.2624569333, &#39;cxe&#39;: 4.7537218335, &#39;mse&#39;: 32587.5087350998}
Epoch:  45 -  {&#39;cxe+mse&#39;: 30647.210086371702, &#39;cxe&#39;: 4.7536073808, &#39;mse&#39;: 30642.4564789909}
Epoch:  46 -  {&#39;cxe+mse&#39;: 28818.4422557057, &#39;cxe&#39;: 4.7534929281, &#39;mse&#39;: 28813.6887627776}
Epoch:  47 -  {&#39;cxe+mse&#39;: 27099.0067665696, &#39;cxe&#39;: 4.7533784755, &#39;mse&#39;: 27094.2533880941}
Epoch:  48 -  {&#39;cxe+mse&#39;: 25482.3670645943, &#39;cxe&#39;: 4.7532640228, &#39;mse&#39;: 25477.6138005715}
Epoch:  49 -  {&#39;cxe+mse&#39;: 23962.3773897563, &#39;cxe&#39;: 4.7531495701, &#39;mse&#39;: 23957.6242401862}
Epoch:  50 -  {&#39;cxe+mse&#39;: 22533.2594123847, &#39;cxe&#39;: 4.7530351175, &#39;mse&#39;: 22528.5063772672}
Epoch:  51 -  {&#39;cxe+mse&#39;: 21189.5802660017, &#39;cxe&#39;: 4.7529206648, &#39;mse&#39;: 21184.8273453369}
Epoch:  52 -  {&#39;cxe+mse&#39;: 19926.2318934939, &#39;cxe&#39;: 4.7528062122, &#39;mse&#39;: 19921.4790872817}
Epoch:  53 -  {&#39;cxe+mse&#39;: 18738.411628085, &#39;cxe&#39;: 4.7526917595, &#39;mse&#39;: 18733.6589363255}
Epoch:  54 -  {&#39;cxe+mse&#39;: 17621.6039352969, &#39;cxe&#39;: 4.7525773069, &#39;mse&#39;: 17616.85135799}
Epoch:  55 -  {&#39;cxe+mse&#39;: 16571.563246479, &#39;cxe&#39;: 4.7524628542, &#39;mse&#39;: 16566.8107836248}
Epoch:  56 -  {&#39;cxe+mse&#39;: 15584.2978186546, &#39;cxe&#39;: 4.7523484016, &#39;mse&#39;: 15579.545470253}
Epoch:  57 -  {&#39;cxe+mse&#39;: 14656.0545593157, &#39;cxe&#39;: 4.7522339489, &#39;mse&#39;: 14651.3023253668}
Epoch:  58 -  {&#39;cxe+mse&#39;: 13783.3047584849, &#39;cxe&#39;: 4.7521194963, &#39;mse&#39;: 13778.5526389886}
Epoch:  59 -  {&#39;cxe+mse&#39;: 12962.7306737955, &#39;cxe&#39;: 4.7520050437, &#39;mse&#39;: 12957.9786687518}
Epoch:  60 -  {&#39;cxe+mse&#39;: 12191.2129175957, &#39;cxe&#39;: 4.751890591, &#39;mse&#39;: 12186.4610270047}
Epoch:  61 -  {&#39;cxe+mse&#39;: 11465.818598125801, &#39;cxe&#39;: 4.7517761384, &#39;mse&#39;: 11461.0668219874}
Epoch:  62 -  {&#39;cxe+mse&#39;: 10783.790169685499, &#39;cxe&#39;: 4.7516616858, &#39;mse&#39;: 10779.0385079997}
Epoch:  63 -  {&#39;cxe+mse&#39;: 10142.5349494033, &#39;cxe&#39;: 4.7515472332, &#39;mse&#39;: 10137.7834021701}
Epoch:  64 -  {&#39;cxe+mse&#39;: 9539.6152607559, &#39;cxe&#39;: 4.7514327805, &#39;mse&#39;: 9534.8638279754}
Epoch:  65 -  {&#39;cxe+mse&#39;: 8972.7391663656, &#39;cxe&#39;: 4.7513183279, &#39;mse&#39;: 8967.9878480377}
Epoch:  66 -  {&#39;cxe+mse&#39;: 8439.7517548457, &#39;cxe&#39;: 4.7512038753, &#39;mse&#39;: 8435.0005509704}
Epoch:  67 -  {&#39;cxe+mse&#39;: 7938.6269485692, &#39;cxe&#39;: 4.7510894227, &#39;mse&#39;: 7933.8758591465}
Epoch:  68 -  {&#39;cxe+mse&#39;: 7467.459801218401, &#39;cxe&#39;: 4.7509749701, &#39;mse&#39;: 7462.7088262483}
Epoch:  69 -  {&#39;cxe+mse&#39;: 7024.4592558315, &#39;cxe&#39;: 4.7508605175, &#39;mse&#39;: 7019.708395314}
Epoch:  70 -  {&#39;cxe+mse&#39;: 6607.9413358163, &#39;cxe&#39;: 4.7507460649, &#39;mse&#39;: 6603.1905897514}
Epoch:  71 -  {&#39;cxe+mse&#39;: 6216.3227430449, &#39;cxe&#39;: 4.7506316123, &#39;mse&#39;: 6211.5721114326}
Epoch:  72 -  {&#39;cxe+mse&#39;: 5848.1148386923005, &#39;cxe&#39;: 4.7505171596, &#39;mse&#39;: 5843.3643215327}
Epoch:  73 -  {&#39;cxe+mse&#39;: 5501.9179839367, &#39;cxe&#39;: 4.750402707, &#39;mse&#39;: 5497.1675812297}
Epoch:  74 -  {&#39;cxe+mse&#39;: 5176.416219005, &#39;cxe&#39;: 4.7502882545, &#39;mse&#39;: 5171.6659307505}
Epoch:  75 -  {&#39;cxe+mse&#39;: 4870.3722603364, &#39;cxe&#39;: 4.7501738019, &#39;mse&#39;: 4865.6220865345}
Epoch:  76 -  {&#39;cxe+mse&#39;: 4582.622796846899, &#39;cxe&#39;: 4.7500593493, &#39;mse&#39;: 4577.8727374976}
Epoch:  77 -  {&#39;cxe+mse&#39;: 4312.0740674088, &#39;cxe&#39;: 4.7499448967, &#39;mse&#39;: 4307.3241225121}
Epoch:  78 -  {&#39;cxe+mse&#39;: 4057.697702736, &#39;cxe&#39;: 4.7498304441, &#39;mse&#39;: 4052.9478722919}
Epoch:  79 -  {&#39;cxe+mse&#39;: 3818.5268158653003, &#39;cxe&#39;: 4.7497159915, &#39;mse&#39;: 3813.7770998738}
Epoch:  80 -  {&#39;cxe+mse&#39;: 3593.6523263725003, &#39;cxe&#39;: 4.7496015389, &#39;mse&#39;: 3588.9027248336}
Epoch:  81 -  {&#39;cxe+mse&#39;: 3382.2195043481, &#39;cxe&#39;: 4.7494870863, &#39;mse&#39;: 3377.4700172618}
Epoch:  82 -  {&#39;cxe+mse&#39;: 3183.4247209951, &#39;cxe&#39;: 4.7493726338, &#39;mse&#39;: 3178.6753483613}
Epoch:  83 -  {&#39;cxe+mse&#39;: 2996.5123934946996, &#39;cxe&#39;: 4.7492581812, &#39;mse&#39;: 2991.7631353135}
Epoch:  84 -  {&#39;cxe+mse&#39;: 2820.7721125271, &#39;cxe&#39;: 4.7491437286, &#39;mse&#39;: 2816.0229687985}
Epoch:  85 -  {&#39;cxe+mse&#39;: 2655.5359415253997, &#39;cxe&#39;: 4.7490292761, &#39;mse&#39;: 2650.7869122493}
Epoch:  86 -  {&#39;cxe+mse&#39;: 2500.1758773957, &#39;cxe&#39;: 4.7489148235, &#39;mse&#39;: 2495.4269625722}
Epoch:  87 -  {&#39;cxe+mse&#39;: 2354.1014630524, &#39;cxe&#39;: 4.7488003709, &#39;mse&#39;: 2349.3526626815}
Epoch:  88 -  {&#39;cxe+mse&#39;: 2216.7575426878, &#39;cxe&#39;: 4.7486859184, &#39;mse&#39;: 2212.0088567694}
Epoch:  89 -  {&#39;cxe+mse&#39;: 2087.6221512469, &#39;cxe&#39;: 4.7485714658, &#39;mse&#39;: 2082.8735797811}
Epoch:  90 -  {&#39;cxe+mse&#39;: 1966.2045300816, &#39;cxe&#39;: 4.7484570132, &#39;mse&#39;: 1961.4560730684}
Epoch:  91 -  {&#39;cxe+mse&#39;: 1852.0432612406, &#39;cxe&#39;: 4.7483425607, &#39;mse&#39;: 1847.2949186799}
Epoch:  92 -  {&#39;cxe+mse&#39;: 1744.7045133021, &#39;cxe&#39;: 4.7482281081, &#39;mse&#39;: 1739.956285194}
Epoch:  93 -  {&#39;cxe+mse&#39;: 1643.780392083, &#39;cxe&#39;: 4.7481136556, &#39;mse&#39;: 1639.0322784274}
Epoch:  94 -  {&#39;cxe+mse&#39;: 1548.8873899501, &#39;cxe&#39;: 4.747999203, &#39;mse&#39;: 1544.1393907471}
Epoch:  95 -  {&#39;cxe+mse&#39;: 1459.6649278428, &#39;cxe&#39;: 4.7478847505, &#39;mse&#39;: 1454.9170430923}
Epoch:  96 -  {&#39;cxe+mse&#39;: 1375.7739844613, &#39;cxe&#39;: 4.747770298, &#39;mse&#39;: 1371.0262141633}
Epoch:  97 -  {&#39;cxe+mse&#39;: 1296.8958074101, &#39;cxe&#39;: 4.7476558454, &#39;mse&#39;: 1292.1481515647}
Epoch:  98 -  {&#39;cxe+mse&#39;: 1222.7307013982002, &#39;cxe&#39;: 4.7475413929, &#39;mse&#39;: 1217.9831600053}
Epoch:  99 -  {&#39;cxe+mse&#39;: 1152.9968888867, &#39;cxe&#39;: 4.7474269404, &#39;mse&#39;: 1148.2494619463}
Epoch:  100 -  {&#39;cxe+mse&#39;: 1087.4294388539, &#39;cxe&#39;: 4.7473124878, &#39;mse&#39;: 1082.6821263661}
Epoch:  101 -  {&#39;cxe+mse&#39;: 1025.7792596068, &#39;cxe&#39;: 4.7471980353, &#39;mse&#39;: 1021.0320615715}
Epoch:  102 -  {&#39;cxe+mse&#39;: 967.8121518057, &#39;cxe&#39;: 4.7470835828, &#39;mse&#39;: 963.0650682229}
Epoch:  103 -  {&#39;cxe+mse&#39;: 913.3079181074, &#39;cxe&#39;: 4.7469691302, &#39;mse&#39;: 908.5609489772}
Epoch:  104 -  {&#39;cxe+mse&#39;: 862.0595260375, &#39;cxe&#39;: 4.7468546777, &#39;mse&#39;: 857.3126713598}
Epoch:  105 -  {&#39;cxe+mse&#39;: 813.8723209123, &#39;cxe&#39;: 4.7467402252, &#39;mse&#39;: 809.1255806871}
Epoch:  106 -  {&#39;cxe+mse&#39;: 768.563285816, &#39;cxe&#39;: 4.7466257727, &#39;mse&#39;: 763.8166600433}
Epoch:  107 -  {&#39;cxe+mse&#39;: 725.9603458222, &#39;cxe&#39;: 4.7465113202, &#39;mse&#39;: 721.213834502}
Epoch:  108 -  {&#39;cxe+mse&#39;: 685.9017138119, &#39;cxe&#39;: 4.7463968677, &#39;mse&#39;: 681.1553169442}
Epoch:  109 -  {&#39;cxe+mse&#39;: 648.2352754039, &#39;cxe&#39;: 4.7462824152, &#39;mse&#39;: 643.4889929887}
Epoch:  110 -  {&#39;cxe+mse&#39;: 612.8180106562, &#39;cxe&#39;: 4.7461679626, &#39;mse&#39;: 608.0718426936}
Epoch:  111 -  {&#39;cxe+mse&#39;: 579.5154503435999, &#39;cxe&#39;: 4.7460535101, &#39;mse&#39;: 574.7693968335}
Epoch:  112 -  {&#39;cxe+mse&#39;: 548.2011647399, &#39;cxe&#39;: 4.7459390576, &#39;mse&#39;: 543.4552256823}
Epoch:  113 -  {&#39;cxe+mse&#39;: 518.7562829663, &#39;cxe&#39;: 4.7458246051, &#39;mse&#39;: 514.0104583612}
Epoch:  114 -  {&#39;cxe+mse&#39;: 491.0690410742, &#39;cxe&#39;: 4.7457101526, &#39;mse&#39;: 486.3233309216}
Epoch:  115 -  {&#39;cxe+mse&#39;: 465.0343571475, &#39;cxe&#39;: 4.7455957002, &#39;mse&#39;: 460.2887614473}
Epoch:  116 -  {&#39;cxe+mse&#39;: 440.5534318071, &#39;cxe&#39;: 4.7454812477, &#39;mse&#39;: 435.8079505594}
Epoch:  117 -  {&#39;cxe+mse&#39;: 417.53337260070003, &#39;cxe&#39;: 4.7453667952, &#39;mse&#39;: 412.7880058055}
Epoch:  118 -  {&#39;cxe+mse&#39;: 395.88684084799996, &#39;cxe&#39;: 4.7452523427, &#39;mse&#39;: 391.1415885053}
Epoch:  119 -  {&#39;cxe+mse&#39;: 375.5317195997, &#39;cxe&#39;: 4.7451378902, &#39;mse&#39;: 370.7865817095}
Epoch:  120 -  {&#39;cxe+mse&#39;: 356.3908014487, &#39;cxe&#39;: 4.7450234377, &#39;mse&#39;: 351.645778011}
Epoch:  121 -  {&#39;cxe+mse&#39;: 338.3914950052, &#39;cxe&#39;: 4.7449089853, &#39;mse&#39;: 333.6465860199}
Epoch:  122 -  {&#39;cxe+mse&#39;: 321.46554892050005, &#39;cxe&#39;: 4.7447945328, &#39;mse&#39;: 316.7207543877}
Epoch:  123 -  {&#39;cxe+mse&#39;: 305.5487924111, &#39;cxe&#39;: 4.7446800803, &#39;mse&#39;: 300.8041123308}
Epoch:  124 -  {&#39;cxe+mse&#39;: 290.5808912954, &#39;cxe&#39;: 4.7445656278, &#39;mse&#39;: 285.8363256676}
Epoch:  125 -  {&#39;cxe+mse&#39;: 276.5051186155, &#39;cxe&#39;: 4.7444511754, &#39;mse&#39;: 271.7606674401}
Epoch:  126 -  {&#39;cxe+mse&#39;: 263.2681389736, &#39;cxe&#39;: 4.7443367229, &#39;mse&#39;: 258.5238022507}
Epoch:  127 -  {&#39;cxe+mse&#39;: 250.81980576200002, &#39;cxe&#39;: 4.7442222704, &#39;mse&#39;: 246.0755834916}
Epoch:  128 -  {&#39;cxe+mse&#39;: 239.11297051510002, &#39;cxe&#39;: 4.744107818, &#39;mse&#39;: 234.3688626971}
Epoch:  129 -  {&#39;cxe+mse&#39;: 228.10330366059998, &#39;cxe&#39;: 4.7439933655, &#39;mse&#39;: 223.3593102951}
Epoch:  130 -  {&#39;cxe+mse&#39;: 217.7491259869, &#39;cxe&#39;: 4.7438789131, &#39;mse&#39;: 213.0052470738}
Epoch:  131 -  {&#39;cxe+mse&#39;: 208.011250186, &#39;cxe&#39;: 4.7437644606, &#39;mse&#39;: 203.2674857254}
Epoch:  132 -  {&#39;cxe+mse&#39;: 198.8528318708, &#39;cxe&#39;: 4.7436500082, &#39;mse&#39;: 194.1091818626}
Epoch:  133 -  {&#39;cxe+mse&#39;: 190.23922949869998, &#39;cxe&#39;: 4.7435355557, &#39;mse&#39;: 185.495693943}
Epoch:  134 -  {&#39;cxe+mse&#39;: 182.13787267109998, &#39;cxe&#39;: 4.7434211033, &#39;mse&#39;: 177.3944515678}
Epoch:  135 -  {&#39;cxe+mse&#39;: 174.51813830470002, &#39;cxe&#39;: 4.7433066508, &#39;mse&#39;: 169.7748316539}
Epoch:  136 -  {&#39;cxe+mse&#39;: 167.3512342086, &#39;cxe&#39;: 4.7431921984, &#39;mse&#39;: 162.6080420102}
Epoch:  137 -  {&#39;cxe+mse&#39;: 160.61008961980002, &#39;cxe&#39;: 4.743077746, &#39;mse&#39;: 155.8670118738}
Epoch:  138 -  {&#39;cxe+mse&#39;: 154.2692522845, &#39;cxe&#39;: 4.7429632935, &#39;mse&#39;: 149.526288991}
Epoch:  139 -  {&#39;cxe+mse&#39;: 148.304791692, &#39;cxe&#39;: 4.7428488411, &#39;mse&#39;: 143.5619428509}
Epoch:  140 -  {&#39;cxe+mse&#39;: 142.6942080938, &#39;cxe&#39;: 4.7427343887, &#39;mse&#39;: 137.9514737051}
Epoch:  141 -  {&#39;cxe+mse&#39;: 137.4163469625, &#39;cxe&#39;: 4.7426199362, &#39;mse&#39;: 132.6737270263}
Epoch:  142 -  {&#39;cxe+mse&#39;: 132.4513185651, &#39;cxe&#39;: 4.7425054838, &#39;mse&#39;: 127.7088130813}
Epoch:  143 -  {&#39;cxe+mse&#39;: 127.7804223435, &#39;cxe&#39;: 4.7423910314, &#39;mse&#39;: 123.0380313121}
Epoch:  144 -  {&#39;cxe+mse&#39;: 123.3860758177, &#39;cxe&#39;: 4.742276579, &#39;mse&#39;: 118.6437992387}
Epoch:  145 -  {&#39;cxe+mse&#39;: 119.2517477383, &#39;cxe&#39;: 4.7421621266, &#39;mse&#39;: 114.5095856117}
Epoch:  146 -  {&#39;cxe+mse&#39;: 115.36189523670001, &#39;cxe&#39;: 4.7420476741, &#39;mse&#39;: 110.6198475626}
Epoch:  147 -  {&#39;cxe+mse&#39;: 111.7019047317, &#39;cxe&#39;: 4.7419332217, &#39;mse&#39;: 106.95997151}
Epoch:  148 -  {&#39;cxe+mse&#39;: 108.2580363701, &#39;cxe&#39;: 4.7418187693, &#39;mse&#39;: 103.5162176008}
Epoch:  149 -  {&#39;cxe+mse&#39;: 105.0173717885, &#39;cxe&#39;: 4.7417043169, &#39;mse&#39;: 100.2756674716}
Epoch:  150 -  {&#39;cxe+mse&#39;: 101.9677649981, &#39;cxe&#39;: 4.7415898645, &#39;mse&#39;: 97.2261751336}
Epoch:  151 -  {&#39;cxe+mse&#39;: 99.0977962069, &#39;cxe&#39;: 4.7414754121, &#39;mse&#39;: 94.3563207948}
Epoch:  152 -  {&#39;cxe+mse&#39;: 96.3967284011, &#39;cxe&#39;: 4.7413609597, &#39;mse&#39;: 91.6553674414}
Epoch:  153 -  {&#39;cxe+mse&#39;: 93.854466524, &#39;cxe&#39;: 4.7412465073, &#39;mse&#39;: 89.1132200167}
Epoch:  154 -  {&#39;cxe+mse&#39;: 91.46151909459999, &#39;cxe&#39;: 4.7411320549, &#39;mse&#39;: 86.7203870397}
Epoch:  155 -  {&#39;cxe+mse&#39;: 89.2089621208, &#39;cxe&#39;: 4.7410176025, &#39;mse&#39;: 84.4679445183}
Epoch:  156 -  {&#39;cxe+mse&#39;: 87.0884051707, &#39;cxe&#39;: 4.7409031502, &#39;mse&#39;: 82.3475020205}
Epoch:  157 -  {&#39;cxe+mse&#39;: 85.0919594716, &#39;cxe&#39;: 4.7407886978, &#39;mse&#39;: 80.3511707738}
Epoch:  158 -  {&#39;cxe+mse&#39;: 83.2122079173, &#39;cxe&#39;: 4.7406742454, &#39;mse&#39;: 78.4715336719}
Epoch:  159 -  {&#39;cxe+mse&#39;: 81.4421768677, &#39;cxe&#39;: 4.740559793, &#39;mse&#39;: 76.7016170747}
Epoch:  160 -  {&#39;cxe+mse&#39;: 79.7753096346, &#39;cxe&#39;: 4.7404453406, &#39;mse&#39;: 75.034864294}
Epoch:  161 -  {&#39;cxe+mse&#39;: 78.20544155329999, &#39;cxe&#39;: 4.7403308883, &#39;mse&#39;: 73.465110665}
Epoch:  162 -  {&#39;cxe+mse&#39;: 76.7267765435, &#39;cxe&#39;: 4.7402164359, &#39;mse&#39;: 71.9865601076}
Epoch:  163 -  {&#39;cxe+mse&#39;: 75.3338650725, &#39;cxe&#39;: 4.7401019835, &#39;mse&#39;: 70.593763089}
Epoch:  164 -  {&#39;cxe+mse&#39;: 74.021583436, &#39;cxe&#39;: 4.7399875311, &#39;mse&#39;: 69.2815959049}
Epoch:  165 -  {&#39;cxe+mse&#39;: 72.78511427640001, &#39;cxe&#39;: 4.7398730788, &#39;mse&#39;: 68.0452411976}
Epoch:  166 -  {&#39;cxe+mse&#39;: 71.6199282673, &#39;cxe&#39;: 4.7397586264, &#39;mse&#39;: 66.8801696409}
Epoch:  167 -  {&#39;cxe+mse&#39;: 70.5217668924, &#39;cxe&#39;: 4.7396441741, &#39;mse&#39;: 65.7821227183}
Epoch:  168 -  {&#39;cxe+mse&#39;: 69.4866262538, &#39;cxe&#39;: 4.7395297217, &#39;mse&#39;: 64.7470965321}
Epoch:  169 -  {&#39;cxe+mse&#39;: 68.5107418489, &#39;cxe&#39;: 4.7394152694, &#39;mse&#39;: 63.7713265795}
Epoch:  170 -  {&#39;cxe+mse&#39;: 67.5905742567, &#39;cxe&#39;: 4.739300817, &#39;mse&#39;: 62.8512734397}
Epoch:  171 -  {&#39;cxe+mse&#39;: 66.7227956811, &#39;cxe&#39;: 4.7391863647, &#39;mse&#39;: 61.9836093164}
Epoch:  172 -  {&#39;cxe+mse&#39;: 65.9042772971, &#39;cxe&#39;: 4.7390719123, &#39;mse&#39;: 61.1652053848}
Epoch:  173 -  {&#39;cxe+mse&#39;: 65.1320773552, &#39;cxe&#39;: 4.73895746, &#39;mse&#39;: 60.3931198952}
Epoch:  174 -  {&#39;cxe+mse&#39;: 64.4034299955, &#39;cxe&#39;: 4.7388430076, &#39;mse&#39;: 59.6645869879}
Epoch:  175 -  {&#39;cxe+mse&#39;: 63.715734732, &#39;cxe&#39;: 4.7387285553, &#39;mse&#39;: 58.9770061767}
Epoch:  176 -  {&#39;cxe+mse&#39;: 63.0665465645, &#39;cxe&#39;: 4.7386141029, &#39;mse&#39;: 58.3279324616}
Epoch:  177 -  {&#39;cxe+mse&#39;: 62.4535666822, &#39;cxe&#39;: 4.7384996506, &#39;mse&#39;: 57.7150670316}
Epoch:  178 -  {&#39;cxe+mse&#39;: 61.8746337233, &#39;cxe&#39;: 4.7383851983, &#39;mse&#39;: 57.136248525}
Epoch:  179 -  {&#39;cxe+mse&#39;: 61.3277155562, &#39;cxe&#39;: 4.738270746, &#39;mse&#39;: 56.5894448102}
Epoch:  180 -  {&#39;cxe+mse&#39;: 60.8109015536, &#39;cxe&#39;: 4.7381562936, &#39;mse&#39;: 56.07274526}
Epoch:  181 -  {&#39;cxe+mse&#39;: 60.3223953273, &#39;cxe&#39;: 4.7380418413, &#39;mse&#39;: 55.584353486}
Epoch:  182 -  {&#39;cxe+mse&#39;: 59.860507897699996, &#39;cxe&#39;: 4.737927389, &#39;mse&#39;: 55.1225805087}
Epoch:  183 -  {&#39;cxe+mse&#39;: 59.423651271900006, &#39;cxe&#39;: 4.7378129367, &#39;mse&#39;: 54.6858383352}
Epoch:  184 -  {&#39;cxe+mse&#39;: 59.010332405599996, &#39;cxe&#39;: 4.7376984844, &#39;mse&#39;: 54.2726339212}
Epoch:  185 -  {&#39;cxe+mse&#39;: 58.619147526, &#39;cxe&#39;: 4.737584032, &#39;mse&#39;: 53.881563494}
Epoch:  186 -  {&#39;cxe+mse&#39;: 58.2487767943, &#39;cxe&#39;: 4.7374695797, &#39;mse&#39;: 53.5113072146}
Epoch:  187 -  {&#39;cxe+mse&#39;: 57.897979286900004, &#39;cxe&#39;: 4.7373551274, &#39;mse&#39;: 53.1606241595}
Epoch:  188 -  {&#39;cxe+mse&#39;: 57.5655882771, &#39;cxe&#39;: 4.7372406751, &#39;mse&#39;: 52.828347602}
Epoch:  189 -  {&#39;cxe+mse&#39;: 57.2505067985, &#39;cxe&#39;: 4.7371262228, &#39;mse&#39;: 52.5133805757}
Epoch:  190 -  {&#39;cxe+mse&#39;: 56.9517034745, &#39;cxe&#39;: 4.7370117705, &#39;mse&#39;: 52.214691704}
Epoch:  191 -  {&#39;cxe+mse&#39;: 56.6682085959, &#39;cxe&#39;: 4.7368973182, &#39;mse&#39;: 51.9313112777}
Epoch:  192 -  {&#39;cxe+mse&#39;: 56.399110433999994, &#39;cxe&#39;: 4.7367828659, &#39;mse&#39;: 51.6623275681}
Epoch:  193 -  {&#39;cxe+mse&#39;: 56.1435517736, &#39;cxe&#39;: 4.7366684136, &#39;mse&#39;: 51.40688336}
Epoch:  194 -  {&#39;cxe+mse&#39;: 55.90072665380001, &#39;cxe&#39;: 4.7365539613, &#39;mse&#39;: 51.1641726925}
Epoch:  195 -  {&#39;cxe+mse&#39;: 55.6698773032, &#39;cxe&#39;: 4.7364395091, &#39;mse&#39;: 50.9334377941}
Epoch:  196 -  {&#39;cxe+mse&#39;: 55.4502912582, &#39;cxe&#39;: 4.7363250568, &#39;mse&#39;: 50.7139662014}
Epoch:  197 -  {&#39;cxe+mse&#39;: 55.241298654400005, &#39;cxe&#39;: 4.7362106045, &#39;mse&#39;: 50.5050880499}
Epoch:  198 -  {&#39;cxe+mse&#39;: 55.0422696792, &#39;cxe&#39;: 4.7360961522, &#39;mse&#39;: 50.306173527}
Epoch:  199 -  {&#39;cxe+mse&#39;: 54.8526121769, &#39;cxe&#39;: 4.7359816999, &#39;mse&#39;: 50.116630477}
Epoch:  200 -  {&#39;cxe+mse&#39;: 54.6717693973, &#39;cxe&#39;: 4.7358672477, &#39;mse&#39;: 49.9359021496}
Epoch:  201 -  {&#39;cxe+mse&#39;: 54.4992178782, &#39;cxe&#39;: 4.7357527954, &#39;mse&#39;: 49.7634650828}
Epoch:  202 -  {&#39;cxe+mse&#39;: 54.3344654553, &#39;cxe&#39;: 4.7356383431, &#39;mse&#39;: 49.5988271122}
Epoch:  203 -  {&#39;cxe+mse&#39;: 54.177049391, &#39;cxe&#39;: 4.7355238909, &#39;mse&#39;: 49.4415255001}
Epoch:  204 -  {&#39;cxe+mse&#39;: 54.026534614, &#39;cxe&#39;: 4.7354094386, &#39;mse&#39;: 49.2911251754}
Epoch:  205 -  {&#39;cxe+mse&#39;: 53.8825120658, &#39;cxe&#39;: 4.7352949863, &#39;mse&#39;: 49.1472170795}
Epoch:  206 -  {&#39;cxe+mse&#39;: 53.744597145200004, &#39;cxe&#39;: 4.7351805341, &#39;mse&#39;: 49.0094166111}
Epoch:  207 -  {&#39;cxe+mse&#39;: 53.6124282449, &#39;cxe&#39;: 4.7350660818, &#39;mse&#39;: 48.8773621631}
Epoch:  208 -  {&#39;cxe+mse&#39;: 53.485665378, &#39;cxe&#39;: 4.7349516296, &#39;mse&#39;: 48.7507137484}
Epoch:  209 -  {&#39;cxe+mse&#39;: 53.3639888839, &#39;cxe&#39;: 4.7348371773, &#39;mse&#39;: 48.6291517066}
Epoch:  210 -  {&#39;cxe+mse&#39;: 53.2470982137, &#39;cxe&#39;: 4.7347227251, &#39;mse&#39;: 48.5123754886}
Epoch:  211 -  {&#39;cxe+mse&#39;: 53.134710787, &#39;cxe&#39;: 4.7346082728, &#39;mse&#39;: 48.4001025142}
Epoch:  212 -  {&#39;cxe+mse&#39;: 53.0265609174, &#39;cxe&#39;: 4.7344938206, &#39;mse&#39;: 48.2920670968}
Epoch:  213 -  {&#39;cxe+mse&#39;: 52.9223988024, &#39;cxe&#39;: 4.7343793683, &#39;mse&#39;: 48.1880194341}
Epoch:  214 -  {&#39;cxe+mse&#39;: 52.8219895738, &#39;cxe&#39;: 4.7342649161, &#39;mse&#39;: 48.0877246577}
Epoch:  215 -  {&#39;cxe+mse&#39;: 52.725112404, &#39;cxe&#39;: 4.7341504639, &#39;mse&#39;: 47.9909619401}
Epoch:  216 -  {&#39;cxe+mse&#39;: 52.631559667, &#39;cxe&#39;: 4.7340360116, &#39;mse&#39;: 47.8975236554}
Epoch:  217 -  {&#39;cxe+mse&#39;: 52.541136148700005, &#39;cxe&#39;: 4.7339215594, &#39;mse&#39;: 47.8072145893}
Epoch:  218 -  {&#39;cxe+mse&#39;: 52.4536583049, &#39;cxe&#39;: 4.7338071072, &#39;mse&#39;: 47.7198511977}
Epoch:  219 -  {&#39;cxe+mse&#39;: 52.368953563, &#39;cxe&#39;: 4.733692655, &#39;mse&#39;: 47.635260908}
Epoch:  220 -  {&#39;cxe+mse&#39;: 52.2868596661, &#39;cxe&#39;: 4.7335782027, &#39;mse&#39;: 47.5532814634}
Epoch:  221 -  {&#39;cxe+mse&#39;: 52.2072240566, &#39;cxe&#39;: 4.7334637505, &#39;mse&#39;: 47.4737603061}
Epoch:  222 -  {&#39;cxe+mse&#39;: 52.1299032953, &#39;cxe&#39;: 4.7333492983, &#39;mse&#39;: 47.396553997}
Epoch:  223 -  {&#39;cxe+mse&#39;: 52.0547625168, &#39;cxe&#39;: 4.7332348461, &#39;mse&#39;: 47.3215276707}
Epoch:  224 -  {&#39;cxe+mse&#39;: 51.9816749163, &#39;cxe&#39;: 4.7331203939, &#39;mse&#39;: 47.2485545224}
Epoch:  225 -  {&#39;cxe+mse&#39;: 51.9105212679, &#39;cxe&#39;: 4.7330059417, &#39;mse&#39;: 47.1775153262}
Epoch:  226 -  {&#39;cxe+mse&#39;: 51.8411894713, &#39;cxe&#39;: 4.7328914895, &#39;mse&#39;: 47.1082979818}
Epoch:  227 -  {&#39;cxe+mse&#39;: 51.773574125500005, &#39;cxe&#39;: 4.7327770373, &#39;mse&#39;: 47.0407970882}
Epoch:  228 -  {&#39;cxe+mse&#39;: 51.7075761282, &#39;cxe&#39;: 4.7326625851, &#39;mse&#39;: 46.9749135431}
Epoch:  229 -  {&#39;cxe+mse&#39;: 51.6431022992, &#39;cxe&#39;: 4.7325481329, &#39;mse&#39;: 46.9105541663}
Epoch:  230 -  {&#39;cxe+mse&#39;: 51.580065026199996, &#39;cxe&#39;: 4.7324336807, &#39;mse&#39;: 46.8476313455}
Epoch:  231 -  {&#39;cxe+mse&#39;: 51.51838193179999, &#39;cxe&#39;: 4.7323192285, &#39;mse&#39;: 46.7860627033}
Epoch:  232 -  {&#39;cxe+mse&#39;: 51.4579755604, &#39;cxe&#39;: 4.7322047763, &#39;mse&#39;: 46.7257707841}
Epoch:  233 -  {&#39;cxe+mse&#39;: 51.3987730839, &#39;cxe&#39;: 4.7320903241, &#39;mse&#39;: 46.6666827598}
Epoch:  234 -  {&#39;cxe+mse&#39;: 51.3407060249, &#39;cxe&#39;: 4.7319758719, &#39;mse&#39;: 46.608730153}
Epoch:  235 -  {&#39;cxe+mse&#39;: 51.283709996400006, &#39;cxe&#39;: 4.7318614197, &#39;mse&#39;: 46.5518485767}
Epoch:  236 -  {&#39;cxe+mse&#39;: 51.2277244574, &#39;cxe&#39;: 4.7317469676, &#39;mse&#39;: 46.4959774898}
Epoch:  237 -  {&#39;cxe+mse&#39;: 51.1726924826, &#39;cxe&#39;: 4.7316325154, &#39;mse&#39;: 46.4410599672}
Epoch:  238 -  {&#39;cxe+mse&#39;: 51.118560546299996, &#39;cxe&#39;: 4.7315180632, &#39;mse&#39;: 46.3870424831}
Epoch:  239 -  {&#39;cxe+mse&#39;: 51.0652783192, &#39;cxe&#39;: 4.731403611, &#39;mse&#39;: 46.3338747082}
Epoch:  240 -  {&#39;cxe+mse&#39;: 51.0127984771, &#39;cxe&#39;: 4.7312891589, &#39;mse&#39;: 46.2815093182}
Epoch:  241 -  {&#39;cxe+mse&#39;: 50.9610765206, &#39;cxe&#39;: 4.7311747067, &#39;mse&#39;: 46.2299018139}
Epoch:  242 -  {&#39;cxe+mse&#39;: 50.9100706074, &#39;cxe&#39;: 4.7310602545, &#39;mse&#39;: 46.1790103529}
Epoch:  243 -  {&#39;cxe+mse&#39;: 50.8597413922, &#39;cxe&#39;: 4.7309458024, &#39;mse&#39;: 46.1287955898}
Epoch:  244 -  {&#39;cxe+mse&#39;: 50.8100518779, &#39;cxe&#39;: 4.7308313502, &#39;mse&#39;: 46.0792205277}
Epoch:  245 -  {&#39;cxe+mse&#39;: 50.7609672752, &#39;cxe&#39;: 4.7307168981, &#39;mse&#39;: 46.0302503771}
Epoch:  246 -  {&#39;cxe+mse&#39;: 50.712454869999995, &#39;cxe&#39;: 4.7306024459, &#39;mse&#39;: 45.9818524241}
Epoch:  247 -  {&#39;cxe+mse&#39;: 50.664483900099995, &#39;cxe&#39;: 4.7304879938, &#39;mse&#39;: 45.9339959063}
Epoch:  248 -  {&#39;cxe+mse&#39;: 50.617025437500004, &#39;cxe&#39;: 4.7303735416, &#39;mse&#39;: 45.8866518959}
Epoch:  249 -  {&#39;cxe+mse&#39;: 50.5700522798, &#39;cxe&#39;: 4.7302590895, &#39;mse&#39;: 45.8397931903}
Epoch:  250 -  {&#39;cxe+mse&#39;: 50.5235388457, &#39;cxe&#39;: 4.7301446373, &#39;mse&#39;: 45.7933942084}
Epoch:  251 -  {&#39;cxe+mse&#39;: 50.4774610793, &#39;cxe&#39;: 4.7300301852, &#39;mse&#39;: 45.7474308941}
Epoch:  252 -  {&#39;cxe+mse&#39;: 50.4317963575, &#39;cxe&#39;: 4.729915733, &#39;mse&#39;: 45.7018806245}
Epoch:  253 -  {&#39;cxe+mse&#39;: 50.3865234059, &#39;cxe&#39;: 4.7298012809, &#39;mse&#39;: 45.656722125}
Epoch:  254 -  {&#39;cxe+mse&#39;: 50.341622216699996, &#39;cxe&#39;: 4.7296868288, &#39;mse&#39;: 45.6119353879}
Epoch:  255 -  {&#39;cxe+mse&#39;: 50.2970739733, &#39;cxe&#39;: 4.7295723766, &#39;mse&#39;: 45.5675015967}
Epoch:  256 -  {&#39;cxe+mse&#39;: 50.25286097990001, &#39;cxe&#39;: 4.7294579245, &#39;mse&#39;: 45.5234030554}
Epoch:  257 -  {&#39;cxe+mse&#39;: 50.2089665931, &#39;cxe&#39;: 4.7293434724, &#39;mse&#39;: 45.4796231207}
Epoch:  258 -  {&#39;cxe+mse&#39;: 50.165375159999996, &#39;cxe&#39;: 4.7292290203, &#39;mse&#39;: 45.4361461397}
Epoch:  259 -  {&#39;cxe+mse&#39;: 50.1220719584, &#39;cxe&#39;: 4.7291145682, &#39;mse&#39;: 45.3929573902}
Epoch:  260 -  {&#39;cxe+mse&#39;: 50.0790431412, &#39;cxe&#39;: 4.729000116, &#39;mse&#39;: 45.3500430252}
Epoch:  261 -  {&#39;cxe+mse&#39;: 50.0362756844, &#39;cxe&#39;: 4.7288856639, &#39;mse&#39;: 45.3073900205}
Epoch:  262 -  {&#39;cxe+mse&#39;: 49.9937573374, &#39;cxe&#39;: 4.7287712118, &#39;mse&#39;: 45.2649861256}
Epoch:  263 -  {&#39;cxe+mse&#39;: 49.9514765767, &#39;cxe&#39;: 4.7286567597, &#39;mse&#39;: 45.222819817}
Epoch:  264 -  {&#39;cxe+mse&#39;: 49.9094225631, &#39;cxe&#39;: 4.7285423076, &#39;mse&#39;: 45.1808802555}
Epoch:  265 -  {&#39;cxe+mse&#39;: 49.8675850997, &#39;cxe&#39;: 4.7284278555, &#39;mse&#39;: 45.1391572442}
Epoch:  266 -  {&#39;cxe+mse&#39;: 49.8259545944, &#39;cxe&#39;: 4.7283134034, &#39;mse&#39;: 45.097641191}
Epoch:  267 -  {&#39;cxe+mse&#39;: 49.7845220234, &#39;cxe&#39;: 4.7281989513, &#39;mse&#39;: 45.0563230721}
Epoch:  268 -  {&#39;cxe+mse&#39;: 49.7432788967, &#39;cxe&#39;: 4.7280844992, &#39;mse&#39;: 45.0151943975}
Epoch:  269 -  {&#39;cxe+mse&#39;: 49.7022172272, &#39;cxe&#39;: 4.7279700471, &#39;mse&#39;: 44.9742471801}
Epoch:  270 -  {&#39;cxe+mse&#39;: 49.6613294996, &#39;cxe&#39;: 4.727855595, &#39;mse&#39;: 44.9334739046}
Epoch:  271 -  {&#39;cxe+mse&#39;: 49.6206086427, &#39;cxe&#39;: 4.7277411429, &#39;mse&#39;: 44.8928674998}
Epoch:  272 -  {&#39;cxe+mse&#39;: 49.5800480029, &#39;cxe&#39;: 4.7276266909, &#39;mse&#39;: 44.852421312}
Epoch:  273 -  {&#39;cxe+mse&#39;: 49.5396413185, &#39;cxe&#39;: 4.7275122388, &#39;mse&#39;: 44.8121290797}
Epoch:  274 -  {&#39;cxe+mse&#39;: 49.4993826975, &#39;cxe&#39;: 4.7273977867, &#39;mse&#39;: 44.7719849108}
Epoch:  275 -  {&#39;cxe+mse&#39;: 49.4592665941, &#39;cxe&#39;: 4.7272833346, &#39;mse&#39;: 44.7319832595}
Epoch:  276 -  {&#39;cxe+mse&#39;: 49.419287789200006, &#39;cxe&#39;: 4.7271688825, &#39;mse&#39;: 44.6921189067}
Epoch:  277 -  {&#39;cxe+mse&#39;: 49.379441369999995, &#39;cxe&#39;: 4.7270544305, &#39;mse&#39;: 44.6523869395}
Epoch:  278 -  {&#39;cxe+mse&#39;: 49.3397227118, &#39;cxe&#39;: 4.7269399784, &#39;mse&#39;: 44.6127827334}
Epoch:  279 -  {&#39;cxe+mse&#39;: 49.3001274612, &#39;cxe&#39;: 4.7268255263, &#39;mse&#39;: 44.5733019349}
Epoch:  280 -  {&#39;cxe+mse&#39;: 49.2606515197, &#39;cxe&#39;: 4.7267110743, &#39;mse&#39;: 44.5339404454}
Epoch:  281 -  {&#39;cxe+mse&#39;: 49.221291027999996, &#39;cxe&#39;: 4.7265966222, &#39;mse&#39;: 44.4946944058}
Epoch:  282 -  {&#39;cxe+mse&#39;: 49.1820423523, &#39;cxe&#39;: 4.7264821702, &#39;mse&#39;: 44.4555601821}
Epoch:  283 -  {&#39;cxe+mse&#39;: 49.1429020702, &#39;cxe&#39;: 4.7263677181, &#39;mse&#39;: 44.4165343521}
Epoch:  284 -  {&#39;cxe+mse&#39;: 49.1038669588, &#39;cxe&#39;: 4.726253266, &#39;mse&#39;: 44.3776136928}
Epoch:  285 -  {&#39;cxe+mse&#39;: 49.0649339822, &#39;cxe&#39;: 4.726138814, &#39;mse&#39;: 44.3387951682}
Epoch:  286 -  {&#39;cxe+mse&#39;: 49.0261002803, &#39;cxe&#39;: 4.726024362, &#39;mse&#39;: 44.3000759183}
Epoch:  287 -  {&#39;cxe+mse&#39;: 48.9873631585, &#39;cxe&#39;: 4.7259099099, &#39;mse&#39;: 44.2614532486}
Epoch:  288 -  {&#39;cxe+mse&#39;: 48.9487200779, &#39;cxe&#39;: 4.7257954579, &#39;mse&#39;: 44.22292462}
Epoch:  289 -  {&#39;cxe+mse&#39;: 48.9101686457, &#39;cxe&#39;: 4.7256810058, &#39;mse&#39;: 44.1844876399}
Epoch:  290 -  {&#39;cxe+mse&#39;: 48.8717066065, &#39;cxe&#39;: 4.7255665538, &#39;mse&#39;: 44.1461400527}
Epoch:  291 -  {&#39;cxe+mse&#39;: 48.8333318344, &#39;cxe&#39;: 4.7254521018, &#39;mse&#39;: 44.1078797326}
Epoch:  292 -  {&#39;cxe+mse&#39;: 48.795042324600004, &#39;cxe&#39;: 4.7253376497, &#39;mse&#39;: 44.0697046749}
Epoch:  293 -  {&#39;cxe+mse&#39;: 48.756836187000005, &#39;cxe&#39;: 4.7252231977, &#39;mse&#39;: 44.0316129893}
Epoch:  294 -  {&#39;cxe+mse&#39;: 48.7187116387, &#39;cxe&#39;: 4.7251087457, &#39;mse&#39;: 43.993602893}
Epoch:  295 -  {&#39;cxe+mse&#39;: 48.6806669977, &#39;cxe&#39;: 4.7249942936, &#39;mse&#39;: 43.9556727041}
Epoch:  296 -  {&#39;cxe+mse&#39;: 48.6427006771, &#39;cxe&#39;: 4.7248798416, &#39;mse&#39;: 43.9178208355}
Epoch:  297 -  {&#39;cxe+mse&#39;: 48.6048111793, &#39;cxe&#39;: 4.7247653896, &#39;mse&#39;: 43.8800457897}
Epoch:  298 -  {&#39;cxe+mse&#39;: 48.566997090499996, &#39;cxe&#39;: 4.7246509376, &#39;mse&#39;: 43.8423461529}
Epoch:  299 -  {&#39;cxe+mse&#39;: 48.529257075699995, &#39;cxe&#39;: 4.7245364856, &#39;mse&#39;: 43.8047205901}
Epoch:  300 -  {&#39;cxe+mse&#39;: 48.4915898744, &#39;cxe&#39;: 4.7244220336, &#39;mse&#39;: 43.7671678408}
Epoch:  301 -  {&#39;cxe+mse&#39;: 48.453994295600005, &#39;cxe&#39;: 4.7243075816, &#39;mse&#39;: 43.729686714}
Epoch:  302 -  {&#39;cxe+mse&#39;: 48.416469214, &#39;cxe&#39;: 4.7241931296, &#39;mse&#39;: 43.6922760844}
Epoch:  303 -  {&#39;cxe+mse&#39;: 48.379013565899996, &#39;cxe&#39;: 4.7240786776, &#39;mse&#39;: 43.6549348883}
Epoch:  304 -  {&#39;cxe+mse&#39;: 48.3416263456, &#39;cxe&#39;: 4.7239642256, &#39;mse&#39;: 43.61766212}
Epoch:  305 -  {&#39;cxe+mse&#39;: 48.3043066019, &#39;cxe&#39;: 4.7238497736, &#39;mse&#39;: 43.5804568283}
Epoch:  306 -  {&#39;cxe+mse&#39;: 48.267053434800005, &#39;cxe&#39;: 4.7237353216, &#39;mse&#39;: 43.5433181132}
Epoch:  307 -  {&#39;cxe+mse&#39;: 48.229865992499995, &#39;cxe&#39;: 4.7236208696, &#39;mse&#39;: 43.5062451229}
Epoch:  308 -  {&#39;cxe+mse&#39;: 48.1927434686, &#39;cxe&#39;: 4.7235064176, &#39;mse&#39;: 43.469237051}
Epoch:  309 -  {&#39;cxe+mse&#39;: 48.1556850992, &#39;cxe&#39;: 4.7233919656, &#39;mse&#39;: 43.4322931336}
Epoch:  310 -  {&#39;cxe+mse&#39;: 48.1186901605, &#39;cxe&#39;: 4.7232775136, &#39;mse&#39;: 43.3954126469}
Epoch:  311 -  {&#39;cxe+mse&#39;: 48.081757966299996, &#39;cxe&#39;: 4.7231630616, &#39;mse&#39;: 43.3585949047}
Epoch:  312 -  {&#39;cxe+mse&#39;: 48.044887866, &#39;cxe&#39;: 4.7230486097, &#39;mse&#39;: 43.3218392563}
Epoch:  313 -  {&#39;cxe+mse&#39;: 48.008079241900006, &#39;cxe&#39;: 4.7229341577, &#39;mse&#39;: 43.2851450842}
Epoch:  314 -  {&#39;cxe+mse&#39;: 47.9713315079, &#39;cxe&#39;: 4.7228197057, &#39;mse&#39;: 43.2485118022}
Epoch:  315 -  {&#39;cxe+mse&#39;: 47.9346441074, &#39;cxe&#39;: 4.7227052537, &#39;mse&#39;: 43.2119388537}
Epoch:  316 -  {&#39;cxe+mse&#39;: 47.8980165114, &#39;cxe&#39;: 4.7225908018, &#39;mse&#39;: 43.1754257096}
Epoch:  317 -  {&#39;cxe+mse&#39;: 47.8614482167, &#39;cxe&#39;: 4.7224763498, &#39;mse&#39;: 43.1389718669}
Epoch:  318 -  {&#39;cxe+mse&#39;: 47.8249387451, &#39;cxe&#39;: 4.7223618979, &#39;mse&#39;: 43.1025768472}
Epoch:  319 -  {&#39;cxe+mse&#39;: 47.788487640700005, &#39;cxe&#39;: 4.7222474459, &#39;mse&#39;: 43.0662401948}
Epoch:  320 -  {&#39;cxe+mse&#39;: 47.752094469899994, &#39;cxe&#39;: 4.7221329939, &#39;mse&#39;: 43.029961476}
Epoch:  321 -  {&#39;cxe+mse&#39;: 47.7157588193, &#39;cxe&#39;: 4.722018542, &#39;mse&#39;: 42.9937402773}
Epoch:  322 -  {&#39;cxe+mse&#39;: 47.6794802943, &#39;cxe&#39;: 4.72190409, &#39;mse&#39;: 42.9575762043}
Epoch:  323 -  {&#39;cxe+mse&#39;: 47.6432585189, &#39;cxe&#39;: 4.7217896381, &#39;mse&#39;: 42.9214688808}
Epoch:  324 -  {&#39;cxe+mse&#39;: 47.6070931333, &#39;cxe&#39;: 4.7216751861, &#39;mse&#39;: 42.8854179472}
Epoch:  325 -  {&#39;cxe+mse&#39;: 47.5709837943, &#39;cxe&#39;: 4.7215607342, &#39;mse&#39;: 42.8494230601}
Epoch:  326 -  {&#39;cxe+mse&#39;: 47.5349301733, &#39;cxe&#39;: 4.7214462823, &#39;mse&#39;: 42.813483891}
Epoch:  327 -  {&#39;cxe+mse&#39;: 47.4989319558, &#39;cxe&#39;: 4.7213318303, &#39;mse&#39;: 42.7776001255}
Epoch:  328 -  {&#39;cxe+mse&#39;: 47.462988840899996, &#39;cxe&#39;: 4.7212173784, &#39;mse&#39;: 42.7417714625}
Epoch:  329 -  {&#39;cxe+mse&#39;: 47.4271005398, &#39;cxe&#39;: 4.7211029265, &#39;mse&#39;: 42.7059976133}
Epoch:  330 -  {&#39;cxe+mse&#39;: 47.3912667754, &#39;cxe&#39;: 4.7209884745, &#39;mse&#39;: 42.6702783009}
Epoch:  331 -  {&#39;cxe+mse&#39;: 47.355487282, &#39;cxe&#39;: 4.7208740226, &#39;mse&#39;: 42.6346132594}
Epoch:  332 -  {&#39;cxe+mse&#39;: 47.319761803999995, &#39;cxe&#39;: 4.7207595707, &#39;mse&#39;: 42.5990022333}
Epoch:  333 -  {&#39;cxe+mse&#39;: 47.2840900956, &#39;cxe&#39;: 4.7206451188, &#39;mse&#39;: 42.5634449768}
Epoch:  334 -  {&#39;cxe+mse&#39;: 47.2484719201, &#39;cxe&#39;: 4.7205306668, &#39;mse&#39;: 42.5279412533}
Epoch:  335 -  {&#39;cxe+mse&#39;: 47.2129070498, &#39;cxe&#39;: 4.7204162149, &#39;mse&#39;: 42.4924908349}
Epoch:  336 -  {&#39;cxe+mse&#39;: 47.1773952647, &#39;cxe&#39;: 4.720301763, &#39;mse&#39;: 42.4570935017}
Epoch:  337 -  {&#39;cxe+mse&#39;: 47.141936352799995, &#39;cxe&#39;: 4.7201873111, &#39;mse&#39;: 42.4217490417}
Epoch:  338 -  {&#39;cxe+mse&#39;: 47.1065301091, &#39;cxe&#39;: 4.7200728592, &#39;mse&#39;: 42.3864572499}
Epoch:  339 -  {&#39;cxe+mse&#39;: 47.0711763355, &#39;cxe&#39;: 4.7199584073, &#39;mse&#39;: 42.3512179282}
Epoch:  340 -  {&#39;cxe+mse&#39;: 47.0358748402, &#39;cxe&#39;: 4.7198439554, &#39;mse&#39;: 42.3160308848}
Epoch:  341 -  {&#39;cxe+mse&#39;: 47.0006254374, &#39;cxe&#39;: 4.7197295035, &#39;mse&#39;: 42.2808959339}
Epoch:  342 -  {&#39;cxe+mse&#39;: 46.965427947100004, &#39;cxe&#39;: 4.7196150516, &#39;mse&#39;: 42.2458128955}
Epoch:  343 -  {&#39;cxe+mse&#39;: 46.930282194499995, &#39;cxe&#39;: 4.7195005997, &#39;mse&#39;: 42.2107815948}
Epoch:  344 -  {&#39;cxe+mse&#39;: 46.8951880098, &#39;cxe&#39;: 4.7193861478, &#39;mse&#39;: 42.175801862}
Epoch:  345 -  {&#39;cxe+mse&#39;: 46.860145228099995, &#39;cxe&#39;: 4.7192716959, &#39;mse&#39;: 42.1408735322}
Epoch:  346 -  {&#39;cxe+mse&#39;: 46.8251536887, &#39;cxe&#39;: 4.719157244, &#39;mse&#39;: 42.1059964447}
Epoch:  347 -  {&#39;cxe+mse&#39;: 46.7902132353, &#39;cxe&#39;: 4.7190427921, &#39;mse&#39;: 42.0711704432}
Epoch:  348 -  {&#39;cxe+mse&#39;: 46.7553237156, &#39;cxe&#39;: 4.7189283403, &#39;mse&#39;: 42.0363953753}
Epoch:  349 -  {&#39;cxe+mse&#39;: 46.7204849807, &#39;cxe&#39;: 4.7188138884, &#39;mse&#39;: 42.0016710923}
Epoch:  350 -  {&#39;cxe+mse&#39;: 46.68569688549999, &#39;cxe&#39;: 4.7186994365, &#39;mse&#39;: 41.966997449}
Epoch:  351 -  {&#39;cxe+mse&#39;: 46.6509592881, &#39;cxe&#39;: 4.7185849846, &#39;mse&#39;: 41.9323743035}
Epoch:  352 -  {&#39;cxe+mse&#39;: 46.6162720499, &#39;cxe&#39;: 4.7184705328, &#39;mse&#39;: 41.8978015171}
Epoch:  353 -  {&#39;cxe+mse&#39;: 46.5816350348, &#39;cxe&#39;: 4.7183560809, &#39;mse&#39;: 41.8632789539}
Epoch:  354 -  {&#39;cxe+mse&#39;: 46.5470481099, &#39;cxe&#39;: 4.718241629, &#39;mse&#39;: 41.8288064809}
Epoch:  355 -  {&#39;cxe+mse&#39;: 46.5125111449, &#39;cxe&#39;: 4.7181271772, &#39;mse&#39;: 41.7943839677}
Epoch:  356 -  {&#39;cxe+mse&#39;: 46.4780240116, &#39;cxe&#39;: 4.7180127253, &#39;mse&#39;: 41.7600112863}
Epoch:  357 -  {&#39;cxe+mse&#39;: 46.443586584500004, &#39;cxe&#39;: 4.7178982734, &#39;mse&#39;: 41.7256883111}
Epoch:  358 -  {&#39;cxe+mse&#39;: 46.409198740200004, &#39;cxe&#39;: 4.7177838216, &#39;mse&#39;: 41.6914149186}
Epoch:  359 -  {&#39;cxe+mse&#39;: 46.3748603572, &#39;cxe&#39;: 4.7176693697, &#39;mse&#39;: 41.6571909875}
Epoch:  360 -  {&#39;cxe+mse&#39;: 46.3405713163, &#39;cxe&#39;: 4.7175549179, &#39;mse&#39;: 41.6230163984}
Epoch:  361 -  {&#39;cxe+mse&#39;: 46.3063314999, &#39;cxe&#39;: 4.717440466, &#39;mse&#39;: 41.5888910339}
Epoch:  362 -  {&#39;cxe+mse&#39;: 46.2721407922, &#39;cxe&#39;: 4.7173260142, &#39;mse&#39;: 41.554814778}
Epoch:  363 -  {&#39;cxe+mse&#39;: 46.237999079000005, &#39;cxe&#39;: 4.7172115624, &#39;mse&#39;: 41.5207875166}
Epoch:  364 -  {&#39;cxe+mse&#39;: 46.2039062478, &#39;cxe&#39;: 4.7170971105, &#39;mse&#39;: 41.4868091373}
Epoch:  365 -  {&#39;cxe+mse&#39;: 46.169862187599996, &#39;cxe&#39;: 4.7169826587, &#39;mse&#39;: 41.4528795289}
Epoch:  366 -  {&#39;cxe+mse&#39;: 46.135866788600005, &#39;cxe&#39;: 4.7168682069, &#39;mse&#39;: 41.4189985817}
Epoch:  367 -  {&#39;cxe+mse&#39;: 46.1019199424, &#39;cxe&#39;: 4.716753755, &#39;mse&#39;: 41.3851661874}
Epoch:  368 -  {&#39;cxe+mse&#39;: 46.0680215421, &#39;cxe&#39;: 4.7166393032, &#39;mse&#39;: 41.3513822389}
Epoch:  369 -  {&#39;cxe+mse&#39;: 46.0341714818, &#39;cxe&#39;: 4.7165248514, &#39;mse&#39;: 41.3176466304}
Epoch:  370 -  {&#39;cxe+mse&#39;: 46.0003696565, &#39;cxe&#39;: 4.7164103996, &#39;mse&#39;: 41.2839592569}
Epoch:  371 -  {&#39;cxe+mse&#39;: 45.9666159627, &#39;cxe&#39;: 4.7162959477, &#39;mse&#39;: 41.250320015}
Epoch:  372 -  {&#39;cxe+mse&#39;: 45.9329102976, &#39;cxe&#39;: 4.7161814959, &#39;mse&#39;: 41.2167288017}
Epoch:  373 -  {&#39;cxe+mse&#39;: 45.8992525597, &#39;cxe&#39;: 4.7160670441, &#39;mse&#39;: 41.1831855156}
Epoch:  374 -  {&#39;cxe+mse&#39;: 45.865642647899996, &#39;cxe&#39;: 4.7159525923, &#39;mse&#39;: 41.1496900556}
Epoch:  375 -  {&#39;cxe+mse&#39;: 45.832080462499995, &#39;cxe&#39;: 4.7158381405, &#39;mse&#39;: 41.116242322}
Epoch:  376 -  {&#39;cxe+mse&#39;: 45.7985659044, &#39;cxe&#39;: 4.7157236887, &#39;mse&#39;: 41.0828422157}
Epoch:  377 -  {&#39;cxe+mse&#39;: 45.7650988752, &#39;cxe&#39;: 4.7156092369, &#39;mse&#39;: 41.0494896383}
Epoch:  378 -  {&#39;cxe+mse&#39;: 45.731679277299996, &#39;cxe&#39;: 4.7154947851, &#39;mse&#39;: 41.0161844922}
Epoch:  379 -  {&#39;cxe+mse&#39;: 45.698307013999994, &#39;cxe&#39;: 4.7153803333, &#39;mse&#39;: 40.9829266807}
Epoch:  380 -  {&#39;cxe+mse&#39;: 45.6649819891, &#39;cxe&#39;: 4.7152658815, &#39;mse&#39;: 40.9497161076}
Epoch:  381 -  {&#39;cxe+mse&#39;: 45.6317041071, &#39;cxe&#39;: 4.7151514297, &#39;mse&#39;: 40.9165526774}
Epoch:  382 -  {&#39;cxe+mse&#39;: 45.5984732731, &#39;cxe&#39;: 4.7150369779, &#39;mse&#39;: 40.8834362952}
Epoch:  383 -  {&#39;cxe+mse&#39;: 45.5652893929, &#39;cxe&#39;: 4.7149225261, &#39;mse&#39;: 40.8503668668}
Epoch:  384 -  {&#39;cxe+mse&#39;: 45.5321523726, &#39;cxe&#39;: 4.7148080743, &#39;mse&#39;: 40.8173442983}
Epoch:  385 -  {&#39;cxe+mse&#39;: 45.4990621193, &#39;cxe&#39;: 4.7146936226, &#39;mse&#39;: 40.7843684967}
Epoch:  386 -  {&#39;cxe+mse&#39;: 45.4660185401, &#39;cxe&#39;: 4.7145791708, &#39;mse&#39;: 40.7514393693}
Epoch:  387 -  {&#39;cxe+mse&#39;: 45.4330215429, &#39;cxe&#39;: 4.714464719, &#39;mse&#39;: 40.7185568239}
Epoch:  388 -  {&#39;cxe+mse&#39;: 45.4000710362, &#39;cxe&#39;: 4.7143502672, &#39;mse&#39;: 40.685720769}
Epoch:  389 -  {&#39;cxe+mse&#39;: 45.3671669287, &#39;cxe&#39;: 4.7142358155, &#39;mse&#39;: 40.6529311132}
Epoch:  390 -  {&#39;cxe+mse&#39;: 45.3343091295, &#39;cxe&#39;: 4.7141213637, &#39;mse&#39;: 40.6201877658}
Epoch:  391 -  {&#39;cxe+mse&#39;: 45.3014975484, &#39;cxe&#39;: 4.7140069119, &#39;mse&#39;: 40.5874906365}
Epoch:  392 -  {&#39;cxe+mse&#39;: 45.2687320956, &#39;cxe&#39;: 4.7138924602, &#39;mse&#39;: 40.5548396354}
Epoch:  393 -  {&#39;cxe+mse&#39;: 45.2360126813, &#39;cxe&#39;: 4.7137780084, &#39;mse&#39;: 40.5222346729}
Epoch:  394 -  {&#39;cxe+mse&#39;: 45.2033392165, &#39;cxe&#39;: 4.7136635567, &#39;mse&#39;: 40.4896756598}
Epoch:  395 -  {&#39;cxe+mse&#39;: 45.170711612299996, &#39;cxe&#39;: 4.7135491049, &#39;mse&#39;: 40.4571625074}
Epoch:  396 -  {&#39;cxe+mse&#39;: 45.138129780599996, &#39;cxe&#39;: 4.7134346532, &#39;mse&#39;: 40.4246951274}
Epoch:  397 -  {&#39;cxe+mse&#39;: 45.1055936328, &#39;cxe&#39;: 4.7133202014, &#39;mse&#39;: 40.3922734314}
Epoch:  398 -  {&#39;cxe+mse&#39;: 45.073103081700005, &#39;cxe&#39;: 4.7132057497, &#39;mse&#39;: 40.359897332}
Epoch:  399 -  {&#39;cxe+mse&#39;: 45.0406580394, &#39;cxe&#39;: 4.7130912979, &#39;mse&#39;: 40.3275667415}
Epoch:  400 -  {&#39;cxe+mse&#39;: 45.0082584192, &#39;cxe&#39;: 4.7129768462, &#39;mse&#39;: 40.295281573}
Epoch:  401 -  {&#39;cxe+mse&#39;: 44.975904133899995, &#39;cxe&#39;: 4.7128623944, &#39;mse&#39;: 40.2630417395}
Epoch:  402 -  {&#39;cxe+mse&#39;: 44.9435950974, &#39;cxe&#39;: 4.7127479427, &#39;mse&#39;: 40.2308471547}
Epoch:  403 -  {&#39;cxe+mse&#39;: 44.9113312232, &#39;cxe&#39;: 4.712633491, &#39;mse&#39;: 40.1986977322}
Epoch:  404 -  {&#39;cxe+mse&#39;: 44.879112425399995, &#39;cxe&#39;: 4.7125190393, &#39;mse&#39;: 40.1665933861}
Epoch:  405 -  {&#39;cxe+mse&#39;: 44.8469386183, &#39;cxe&#39;: 4.7124045875, &#39;mse&#39;: 40.1345340308}
Epoch:  406 -  {&#39;cxe+mse&#39;: 44.8148097167, &#39;cxe&#39;: 4.7122901358, &#39;mse&#39;: 40.1025195809}
Epoch:  407 -  {&#39;cxe+mse&#39;: 44.7827256353, &#39;cxe&#39;: 4.7121756841, &#39;mse&#39;: 40.0705499512}
Epoch:  408 -  {&#39;cxe+mse&#39;: 44.750686289300006, &#39;cxe&#39;: 4.7120612324, &#39;mse&#39;: 40.0386250569}
Epoch:  409 -  {&#39;cxe+mse&#39;: 44.718691594000006, &#39;cxe&#39;: 4.7119467807, &#39;mse&#39;: 40.0067448133}
Epoch:  410 -  {&#39;cxe+mse&#39;: 44.6867414648, &#39;cxe&#39;: 4.7118323289, &#39;mse&#39;: 39.9749091359}
Epoch:  411 -  {&#39;cxe+mse&#39;: 44.654835818, &#39;cxe&#39;: 4.7117178772, &#39;mse&#39;: 39.9431179408}
Epoch:  412 -  {&#39;cxe+mse&#39;: 44.6229745694, &#39;cxe&#39;: 4.7116034255, &#39;mse&#39;: 39.9113711439}
Epoch:  413 -  {&#39;cxe+mse&#39;: 44.5911576353, &#39;cxe&#39;: 4.7114889738, &#39;mse&#39;: 39.8796686615}
Epoch:  414 -  {&#39;cxe+mse&#39;: 44.5593849324, &#39;cxe&#39;: 4.7113745221, &#39;mse&#39;: 39.8480104103}
Epoch:  415 -  {&#39;cxe+mse&#39;: 44.527656377300005, &#39;cxe&#39;: 4.7112600704, &#39;mse&#39;: 39.8163963069}
Epoch:  416 -  {&#39;cxe+mse&#39;: 44.495971887, &#39;cxe&#39;: 4.7111456187, &#39;mse&#39;: 39.7848262683}
Epoch:  417 -  {&#39;cxe+mse&#39;: 44.464331378800004, &#39;cxe&#39;: 4.711031167, &#39;mse&#39;: 39.7533002118}
Epoch:  418 -  {&#39;cxe+mse&#39;: 44.43273477, &#39;cxe&#39;: 4.7109167153, &#39;mse&#39;: 39.7218180547}
Epoch:  419 -  {&#39;cxe+mse&#39;: 44.4011819783, &#39;cxe&#39;: 4.7108022637, &#39;mse&#39;: 39.6903797146}
Epoch:  420 -  {&#39;cxe+mse&#39;: 44.369672921399996, &#39;cxe&#39;: 4.710687812, &#39;mse&#39;: 39.6589851094}
Epoch:  421 -  {&#39;cxe+mse&#39;: 44.338207517300006, &#39;cxe&#39;: 4.7105733603, &#39;mse&#39;: 39.627634157}
Epoch:  422 -  {&#39;cxe+mse&#39;: 44.3067856844, &#39;cxe&#39;: 4.7104589086, &#39;mse&#39;: 39.5963267758}
Epoch:  423 -  {&#39;cxe+mse&#39;: 44.2754073409, &#39;cxe&#39;: 4.7103444569, &#39;mse&#39;: 39.565062884}
Epoch:  424 -  {&#39;cxe+mse&#39;: 44.244072405699995, &#39;cxe&#39;: 4.7102300053, &#39;mse&#39;: 39.5338424004}
Epoch:  425 -  {&#39;cxe+mse&#39;: 44.2127807973, &#39;cxe&#39;: 4.7101155536, &#39;mse&#39;: 39.5026652437}
Epoch:  426 -  {&#39;cxe+mse&#39;: 44.1815324349, &#39;cxe&#39;: 4.7100011019, &#39;mse&#39;: 39.471531333}
Epoch:  427 -  {&#39;cxe+mse&#39;: 44.1503272377, &#39;cxe&#39;: 4.7098866503, &#39;mse&#39;: 39.4404405874}
Epoch:  428 -  {&#39;cxe+mse&#39;: 44.1191651249, &#39;cxe&#39;: 4.7097721986, &#39;mse&#39;: 39.4093929263}
Epoch:  429 -  {&#39;cxe+mse&#39;: 44.0880460161, &#39;cxe&#39;: 4.7096577469, &#39;mse&#39;: 39.3783882692}
Epoch:  430 -  {&#39;cxe+mse&#39;: 44.0569698312, &#39;cxe&#39;: 4.7095432953, &#39;mse&#39;: 39.3474265359}
Epoch:  431 -  {&#39;cxe+mse&#39;: 44.02593649, &#39;cxe&#39;: 4.7094288436, &#39;mse&#39;: 39.3165076464}
Epoch:  432 -  {&#39;cxe+mse&#39;: 43.994945912700004, &#39;cxe&#39;: 4.709314392, &#39;mse&#39;: 39.2856315207}
Epoch:  433 -  {&#39;cxe+mse&#39;: 43.9639980194, &#39;cxe&#39;: 4.7091999403, &#39;mse&#39;: 39.2547980791}
Epoch:  434 -  {&#39;cxe+mse&#39;: 43.9330927308, &#39;cxe&#39;: 4.7090854887, &#39;mse&#39;: 39.2240072421}
Epoch:  435 -  {&#39;cxe+mse&#39;: 43.902229967299995, &#39;cxe&#39;: 4.708971037, &#39;mse&#39;: 39.1932589303}
Epoch:  436 -  {&#39;cxe+mse&#39;: 43.87140965, &#39;cxe&#39;: 4.7088565854, &#39;mse&#39;: 39.1625530646}
Epoch:  437 -  {&#39;cxe+mse&#39;: 43.840631699700005, &#39;cxe&#39;: 4.7087421338, &#39;mse&#39;: 39.1318895659}
Epoch:  438 -  {&#39;cxe+mse&#39;: 43.8098960375, &#39;cxe&#39;: 4.7086276821, &#39;mse&#39;: 39.1012683554}
Epoch:  439 -  {&#39;cxe+mse&#39;: 43.779202585, &#39;cxe&#39;: 4.7085132305, &#39;mse&#39;: 39.0706893545}
Epoch:  440 -  {&#39;cxe+mse&#39;: 43.7485512635, &#39;cxe&#39;: 4.7083987789, &#39;mse&#39;: 39.0401524846}
Epoch:  441 -  {&#39;cxe+mse&#39;: 43.7179419946, &#39;cxe&#39;: 4.7082843272, &#39;mse&#39;: 39.0096576674}
Epoch:  442 -  {&#39;cxe+mse&#39;: 43.6873747005, &#39;cxe&#39;: 4.7081698756, &#39;mse&#39;: 38.9792048249}
Epoch:  443 -  {&#39;cxe+mse&#39;: 43.6568493029, &#39;cxe&#39;: 4.708055424, &#39;mse&#39;: 38.9487938789}
Epoch:  444 -  {&#39;cxe+mse&#39;: 43.626365724100005, &#39;cxe&#39;: 4.7079409724, &#39;mse&#39;: 38.9184247517}
Epoch:  445 -  {&#39;cxe+mse&#39;: 43.5959238864, &#39;cxe&#39;: 4.7078265207, &#39;mse&#39;: 38.8880973657}
Epoch:  446 -  {&#39;cxe+mse&#39;: 43.5655237124, &#39;cxe&#39;: 4.7077120691, &#39;mse&#39;: 38.8578116433}
Epoch:  447 -  {&#39;cxe+mse&#39;: 43.5351651248, &#39;cxe&#39;: 4.7075976175, &#39;mse&#39;: 38.8275675073}
Epoch:  448 -  {&#39;cxe+mse&#39;: 43.5048480464, &#39;cxe&#39;: 4.7074831659, &#39;mse&#39;: 38.7973648805}
Epoch:  449 -  {&#39;cxe+mse&#39;: 43.4745724002, &#39;cxe&#39;: 4.7073687143, &#39;mse&#39;: 38.7672036859}
Epoch:  450 -  {&#39;cxe+mse&#39;: 43.4443381093, &#39;cxe&#39;: 4.7072542627, &#39;mse&#39;: 38.7370838466}
Epoch:  451 -  {&#39;cxe+mse&#39;: 43.4141450972, &#39;cxe&#39;: 4.7071398111, &#39;mse&#39;: 38.7070052861}
Epoch:  452 -  {&#39;cxe+mse&#39;: 43.3839932874, &#39;cxe&#39;: 4.7070253595, &#39;mse&#39;: 38.6769679279}
Epoch:  453 -  {&#39;cxe+mse&#39;: 43.3538826034, &#39;cxe&#39;: 4.7069109079, &#39;mse&#39;: 38.6469716955}
Epoch:  454 -  {&#39;cxe+mse&#39;: 43.3238129691, &#39;cxe&#39;: 4.7067964563, &#39;mse&#39;: 38.6170165128}
Epoch:  455 -  {&#39;cxe+mse&#39;: 43.293784308599996, &#39;cxe&#39;: 4.7066820047, &#39;mse&#39;: 38.5871023039}
Epoch:  456 -  {&#39;cxe+mse&#39;: 43.263796546, &#39;cxe&#39;: 4.7065675532, &#39;mse&#39;: 38.5572289928}
Epoch:  457 -  {&#39;cxe+mse&#39;: 43.2338496055, &#39;cxe&#39;: 4.7064531016, &#39;mse&#39;: 38.5273965039}
Epoch:  458 -  {&#39;cxe+mse&#39;: 43.2039434116, &#39;cxe&#39;: 4.70633865, &#39;mse&#39;: 38.4976047616}
Epoch:  459 -  {&#39;cxe+mse&#39;: 43.1740778889, &#39;cxe&#39;: 4.7062241984, &#39;mse&#39;: 38.4678536905}
Epoch:  460 -  {&#39;cxe+mse&#39;: 43.1442529623, &#39;cxe&#39;: 4.7061097468, &#39;mse&#39;: 38.4381432155}
Epoch:  461 -  {&#39;cxe+mse&#39;: 43.1144685567, &#39;cxe&#39;: 4.7059952953, &#39;mse&#39;: 38.4084732614}
Epoch:  462 -  {&#39;cxe+mse&#39;: 43.0847245971, &#39;cxe&#39;: 4.7058808437, &#39;mse&#39;: 38.3788437534}
Epoch:  463 -  {&#39;cxe+mse&#39;: 43.0550210087, &#39;cxe&#39;: 4.7057663921, &#39;mse&#39;: 38.3492546166}
Epoch:  464 -  {&#39;cxe+mse&#39;: 43.0253577173, &#39;cxe&#39;: 4.7056519406, &#39;mse&#39;: 38.3197057767}
Epoch:  465 -  {&#39;cxe+mse&#39;: 42.9957346479, &#39;cxe&#39;: 4.705537489, &#39;mse&#39;: 38.2901971589}
Epoch:  466 -  {&#39;cxe+mse&#39;: 42.9661517267, &#39;cxe&#39;: 4.7054230375, &#39;mse&#39;: 38.2607286892}
Epoch:  467 -  {&#39;cxe+mse&#39;: 42.936608879299996, &#39;cxe&#39;: 4.7053085859, &#39;mse&#39;: 38.2313002934}
Epoch:  468 -  {&#39;cxe+mse&#39;: 42.9071060319, &#39;cxe&#39;: 4.7051941344, &#39;mse&#39;: 38.2019118975}
Epoch:  469 -  {&#39;cxe+mse&#39;: 42.877643110399994, &#39;cxe&#39;: 4.7050796828, &#39;mse&#39;: 38.1725634276}
Epoch:  470 -  {&#39;cxe+mse&#39;: 42.8482200415, &#39;cxe&#39;: 4.7049652313, &#39;mse&#39;: 38.1432548102}
Epoch:  471 -  {&#39;cxe+mse&#39;: 42.8188367514, &#39;cxe&#39;: 4.7048507797, &#39;mse&#39;: 38.1139859717}
Epoch:  472 -  {&#39;cxe+mse&#39;: 42.7894931669, &#39;cxe&#39;: 4.7047363282, &#39;mse&#39;: 38.0847568387}
Epoch:  473 -  {&#39;cxe+mse&#39;: 42.7601892147, &#39;cxe&#39;: 4.7046218766, &#39;mse&#39;: 38.0555673381}
Epoch:  474 -  {&#39;cxe+mse&#39;: 42.7309248219, &#39;cxe&#39;: 4.7045074251, &#39;mse&#39;: 38.0264173968}
Epoch:  475 -  {&#39;cxe+mse&#39;: 42.7016999155, &#39;cxe&#39;: 4.7043929736, &#39;mse&#39;: 37.9973069419}
Epoch:  476 -  {&#39;cxe+mse&#39;: 42.6725144226, &#39;cxe&#39;: 4.704278522, &#39;mse&#39;: 37.9682359006}
Epoch:  477 -  {&#39;cxe+mse&#39;: 42.6433682709, &#39;cxe&#39;: 4.7041640705, &#39;mse&#39;: 37.9392042004}
Epoch:  478 -  {&#39;cxe+mse&#39;: 42.614261387700004, &#39;cxe&#39;: 4.704049619, &#39;mse&#39;: 37.9102117687}
Epoch:  479 -  {&#39;cxe+mse&#39;: 42.5851937009, &#39;cxe&#39;: 4.7039351675, &#39;mse&#39;: 37.8812585334}
Epoch:  480 -  {&#39;cxe+mse&#39;: 42.5561651382, &#39;cxe&#39;: 4.7038207159, &#39;mse&#39;: 37.8523444223}
Epoch:  481 -  {&#39;cxe+mse&#39;: 42.527175627599995, &#39;cxe&#39;: 4.7037062644, &#39;mse&#39;: 37.8234693632}
Epoch:  482 -  {&#39;cxe+mse&#39;: 42.4982250974, &#39;cxe&#39;: 4.7035918129, &#39;mse&#39;: 37.7946332845}
Epoch:  483 -  {&#39;cxe+mse&#39;: 42.469313475899995, &#39;cxe&#39;: 4.7034773614, &#39;mse&#39;: 37.7658361145}
Epoch:  484 -  {&#39;cxe+mse&#39;: 42.4404406913, &#39;cxe&#39;: 4.7033629099, &#39;mse&#39;: 37.7370777814}
Epoch:  485 -  {&#39;cxe+mse&#39;: 42.4116066725, &#39;cxe&#39;: 4.7032484584, &#39;mse&#39;: 37.7083582141}
Epoch:  486 -  {&#39;cxe+mse&#39;: 42.382811348000004, &#39;cxe&#39;: 4.7031340069, &#39;mse&#39;: 37.6796773411}
Epoch:  487 -  {&#39;cxe+mse&#39;: 42.354054646899996, &#39;cxe&#39;: 4.7030195554, &#39;mse&#39;: 37.6510350915}
Epoch:  488 -  {&#39;cxe+mse&#39;: 42.3253364981, &#39;cxe&#39;: 4.7029051039, &#39;mse&#39;: 37.6224313942}
Epoch:  489 -  {&#39;cxe+mse&#39;: 42.296656830799996, &#39;cxe&#39;: 4.7027906524, &#39;mse&#39;: 37.5938661784}
Epoch:  490 -  {&#39;cxe+mse&#39;: 42.2680155744, &#39;cxe&#39;: 4.7026762009, &#39;mse&#39;: 37.5653393735}
Epoch:  491 -  {&#39;cxe+mse&#39;: 42.2394126584, &#39;cxe&#39;: 4.7025617494, &#39;mse&#39;: 37.536850909}
Epoch:  492 -  {&#39;cxe+mse&#39;: 42.2108480124, &#39;cxe&#39;: 4.7024472979, &#39;mse&#39;: 37.5084007145}
Epoch:  493 -  {&#39;cxe+mse&#39;: 42.1823215662, &#39;cxe&#39;: 4.7023328465, &#39;mse&#39;: 37.4799887197}
Epoch:  494 -  {&#39;cxe+mse&#39;: 42.153833249600005, &#39;cxe&#39;: 4.702218395, &#39;mse&#39;: 37.4516148546}
Epoch:  495 -  {&#39;cxe+mse&#39;: 42.1253829927, &#39;cxe&#39;: 4.7021039435, &#39;mse&#39;: 37.4232790492}
Epoch:  496 -  {&#39;cxe+mse&#39;: 42.096970725800006, &#39;cxe&#39;: 4.701989492, &#39;mse&#39;: 37.3949812338}
Epoch:  497 -  {&#39;cxe+mse&#39;: 42.068596379300004, &#39;cxe&#39;: 4.7018750406, &#39;mse&#39;: 37.3667213387}
Epoch:  498 -  {&#39;cxe+mse&#39;: 42.0402598835, &#39;cxe&#39;: 4.7017605891, &#39;mse&#39;: 37.3384992944}
Epoch:  499 -  {&#39;cxe+mse&#39;: 42.0119611692, &#39;cxe&#39;: 4.7016461376, &#39;mse&#39;: 37.3103150316}
Epoch:  500 -  {&#39;cxe+mse&#39;: 41.9837001672, &#39;cxe&#39;: 4.7015316862, &#39;mse&#39;: 37.282168481}
Epoch:  501 -  {&#39;cxe+mse&#39;: 41.955476808300006, &#39;cxe&#39;: 4.7014172347, &#39;mse&#39;: 37.2540595736}
Epoch:  502 -  {&#39;cxe+mse&#39;: 41.9272910237, &#39;cxe&#39;: 4.7013027832, &#39;mse&#39;: 37.2259882405}
Epoch:  503 -  {&#39;cxe+mse&#39;: 41.8991427446, &#39;cxe&#39;: 4.7011883318, &#39;mse&#39;: 37.1979544128}
Epoch:  504 -  {&#39;cxe+mse&#39;: 41.8710319022, &#39;cxe&#39;: 4.7010738803, &#39;mse&#39;: 37.1699580219}
Epoch:  505 -  {&#39;cxe+mse&#39;: 41.8429584283, &#39;cxe&#39;: 4.7009594289, &#39;mse&#39;: 37.1419989994}
Epoch:  506 -  {&#39;cxe+mse&#39;: 41.814922254200006, &#39;cxe&#39;: 4.7008449774, &#39;mse&#39;: 37.1140772768}
Epoch:  507 -  {&#39;cxe+mse&#39;: 41.786923312, &#39;cxe&#39;: 4.700730526, &#39;mse&#39;: 37.086192786}
Epoch:  508 -  {&#39;cxe+mse&#39;: 41.7589615335, &#39;cxe&#39;: 4.7006160746, &#39;mse&#39;: 37.0583454589}
Epoch:  509 -  {&#39;cxe+mse&#39;: 41.731036850600006, &#39;cxe&#39;: 4.7005016231, &#39;mse&#39;: 37.0305352275}
Epoch:  510 -  {&#39;cxe+mse&#39;: 41.703149195900004, &#39;cxe&#39;: 4.7003871717, &#39;mse&#39;: 37.0027620242}
Epoch:  511 -  {&#39;cxe+mse&#39;: 41.6752985014, &#39;cxe&#39;: 4.7002727203, &#39;mse&#39;: 36.9750257811}
Epoch:  512 -  {&#39;cxe+mse&#39;: 41.6474846996, &#39;cxe&#39;: 4.7001582688, &#39;mse&#39;: 36.9473264308}
Epoch:  513 -  {&#39;cxe+mse&#39;: 41.6197077233, &#39;cxe&#39;: 4.7000438174, &#39;mse&#39;: 36.9196639059}
Epoch:  514 -  {&#39;cxe+mse&#39;: 41.5919675053, &#39;cxe&#39;: 4.699929366, &#39;mse&#39;: 36.8920381393}
Epoch:  515 -  {&#39;cxe+mse&#39;: 41.5642639784, &#39;cxe&#39;: 4.6998149146, &#39;mse&#39;: 36.8644490638}
Epoch:  516 -  {&#39;cxe+mse&#39;: 41.5365970755, &#39;cxe&#39;: 4.6997004631, &#39;mse&#39;: 36.8368966124}
Epoch:  517 -  {&#39;cxe+mse&#39;: 41.5089667301, &#39;cxe&#39;: 4.6995860117, &#39;mse&#39;: 36.8093807184}
Epoch:  518 -  {&#39;cxe+mse&#39;: 41.481372875299996, &#39;cxe&#39;: 4.6994715603, &#39;mse&#39;: 36.781901315}
Epoch:  519 -  {&#39;cxe+mse&#39;: 41.453815444700005, &#39;cxe&#39;: 4.6993571089, &#39;mse&#39;: 36.7544583358}
Epoch:  520 -  {&#39;cxe+mse&#39;: 41.426294371800005, &#39;cxe&#39;: 4.6992426575, &#39;mse&#39;: 36.7270517143}
Epoch:  521 -  {&#39;cxe+mse&#39;: 41.3988095903, &#39;cxe&#39;: 4.6991282061, &#39;mse&#39;: 36.6996813842}
Epoch:  522 -  {&#39;cxe+mse&#39;: 41.371361034299994, &#39;cxe&#39;: 4.6990137547, &#39;mse&#39;: 36.6723472796}
Epoch:  523 -  {&#39;cxe+mse&#39;: 41.343948637500006, &#39;cxe&#39;: 4.6988993033, &#39;mse&#39;: 36.6450493342}
Epoch:  524 -  {&#39;cxe+mse&#39;: 41.3165723343, &#39;cxe&#39;: 4.6987848519, &#39;mse&#39;: 36.6177874824}
Epoch:  525 -  {&#39;cxe+mse&#39;: 41.2892320589, &#39;cxe&#39;: 4.6986704005, &#39;mse&#39;: 36.5905616584}
Epoch:  526 -  {&#39;cxe+mse&#39;: 41.2619277457, &#39;cxe&#39;: 4.6985559491, &#39;mse&#39;: 36.5633717966}
Epoch:  527 -  {&#39;cxe+mse&#39;: 41.2346593292, &#39;cxe&#39;: 4.6984414977, &#39;mse&#39;: 36.5362178315}
Epoch:  528 -  {&#39;cxe+mse&#39;: 41.2074267443, &#39;cxe&#39;: 4.6983270463, &#39;mse&#39;: 36.509099698}
Epoch:  529 -  {&#39;cxe+mse&#39;: 41.180229925700004, &#39;cxe&#39;: 4.698212595, &#39;mse&#39;: 36.4820173307}
Epoch:  530 -  {&#39;cxe+mse&#39;: 41.1530688083, &#39;cxe&#39;: 4.6980981436, &#39;mse&#39;: 36.4549706647}
Epoch:  531 -  {&#39;cxe+mse&#39;: 41.1259433272, &#39;cxe&#39;: 4.6979836922, &#39;mse&#39;: 36.427959635}
Epoch:  532 -  {&#39;cxe+mse&#39;: 41.0988534178, &#39;cxe&#39;: 4.6978692408, &#39;mse&#39;: 36.400984177}
Epoch:  533 -  {&#39;cxe+mse&#39;: 41.0717990153, &#39;cxe&#39;: 4.6977547895, &#39;mse&#39;: 36.3740442258}
Epoch:  534 -  {&#39;cxe+mse&#39;: 41.0447800553, &#39;cxe&#39;: 4.6976403381, &#39;mse&#39;: 36.3471397172}
Epoch:  535 -  {&#39;cxe+mse&#39;: 41.0177964733, &#39;cxe&#39;: 4.6975258867, &#39;mse&#39;: 36.3202705866}
Epoch:  536 -  {&#39;cxe+mse&#39;: 40.9908482053, &#39;cxe&#39;: 4.6974114354, &#39;mse&#39;: 36.2934367699}
Epoch:  537 -  {&#39;cxe+mse&#39;: 40.963935186899995, &#39;cxe&#39;: 4.697296984, &#39;mse&#39;: 36.2666382029}
Epoch:  538 -  {&#39;cxe+mse&#39;: 40.9370573545, &#39;cxe&#39;: 4.6971825327, &#39;mse&#39;: 36.2398748218}
Epoch:  539 -  {&#39;cxe+mse&#39;: 40.910214643900005, &#39;cxe&#39;: 4.6970680813, &#39;mse&#39;: 36.2131465626}
Epoch:  540 -  {&#39;cxe+mse&#39;: 40.883406991600005, &#39;cxe&#39;: 4.69695363, &#39;mse&#39;: 36.1864533616}
Epoch:  541 -  {&#39;cxe+mse&#39;: 40.856634334, &#39;cxe&#39;: 4.6968391786, &#39;mse&#39;: 36.1597951554}
Epoch:  542 -  {&#39;cxe+mse&#39;: 40.8298966076, &#39;cxe&#39;: 4.6967247273, &#39;mse&#39;: 36.1331718803}
Epoch:  543 -  {&#39;cxe+mse&#39;: 40.8031937492, &#39;cxe&#39;: 4.6966102759, &#39;mse&#39;: 36.1065834733}
Epoch:  544 -  {&#39;cxe+mse&#39;: 40.7765256955, &#39;cxe&#39;: 4.6964958246, &#39;mse&#39;: 36.0800298709}
Epoch:  545 -  {&#39;cxe+mse&#39;: 40.7498923836, &#39;cxe&#39;: 4.6963813733, &#39;mse&#39;: 36.0535110103}
Epoch:  546 -  {&#39;cxe+mse&#39;: 40.723293750399996, &#39;cxe&#39;: 4.6962669219, &#39;mse&#39;: 36.0270268285}
Epoch:  547 -  {&#39;cxe+mse&#39;: 40.696729733299996, &#39;cxe&#39;: 4.6961524706, &#39;mse&#39;: 36.0005772627}
Epoch:  548 -  {&#39;cxe+mse&#39;: 40.670200269599995, &#39;cxe&#39;: 4.6960380193, &#39;mse&#39;: 35.9741622503}
Epoch:  549 -  {&#39;cxe+mse&#39;: 40.643705296600004, &#39;cxe&#39;: 4.6959235679, &#39;mse&#39;: 35.9477817287}
Epoch:  550 -  {&#39;cxe+mse&#39;: 40.6172447522, &#39;cxe&#39;: 4.6958091166, &#39;mse&#39;: 35.9214356356}
Epoch:  551 -  {&#39;cxe+mse&#39;: 40.590818573899995, &#39;cxe&#39;: 4.6956946653, &#39;mse&#39;: 35.8951239086}
Epoch:  552 -  {&#39;cxe+mse&#39;: 40.564426699600006, &#39;cxe&#39;: 4.695580214, &#39;mse&#39;: 35.8688464856}
Epoch:  553 -  {&#39;cxe+mse&#39;: 40.5380690674, &#39;cxe&#39;: 4.6954657627, &#39;mse&#39;: 35.8426033047}
Epoch:  554 -  {&#39;cxe+mse&#39;: 40.5117456153, &#39;cxe&#39;: 4.6953513114, &#39;mse&#39;: 35.8163943039}
Epoch:  555 -  {&#39;cxe+mse&#39;: 40.4854562815, &#39;cxe&#39;: 4.69523686, &#39;mse&#39;: 35.7902194215}
Epoch:  556 -  {&#39;cxe+mse&#39;: 40.459201004600004, &#39;cxe&#39;: 4.6951224087, &#39;mse&#39;: 35.7640785959}
Epoch:  557 -  {&#39;cxe+mse&#39;: 40.432979723, &#39;cxe&#39;: 4.6950079574, &#39;mse&#39;: 35.7379717656}
Epoch:  558 -  {&#39;cxe+mse&#39;: 40.4067923752, &#39;cxe&#39;: 4.6948935061, &#39;mse&#39;: 35.7118988691}
Epoch:  559 -  {&#39;cxe+mse&#39;: 40.3806389001, &#39;cxe&#39;: 4.6947790548, &#39;mse&#39;: 35.6858598453}
Epoch:  560 -  {&#39;cxe+mse&#39;: 40.3545192366, &#39;cxe&#39;: 4.6946646036, &#39;mse&#39;: 35.659854633}
Epoch:  561 -  {&#39;cxe+mse&#39;: 40.328433323599995, &#39;cxe&#39;: 4.6945501523, &#39;mse&#39;: 35.6338831713}
Epoch:  562 -  {&#39;cxe+mse&#39;: 40.302381100299996, &#39;cxe&#39;: 4.694435701, &#39;mse&#39;: 35.6079453993}
Epoch:  563 -  {&#39;cxe+mse&#39;: 40.276362505899996, &#39;cxe&#39;: 4.6943212497, &#39;mse&#39;: 35.5820412562}
Epoch:  564 -  {&#39;cxe+mse&#39;: 40.250377479799994, &#39;cxe&#39;: 4.6942067984, &#39;mse&#39;: 35.5561706814}
Epoch:  565 -  {&#39;cxe+mse&#39;: 40.2244259615, &#39;cxe&#39;: 4.6940923471, &#39;mse&#39;: 35.5303336144}
Epoch:  566 -  {&#39;cxe+mse&#39;: 40.1985078909, &#39;cxe&#39;: 4.6939778959, &#39;mse&#39;: 35.504529995}
Epoch:  567 -  {&#39;cxe+mse&#39;: 40.1726232074, &#39;cxe&#39;: 4.6938634446, &#39;mse&#39;: 35.4787597628}
Epoch:  568 -  {&#39;cxe+mse&#39;: 40.146771851, &#39;cxe&#39;: 4.6937489933, &#39;mse&#39;: 35.4530228577}
Epoch:  569 -  {&#39;cxe+mse&#39;: 40.1209537617, &#39;cxe&#39;: 4.693634542, &#39;mse&#39;: 35.4273192197}
Epoch:  570 -  {&#39;cxe+mse&#39;: 40.0951688798, &#39;cxe&#39;: 4.6935200908, &#39;mse&#39;: 35.401648789}
Epoch:  571 -  {&#39;cxe+mse&#39;: 40.0694171453, &#39;cxe&#39;: 4.6934056395, &#39;mse&#39;: 35.3760115058}
Epoch:  572 -  {&#39;cxe+mse&#39;: 40.0436984989, &#39;cxe&#39;: 4.6932911883, &#39;mse&#39;: 35.3504073106}
Epoch:  573 -  {&#39;cxe+mse&#39;: 40.0180128807, &#39;cxe&#39;: 4.693176737, &#39;mse&#39;: 35.3248361437}
Epoch:  574 -  {&#39;cxe+mse&#39;: 39.9923602316, &#39;cxe&#39;: 4.6930622857, &#39;mse&#39;: 35.2992979459}
Epoch:  575 -  {&#39;cxe+mse&#39;: 39.96674049240001, &#39;cxe&#39;: 4.6929478345, &#39;mse&#39;: 35.2737926579}
Epoch:  576 -  {&#39;cxe+mse&#39;: 39.941153603800004, &#39;cxe&#39;: 4.6928333832, &#39;mse&#39;: 35.2483202206}
Epoch:  577 -  {&#39;cxe+mse&#39;: 39.9155995069, &#39;cxe&#39;: 4.692718932, &#39;mse&#39;: 35.2228805749}
Epoch:  578 -  {&#39;cxe+mse&#39;: 39.8900781428, &#39;cxe&#39;: 4.6926044808, &#39;mse&#39;: 35.197473662}
Epoch:  579 -  {&#39;cxe+mse&#39;: 39.8645894526, &#39;cxe&#39;: 4.6924900295, &#39;mse&#39;: 35.1720994231}
Epoch:  580 -  {&#39;cxe+mse&#39;: 39.8391333778, &#39;cxe&#39;: 4.6923755783, &#39;mse&#39;: 35.1467577995}
Epoch:  581 -  {&#39;cxe+mse&#39;: 39.81370986, &#39;cxe&#39;: 4.6922611271, &#39;mse&#39;: 35.1214487329}
Epoch:  582 -  {&#39;cxe+mse&#39;: 39.788318840399995, &#39;cxe&#39;: 4.6921466758, &#39;mse&#39;: 35.0961721646}
Epoch:  583 -  {&#39;cxe+mse&#39;: 39.7629602612, &#39;cxe&#39;: 4.6920322246, &#39;mse&#39;: 35.0709280366}
Epoch:  584 -  {&#39;cxe+mse&#39;: 39.737634064, &#39;cxe&#39;: 4.6919177734, &#39;mse&#39;: 35.0457162906}
Epoch:  585 -  {&#39;cxe+mse&#39;: 39.7123401907, &#39;cxe&#39;: 4.6918033221, &#39;mse&#39;: 35.0205368686}
Epoch:  586 -  {&#39;cxe+mse&#39;: 39.6870785835, &#39;cxe&#39;: 4.6916888709, &#39;mse&#39;: 34.9953897126}
Epoch:  587 -  {&#39;cxe+mse&#39;: 39.6618491846, &#39;cxe&#39;: 4.6915744197, &#39;mse&#39;: 34.9702747649}
Epoch:  588 -  {&#39;cxe+mse&#39;: 39.6366519363, &#39;cxe&#39;: 4.6914599685, &#39;mse&#39;: 34.9451919678}
Epoch:  589 -  {&#39;cxe+mse&#39;: 39.611486781, &#39;cxe&#39;: 4.6913455173, &#39;mse&#39;: 34.9201412637}
Epoch:  590 -  {&#39;cxe+mse&#39;: 39.5863536612, &#39;cxe&#39;: 4.6912310661, &#39;mse&#39;: 34.8951225951}
Epoch:  591 -  {&#39;cxe+mse&#39;: 39.56125251980001, &#39;cxe&#39;: 4.6911166149, &#39;mse&#39;: 34.8701359049}
Epoch:  592 -  {&#39;cxe+mse&#39;: 39.5361832994, &#39;cxe&#39;: 4.6910021637, &#39;mse&#39;: 34.8451811357}
Epoch:  593 -  {&#39;cxe+mse&#39;: 39.511145943, &#39;cxe&#39;: 4.6908877125, &#39;mse&#39;: 34.8202582305}
Epoch:  594 -  {&#39;cxe+mse&#39;: 39.4861403936, &#39;cxe&#39;: 4.6907732613, &#39;mse&#39;: 34.7953671323}
Epoch:  595 -  {&#39;cxe+mse&#39;: 39.461166594299996, &#39;cxe&#39;: 4.6906588101, &#39;mse&#39;: 34.7705077842}
Epoch:  596 -  {&#39;cxe+mse&#39;: 39.4362244884, &#39;cxe&#39;: 4.6905443589, &#39;mse&#39;: 34.7456801295}
Epoch:  597 -  {&#39;cxe+mse&#39;: 39.4113140194, &#39;cxe&#39;: 4.6904299077, &#39;mse&#39;: 34.7208841117}
Epoch:  598 -  {&#39;cxe+mse&#39;: 39.3864351306, &#39;cxe&#39;: 4.6903154565, &#39;mse&#39;: 34.6961196741}
Epoch:  599 -  {&#39;cxe+mse&#39;: 39.361587765799996, &#39;cxe&#39;: 4.6902010053, &#39;mse&#39;: 34.6713867605}
Epoch:  600 -  {&#39;cxe+mse&#39;: 39.3367718687, &#39;cxe&#39;: 4.6900865542, &#39;mse&#39;: 34.6466853145}
Epoch:  601 -  {&#39;cxe+mse&#39;: 39.311987383, &#39;cxe&#39;: 4.689972103, &#39;mse&#39;: 34.62201528}
Epoch:  602 -  {&#39;cxe+mse&#39;: 39.287234252699996, &#39;cxe&#39;: 4.6898576518, &#39;mse&#39;: 34.5973766009}
Epoch:  603 -  {&#39;cxe+mse&#39;: 39.262512422, &#39;cxe&#39;: 4.6897432006, &#39;mse&#39;: 34.5727692214}
Epoch:  604 -  {&#39;cxe+mse&#39;: 39.2378218351, &#39;cxe&#39;: 4.6896287495, &#39;mse&#39;: 34.5481930856}
Epoch:  605 -  {&#39;cxe+mse&#39;: 39.213162436199994, &#39;cxe&#39;: 4.6895142983, &#39;mse&#39;: 34.5236481379}
Epoch:  606 -  {&#39;cxe+mse&#39;: 39.1885341697, &#39;cxe&#39;: 4.6893998471, &#39;mse&#39;: 34.4991343226}
Epoch:  607 -  {&#39;cxe+mse&#39;: 39.1639369804, &#39;cxe&#39;: 4.689285396, &#39;mse&#39;: 34.4746515844}
Epoch:  608 -  {&#39;cxe+mse&#39;: 39.1393708125, &#39;cxe&#39;: 4.6891709448, &#39;mse&#39;: 34.4501998677}
Epoch:  609 -  {&#39;cxe+mse&#39;: 39.1148356112, &#39;cxe&#39;: 4.6890564937, &#39;mse&#39;: 34.4257791175}
Epoch:  610 -  {&#39;cxe+mse&#39;: 39.090331321200004, &#39;cxe&#39;: 4.6889420425, &#39;mse&#39;: 34.4013892787}
Epoch:  611 -  {&#39;cxe+mse&#39;: 39.0658578875, &#39;cxe&#39;: 4.6888275914, &#39;mse&#39;: 34.3770302961}
Epoch:  612 -  {&#39;cxe+mse&#39;: 39.0414152551, &#39;cxe&#39;: 4.6887131402, &#39;mse&#39;: 34.3527021149}
Epoch:  613 -  {&#39;cxe+mse&#39;: 39.017003369399994, &#39;cxe&#39;: 4.6885986891, &#39;mse&#39;: 34.3284046803}
Epoch:  614 -  {&#39;cxe+mse&#39;: 38.9926221757, &#39;cxe&#39;: 4.688484238, &#39;mse&#39;: 34.3041379377}
Epoch:  615 -  {&#39;cxe+mse&#39;: 38.968271619300005, &#39;cxe&#39;: 4.6883697868, &#39;mse&#39;: 34.2799018325}
Epoch:  616 -  {&#39;cxe+mse&#39;: 38.943951646, &#39;cxe&#39;: 4.6882553357, &#39;mse&#39;: 34.2556963103}
Epoch:  617 -  {&#39;cxe+mse&#39;: 38.919662201200005, &#39;cxe&#39;: 4.6881408846, &#39;mse&#39;: 34.2315213166}
Epoch:  618 -  {&#39;cxe+mse&#39;: 38.8954032308, &#39;cxe&#39;: 4.6880264334, &#39;mse&#39;: 34.2073767974}
Epoch:  619 -  {&#39;cxe+mse&#39;: 38.8711746808, &#39;cxe&#39;: 4.6879119823, &#39;mse&#39;: 34.1832626985}
Epoch:  620 -  {&#39;cxe+mse&#39;: 38.846976497099995, &#39;cxe&#39;: 4.6877975312, &#39;mse&#39;: 34.1591789659}
Epoch:  621 -  {&#39;cxe+mse&#39;: 38.8228086259, &#39;cxe&#39;: 4.6876830801, &#39;mse&#39;: 34.1351255458}
Epoch:  622 -  {&#39;cxe+mse&#39;: 38.798671013299995, &#39;cxe&#39;: 4.687568629, &#39;mse&#39;: 34.1111023843}
Epoch:  623 -  {&#39;cxe+mse&#39;: 38.7745636056, &#39;cxe&#39;: 4.6874541778, &#39;mse&#39;: 34.0871094278}
Epoch:  624 -  {&#39;cxe+mse&#39;: 38.750486349400006, &#39;cxe&#39;: 4.6873397267, &#39;mse&#39;: 34.0631466227}
Epoch:  625 -  {&#39;cxe+mse&#39;: 38.7264391912, &#39;cxe&#39;: 4.6872252756, &#39;mse&#39;: 34.0392139156}
Epoch:  626 -  {&#39;cxe+mse&#39;: 38.702422077600005, &#39;cxe&#39;: 4.6871108245, &#39;mse&#39;: 34.0153112531}
Epoch:  627 -  {&#39;cxe+mse&#39;: 38.6784349555, &#39;cxe&#39;: 4.6869963734, &#39;mse&#39;: 33.9914385821}
Epoch:  628 -  {&#39;cxe+mse&#39;: 38.6544777718, &#39;cxe&#39;: 4.6868819223, &#39;mse&#39;: 33.9675958495}
Epoch:  629 -  {&#39;cxe+mse&#39;: 38.6305504733, &#39;cxe&#39;: 4.6867674712, &#39;mse&#39;: 33.9437830021}
Epoch:  630 -  {&#39;cxe+mse&#39;: 38.6066530073, &#39;cxe&#39;: 4.6866530201, &#39;mse&#39;: 33.9199999872}
Epoch:  631 -  {&#39;cxe+mse&#39;: 38.5827853209, &#39;cxe&#39;: 4.686538569, &#39;mse&#39;: 33.8962467519}
Epoch:  632 -  {&#39;cxe+mse&#39;: 38.558947361499996, &#39;cxe&#39;: 4.686424118, &#39;mse&#39;: 33.8725232435}
Epoch:  633 -  {&#39;cxe+mse&#39;: 38.5351390765, &#39;cxe&#39;: 4.6863096669, &#39;mse&#39;: 33.8488294096}
Epoch:  634 -  {&#39;cxe+mse&#39;: 38.5113604133, &#39;cxe&#39;: 4.6861952158, &#39;mse&#39;: 33.8251651975}
Epoch:  635 -  {&#39;cxe+mse&#39;: 38.4876113198, &#39;cxe&#39;: 4.6860807647, &#39;mse&#39;: 33.8015305551}
Epoch:  636 -  {&#39;cxe+mse&#39;: 38.4638917435, &#39;cxe&#39;: 4.6859663136, &#39;mse&#39;: 33.7779254299}
Epoch:  637 -  {&#39;cxe+mse&#39;: 38.440201632599994, &#39;cxe&#39;: 4.6858518626, &#39;mse&#39;: 33.75434977}
Epoch:  638 -  {&#39;cxe+mse&#39;: 38.4165409347, &#39;cxe&#39;: 4.6857374115, &#39;mse&#39;: 33.7308035232}
Epoch:  639 -  {&#39;cxe+mse&#39;: 38.392909598, &#39;cxe&#39;: 4.6856229604, &#39;mse&#39;: 33.7072866376}
Epoch:  640 -  {&#39;cxe+mse&#39;: 38.369307570800004, &#39;cxe&#39;: 4.6855085094, &#39;mse&#39;: 33.6837990614}
Epoch:  641 -  {&#39;cxe+mse&#39;: 38.345734801199995, &#39;cxe&#39;: 4.6853940583, &#39;mse&#39;: 33.6603407429}
Epoch:  642 -  {&#39;cxe+mse&#39;: 38.322191237700004, &#39;cxe&#39;: 4.6852796072, &#39;mse&#39;: 33.6369116305}
Epoch:  643 -  {&#39;cxe+mse&#39;: 38.2986768289, &#39;cxe&#39;: 4.6851651562, &#39;mse&#39;: 33.6135116727}
Epoch:  644 -  {&#39;cxe+mse&#39;: 38.275191523100005, &#39;cxe&#39;: 4.6850507051, &#39;mse&#39;: 33.590140818}
Epoch:  645 -  {&#39;cxe+mse&#39;: 38.2517352694, &#39;cxe&#39;: 4.6849362541, &#39;mse&#39;: 33.5667990153}
Epoch:  646 -  {&#39;cxe+mse&#39;: 38.2283080163, &#39;cxe&#39;: 4.684821803, &#39;mse&#39;: 33.5434862133}
Epoch:  647 -  {&#39;cxe+mse&#39;: 38.204909712900005, &#39;cxe&#39;: 4.684707352, &#39;mse&#39;: 33.5202023609}
Epoch:  648 -  {&#39;cxe+mse&#39;: 38.1815403082, &#39;cxe&#39;: 4.684592901, &#39;mse&#39;: 33.4969474072}
Epoch:  649 -  {&#39;cxe+mse&#39;: 38.1581997511, &#39;cxe&#39;: 4.6844784499, &#39;mse&#39;: 33.4737213012}
Epoch:  650 -  {&#39;cxe+mse&#39;: 38.1348879912, &#39;cxe&#39;: 4.6843639989, &#39;mse&#39;: 33.4505239923}
Epoch:  651 -  {&#39;cxe+mse&#39;: 38.111604977700004, &#39;cxe&#39;: 4.6842495479, &#39;mse&#39;: 33.4273554298}
Epoch:  652 -  {&#39;cxe+mse&#39;: 38.0883506598, &#39;cxe&#39;: 4.6841350968, &#39;mse&#39;: 33.404215563}
Epoch:  653 -  {&#39;cxe+mse&#39;: 38.0651249874, &#39;cxe&#39;: 4.6840206458, &#39;mse&#39;: 33.3811043416}
Epoch:  654 -  {&#39;cxe+mse&#39;: 38.041927910000005, &#39;cxe&#39;: 4.6839061948, &#39;mse&#39;: 33.3580217152}
Epoch:  655 -  {&#39;cxe+mse&#39;: 38.0187593774, &#39;cxe&#39;: 4.6837917438, &#39;mse&#39;: 33.3349676336}
Epoch:  656 -  {&#39;cxe+mse&#39;: 37.9956193393, &#39;cxe&#39;: 4.6836772927, &#39;mse&#39;: 33.3119420466}
Epoch:  657 -  {&#39;cxe+mse&#39;: 37.9725077458, &#39;cxe&#39;: 4.6835628417, &#39;mse&#39;: 33.2889449041}
Epoch:  658 -  {&#39;cxe+mse&#39;: 37.9494245469, &#39;cxe&#39;: 4.6834483907, &#39;mse&#39;: 33.2659761562}
Epoch:  659 -  {&#39;cxe+mse&#39;: 37.926369692899996, &#39;cxe&#39;: 4.6833339397, &#39;mse&#39;: 33.2430357532}
Epoch:  660 -  {&#39;cxe+mse&#39;: 37.9033431338, &#39;cxe&#39;: 4.6832194887, &#39;mse&#39;: 33.2201236451}
Epoch:  661 -  {&#39;cxe+mse&#39;: 37.8803448202, &#39;cxe&#39;: 4.6831050377, &#39;mse&#39;: 33.1972397825}
Epoch:  662 -  {&#39;cxe+mse&#39;: 37.8573747025, &#39;cxe&#39;: 4.6829905867, &#39;mse&#39;: 33.1743841158}
Epoch:  663 -  {&#39;cxe+mse&#39;: 37.8344327313, &#39;cxe&#39;: 4.6828761357, &#39;mse&#39;: 33.1515565956}
Epoch:  664 -  {&#39;cxe+mse&#39;: 37.8115188571, &#39;cxe&#39;: 4.6827616847, &#39;mse&#39;: 33.1287571724}
Epoch:  665 -  {&#39;cxe+mse&#39;: 37.7886330309, &#39;cxe&#39;: 4.6826472337, &#39;mse&#39;: 33.1059857972}
Epoch:  666 -  {&#39;cxe+mse&#39;: 37.7657752035, &#39;cxe&#39;: 4.6825327827, &#39;mse&#39;: 33.0832424208}
Epoch:  667 -  {&#39;cxe+mse&#39;: 37.7429453258, &#39;cxe&#39;: 4.6824183317, &#39;mse&#39;: 33.0605269941}
Epoch:  668 -  {&#39;cxe+mse&#39;: 37.720143349, &#39;cxe&#39;: 4.6823038808, &#39;mse&#39;: 33.0378394682}
Epoch:  669 -  {&#39;cxe+mse&#39;: 37.6973692241, &#39;cxe&#39;: 4.6821894298, &#39;mse&#39;: 33.0151797943}
Epoch:  670 -  {&#39;cxe+mse&#39;: 37.6746229024, &#39;cxe&#39;: 4.6820749788, &#39;mse&#39;: 32.9925479236}
Epoch:  671 -  {&#39;cxe+mse&#39;: 37.6519043355, &#39;cxe&#39;: 4.6819605278, &#39;mse&#39;: 32.9699438077}
Epoch:  672 -  {&#39;cxe+mse&#39;: 37.6292134747, &#39;cxe&#39;: 4.6818460769, &#39;mse&#39;: 32.9473673978}
Epoch:  673 -  {&#39;cxe+mse&#39;: 37.6065502715, &#39;cxe&#39;: 4.6817316259, &#39;mse&#39;: 32.9248186456}
Epoch:  674 -  {&#39;cxe+mse&#39;: 37.5839146777, &#39;cxe&#39;: 4.6816171749, &#39;mse&#39;: 32.9022975028}
Epoch:  675 -  {&#39;cxe+mse&#39;: 37.561306644999995, &#39;cxe&#39;: 4.681502724, &#39;mse&#39;: 32.879803921}
Epoch:  676 -  {&#39;cxe+mse&#39;: 37.5387261253, &#39;cxe&#39;: 4.681388273, &#39;mse&#39;: 32.8573378523}
Epoch:  677 -  {&#39;cxe+mse&#39;: 37.516173070700006, &#39;cxe&#39;: 4.6812738221, &#39;mse&#39;: 32.8348992486}
Epoch:  678 -  {&#39;cxe+mse&#39;: 37.493647433, &#39;cxe&#39;: 4.6811593711, &#39;mse&#39;: 32.8124880619}
Epoch:  679 -  {&#39;cxe+mse&#39;: 37.4711491645, &#39;cxe&#39;: 4.6810449202, &#39;mse&#39;: 32.7901042443}
Epoch:  680 -  {&#39;cxe+mse&#39;: 37.4486782174, &#39;cxe&#39;: 4.6809304692, &#39;mse&#39;: 32.7677477482}
Epoch:  681 -  {&#39;cxe+mse&#39;: 37.4262345443, &#39;cxe&#39;: 4.6808160183, &#39;mse&#39;: 32.745418526}
Epoch:  682 -  {&#39;cxe+mse&#39;: 37.403818097199995, &#39;cxe&#39;: 4.6807015673, &#39;mse&#39;: 32.7231165299}
Epoch:  683 -  {&#39;cxe+mse&#39;: 37.3814288292, &#39;cxe&#39;: 4.6805871164, &#39;mse&#39;: 32.7008417128}
Epoch:  684 -  {&#39;cxe+mse&#39;: 37.359066692400006, &#39;cxe&#39;: 4.6804726654, &#39;mse&#39;: 32.678594027}
Epoch:  685 -  {&#39;cxe+mse&#39;: 37.336731639999996, &#39;cxe&#39;: 4.6803582145, &#39;mse&#39;: 32.6563734255}
Epoch:  686 -  {&#39;cxe+mse&#39;: 37.3144236247, &#39;cxe&#39;: 4.6802437636, &#39;mse&#39;: 32.6341798611}
Epoch:  687 -  {&#39;cxe+mse&#39;: 37.29214259930001, &#39;cxe&#39;: 4.6801293127, &#39;mse&#39;: 32.6120132866}
Epoch:  688 -  {&#39;cxe+mse&#39;: 37.269888516900004, &#39;cxe&#39;: 4.6800148617, &#39;mse&#39;: 32.5898736552}
Epoch:  689 -  {&#39;cxe+mse&#39;: 37.247661330700005, &#39;cxe&#39;: 4.6799004108, &#39;mse&#39;: 32.5677609199}
Epoch:  690 -  {&#39;cxe+mse&#39;: 37.225460994, &#39;cxe&#39;: 4.6797859599, &#39;mse&#39;: 32.5456750341}
Epoch:  691 -  {&#39;cxe+mse&#39;: 37.203287459900004, &#39;cxe&#39;: 4.679671509, &#39;mse&#39;: 32.5236159509}
Epoch:  692 -  {&#39;cxe+mse&#39;: 37.181140682, &#39;cxe&#39;: 4.6795570581, &#39;mse&#39;: 32.5015836239}
Epoch:  693 -  {&#39;cxe+mse&#39;: 37.1590206137, &#39;cxe&#39;: 4.6794426072, &#39;mse&#39;: 32.4795780065}
Epoch:  694 -  {&#39;cxe+mse&#39;: 37.1369272087, &#39;cxe&#39;: 4.6793281563, &#39;mse&#39;: 32.4575990524}
Epoch:  695 -  {&#39;cxe+mse&#39;: 37.1148604206, &#39;cxe&#39;: 4.6792137054, &#39;mse&#39;: 32.4356467152}
Epoch:  696 -  {&#39;cxe+mse&#39;: 37.0928202033, &#39;cxe&#39;: 4.6790992545, &#39;mse&#39;: 32.4137209488}
Epoch:  697 -  {&#39;cxe+mse&#39;: 37.0708065106, &#39;cxe&#39;: 4.6789848036, &#39;mse&#39;: 32.391821707}
Epoch:  698 -  {&#39;cxe+mse&#39;: 37.0488192966, &#39;cxe&#39;: 4.6788703527, &#39;mse&#39;: 32.3699489439}
Epoch:  699 -  {&#39;cxe+mse&#39;: 37.026858515200004, &#39;cxe&#39;: 4.6787559018, &#39;mse&#39;: 32.3481026134}
Epoch:  700 -  {&#39;cxe+mse&#39;: 37.004924120700004, &#39;cxe&#39;: 4.6786414509, &#39;mse&#39;: 32.3262826698}
Epoch:  701 -  {&#39;cxe+mse&#39;: 36.9830160674, &#39;cxe&#39;: 4.678527, &#39;mse&#39;: 32.3044890674}
Epoch:  702 -  {&#39;cxe+mse&#39;: 36.961134309600006, &#39;cxe&#39;: 4.6784125491, &#39;mse&#39;: 32.2827217605}
Epoch:  703 -  {&#39;cxe+mse&#39;: 36.939278801700006, &#39;cxe&#39;: 4.6782980982, &#39;mse&#39;: 32.2609807035}
Epoch:  704 -  {&#39;cxe+mse&#39;: 36.9174494985, &#39;cxe&#39;: 4.6781836474, &#39;mse&#39;: 32.2392658511}
Epoch:  705 -  {&#39;cxe+mse&#39;: 36.8956463543, &#39;cxe&#39;: 4.6780691965, &#39;mse&#39;: 32.2175771578}
Epoch:  706 -  {&#39;cxe+mse&#39;: 36.873869323899996, &#39;cxe&#39;: 4.6779547456, &#39;mse&#39;: 32.1959145783}
Epoch:  707 -  {&#39;cxe+mse&#39;: 36.852118362199995, &#39;cxe&#39;: 4.6778402947, &#39;mse&#39;: 32.1742780675}
Epoch:  708 -  {&#39;cxe+mse&#39;: 36.8303934243, &#39;cxe&#39;: 4.6777258439, &#39;mse&#39;: 32.1526675804}
Epoch:  709 -  {&#39;cxe+mse&#39;: 36.8086944648, &#39;cxe&#39;: 4.677611393, &#39;mse&#39;: 32.1310830718}
Epoch:  710 -  {&#39;cxe+mse&#39;: 36.787021439200004, &#39;cxe&#39;: 4.6774969422, &#39;mse&#39;: 32.109524497}
Epoch:  711 -  {&#39;cxe+mse&#39;: 36.7653743024, &#39;cxe&#39;: 4.6773824913, &#39;mse&#39;: 32.0879918111}
Epoch:  712 -  {&#39;cxe+mse&#39;: 36.7437530098, &#39;cxe&#39;: 4.6772680405, &#39;mse&#39;: 32.0664849693}
Epoch:  713 -  {&#39;cxe+mse&#39;: 36.722157516699994, &#39;cxe&#39;: 4.6771535896, &#39;mse&#39;: 32.0450039271}
Epoch:  714 -  {&#39;cxe+mse&#39;: 36.7005877787, &#39;cxe&#39;: 4.6770391388, &#39;mse&#39;: 32.0235486399}
Epoch:  715 -  {&#39;cxe+mse&#39;: 36.6790437512, &#39;cxe&#39;: 4.6769246879, &#39;mse&#39;: 32.0021190633}
Epoch:  716 -  {&#39;cxe+mse&#39;: 36.65752539, &#39;cxe&#39;: 4.6768102371, &#39;mse&#39;: 31.9807151529}
Epoch:  717 -  {&#39;cxe+mse&#39;: 36.6360326506, &#39;cxe&#39;: 4.6766957862, &#39;mse&#39;: 31.9593368644}
Epoch:  718 -  {&#39;cxe+mse&#39;: 36.6145654891, &#39;cxe&#39;: 4.6765813354, &#39;mse&#39;: 31.9379841537}
Epoch:  719 -  {&#39;cxe+mse&#39;: 36.5931238613, &#39;cxe&#39;: 4.6764668846, &#39;mse&#39;: 31.9166569767}
Epoch:  720 -  {&#39;cxe+mse&#39;: 36.571707723, &#39;cxe&#39;: 4.6763524337, &#39;mse&#39;: 31.8953552893}
Epoch:  721 -  {&#39;cxe+mse&#39;: 36.5503170307, &#39;cxe&#39;: 4.6762379829, &#39;mse&#39;: 31.8740790478}
Epoch:  722 -  {&#39;cxe+mse&#39;: 36.5289517403, &#39;cxe&#39;: 4.6761235321, &#39;mse&#39;: 31.8528282082}
Epoch:  723 -  {&#39;cxe+mse&#39;: 36.5076118081, &#39;cxe&#39;: 4.6760090813, &#39;mse&#39;: 31.8316027268}
Epoch:  724 -  {&#39;cxe+mse&#39;: 36.4862971904, &#39;cxe&#39;: 4.6758946304, &#39;mse&#39;: 31.81040256}
Epoch:  725 -  {&#39;cxe+mse&#39;: 36.4650078439, &#39;cxe&#39;: 4.6757801796, &#39;mse&#39;: 31.7892276643}
Epoch:  726 -  {&#39;cxe+mse&#39;: 36.4437437249, &#39;cxe&#39;: 4.6756657288, &#39;mse&#39;: 31.7680779961}
Epoch:  727 -  {&#39;cxe+mse&#39;: 36.4225047902, &#39;cxe&#39;: 4.675551278, &#39;mse&#39;: 31.7469535122}
Epoch:  728 -  {&#39;cxe+mse&#39;: 36.4012909963, &#39;cxe&#39;: 4.6754368272, &#39;mse&#39;: 31.7258541691}
Epoch:  729 -  {&#39;cxe+mse&#39;: 36.3801023002, &#39;cxe&#39;: 4.6753223764, &#39;mse&#39;: 31.7047799238}
Epoch:  730 -  {&#39;cxe+mse&#39;: 36.3589386587, &#39;cxe&#39;: 4.6752079256, &#39;mse&#39;: 31.6837307331}
Epoch:  731 -  {&#39;cxe+mse&#39;: 36.3378000288, &#39;cxe&#39;: 4.6750934748, &#39;mse&#39;: 31.662706554}
Epoch:  732 -  {&#39;cxe+mse&#39;: 36.3166863675, &#39;cxe&#39;: 4.674979024, &#39;mse&#39;: 31.6417073435}
Epoch:  733 -  {&#39;cxe+mse&#39;: 36.295597631999996, &#39;cxe&#39;: 4.6748645732, &#39;mse&#39;: 31.6207330588}
Epoch:  734 -  {&#39;cxe+mse&#39;: 36.2745337796, &#39;cxe&#39;: 4.6747501224, &#39;mse&#39;: 31.5997836572}
Epoch:  735 -  {&#39;cxe+mse&#39;: 36.253494767599996, &#39;cxe&#39;: 4.6746356716, &#39;mse&#39;: 31.578859096}
Epoch:  736 -  {&#39;cxe+mse&#39;: 36.2324805534, &#39;cxe&#39;: 4.6745212209, &#39;mse&#39;: 31.5579593325}
Epoch:  737 -  {&#39;cxe+mse&#39;: 36.2114910944, &#39;cxe&#39;: 4.6744067701, &#39;mse&#39;: 31.5370843243}
Epoch:  738 -  {&#39;cxe+mse&#39;: 36.1905263482, &#39;cxe&#39;: 4.6742923193, &#39;mse&#39;: 31.5162340289}
Epoch:  739 -  {&#39;cxe+mse&#39;: 36.1695862726, &#39;cxe&#39;: 4.6741778685, &#39;mse&#39;: 31.4954084041}
Epoch:  740 -  {&#39;cxe+mse&#39;: 36.1486708254, &#39;cxe&#39;: 4.6740634178, &#39;mse&#39;: 31.4746074076}
Epoch:  741 -  {&#39;cxe+mse&#39;: 36.1277799642, &#39;cxe&#39;: 4.673948967, &#39;mse&#39;: 31.4538309972}
Epoch:  742 -  {&#39;cxe+mse&#39;: 36.1069136471, &#39;cxe&#39;: 4.6738345162, &#39;mse&#39;: 31.4330791309}
Epoch:  743 -  {&#39;cxe+mse&#39;: 36.0860718322, &#39;cxe&#39;: 4.6737200655, &#39;mse&#39;: 31.4123517667}
Epoch:  744 -  {&#39;cxe+mse&#39;: 36.0652544773, &#39;cxe&#39;: 4.6736056147, &#39;mse&#39;: 31.3916488626}
Epoch:  745 -  {&#39;cxe+mse&#39;: 36.0444615409, &#39;cxe&#39;: 4.673491164, &#39;mse&#39;: 31.3709703769}
Epoch:  746 -  {&#39;cxe+mse&#39;: 36.023692980999996, &#39;cxe&#39;: 4.6733767132, &#39;mse&#39;: 31.3503162678}
Epoch:  747 -  {&#39;cxe+mse&#39;: 36.0029487562, &#39;cxe&#39;: 4.6732622625, &#39;mse&#39;: 31.3296864937}
Epoch:  748 -  {&#39;cxe+mse&#39;: 35.9822288247, &#39;cxe&#39;: 4.6731478117, &#39;mse&#39;: 31.309081013}
Epoch:  749 -  {&#39;cxe+mse&#39;: 35.9615331453, &#39;cxe&#39;: 4.673033361, &#39;mse&#39;: 31.2884997843}
Epoch:  750 -  {&#39;cxe+mse&#39;: 35.9408616763, &#39;cxe&#39;: 4.6729189102, &#39;mse&#39;: 31.2679427661}
Epoch:  751 -  {&#39;cxe+mse&#39;: 35.9202143766, &#39;cxe&#39;: 4.6728044595, &#39;mse&#39;: 31.2474099171}
Epoch:  752 -  {&#39;cxe+mse&#39;: 35.8995912049, &#39;cxe&#39;: 4.6726900088, &#39;mse&#39;: 31.2269011961}
Epoch:  753 -  {&#39;cxe+mse&#39;: 35.87899212, &#39;cxe&#39;: 4.672575558, &#39;mse&#39;: 31.206416562}
Epoch:  754 -  {&#39;cxe+mse&#39;: 35.858417081, &#39;cxe&#39;: 4.6724611073, &#39;mse&#39;: 31.1859559737}
Epoch:  755 -  {&#39;cxe+mse&#39;: 35.8378660469, &#39;cxe&#39;: 4.6723466566, &#39;mse&#39;: 31.1655193903}
Epoch:  756 -  {&#39;cxe+mse&#39;: 35.8173389766, &#39;cxe&#39;: 4.6722322058, &#39;mse&#39;: 31.1451067708}
Epoch:  757 -  {&#39;cxe+mse&#39;: 35.796835829399996, &#39;cxe&#39;: 4.6721177551, &#39;mse&#39;: 31.1247180743}
Epoch:  758 -  {&#39;cxe+mse&#39;: 35.7763565647, &#39;cxe&#39;: 4.6720033044, &#39;mse&#39;: 31.1043532603}
Epoch:  759 -  {&#39;cxe+mse&#39;: 35.755901141799995, &#39;cxe&#39;: 4.6718888537, &#39;mse&#39;: 31.0840122881}
Epoch:  760 -  {&#39;cxe+mse&#39;: 35.73546952, &#39;cxe&#39;: 4.671774403, &#39;mse&#39;: 31.063695117}
Epoch:  761 -  {&#39;cxe+mse&#39;: 35.7150616589, &#39;cxe&#39;: 4.6716599523, &#39;mse&#39;: 31.0434017066}
Epoch:  762 -  {&#39;cxe+mse&#39;: 35.6946775182, &#39;cxe&#39;: 4.6715455016, &#39;mse&#39;: 31.0231320166}
Epoch:  763 -  {&#39;cxe+mse&#39;: 35.674317057399996, &#39;cxe&#39;: 4.6714310509, &#39;mse&#39;: 31.0028860065}
Epoch:  764 -  {&#39;cxe+mse&#39;: 35.6539802364, &#39;cxe&#39;: 4.6713166002, &#39;mse&#39;: 30.9826636362}
Epoch:  765 -  {&#39;cxe+mse&#39;: 35.6336670149, &#39;cxe&#39;: 4.6712021495, &#39;mse&#39;: 30.9624648654}
Epoch:  766 -  {&#39;cxe+mse&#39;: 35.613377353, &#39;cxe&#39;: 4.6710876988, &#39;mse&#39;: 30.9422896542}
Epoch:  767 -  {&#39;cxe+mse&#39;: 35.5931112107, &#39;cxe&#39;: 4.6709732481, &#39;mse&#39;: 30.9221379626}
Epoch:  768 -  {&#39;cxe+mse&#39;: 35.5728685479, &#39;cxe&#39;: 4.6708587974, &#39;mse&#39;: 30.9020097505}
Epoch:  769 -  {&#39;cxe+mse&#39;: 35.5526493249, &#39;cxe&#39;: 4.6707443467, &#39;mse&#39;: 30.8819049782}
Epoch:  770 -  {&#39;cxe+mse&#39;: 35.532453502, &#39;cxe&#39;: 4.670629896, &#39;mse&#39;: 30.861823606}
Epoch:  771 -  {&#39;cxe+mse&#39;: 35.5122810395, &#39;cxe&#39;: 4.6705154454, &#39;mse&#39;: 30.8417655941}
Epoch:  772 -  {&#39;cxe+mse&#39;: 35.4921318978, &#39;cxe&#39;: 4.6704009947, &#39;mse&#39;: 30.8217309031}
Epoch:  773 -  {&#39;cxe+mse&#39;: 35.4720060372, &#39;cxe&#39;: 4.670286544, &#39;mse&#39;: 30.8017194932}
Epoch:  774 -  {&#39;cxe+mse&#39;: 35.4519034187, &#39;cxe&#39;: 4.6701720934, &#39;mse&#39;: 30.7817313253}
Epoch:  775 -  {&#39;cxe+mse&#39;: 35.4318240025, &#39;cxe&#39;: 4.6700576427, &#39;mse&#39;: 30.7617663598}
Epoch:  776 -  {&#39;cxe+mse&#39;: 35.4117677495, &#39;cxe&#39;: 4.669943192, &#39;mse&#39;: 30.7418245575}
Epoch:  777 -  {&#39;cxe+mse&#39;: 35.3917346207, &#39;cxe&#39;: 4.6698287414, &#39;mse&#39;: 30.7219058793}
Epoch:  778 -  {&#39;cxe+mse&#39;: 35.3717245766, &#39;cxe&#39;: 4.6697142907, &#39;mse&#39;: 30.7020102859}
Epoch:  779 -  {&#39;cxe+mse&#39;: 35.3517375786, &#39;cxe&#39;: 4.6695998401, &#39;mse&#39;: 30.6821377385}
Epoch:  780 -  {&#39;cxe+mse&#39;: 35.3317735873, &#39;cxe&#39;: 4.6694853894, &#39;mse&#39;: 30.6622881979}
Epoch:  781 -  {&#39;cxe+mse&#39;: 35.3118325642, &#39;cxe&#39;: 4.6693709388, &#39;mse&#39;: 30.6424616254}
Epoch:  782 -  {&#39;cxe+mse&#39;: 35.2919144703, &#39;cxe&#39;: 4.6692564881, &#39;mse&#39;: 30.6226579822}
Epoch:  783 -  {&#39;cxe+mse&#39;: 35.272019267, &#39;cxe&#39;: 4.6691420375, &#39;mse&#39;: 30.6028772295}
Epoch:  784 -  {&#39;cxe+mse&#39;: 35.2521469155, &#39;cxe&#39;: 4.6690275868, &#39;mse&#39;: 30.5831193287}
Epoch:  785 -  {&#39;cxe+mse&#39;: 35.2322973774, &#39;cxe&#39;: 4.6689131362, &#39;mse&#39;: 30.5633842412}
Epoch:  786 -  {&#39;cxe+mse&#39;: 35.2124706141, &#39;cxe&#39;: 4.6687986856, &#39;mse&#39;: 30.5436719285}
Epoch:  787 -  {&#39;cxe+mse&#39;: 35.1926665872, &#39;cxe&#39;: 4.6686842349, &#39;mse&#39;: 30.5239823523}
Epoch:  788 -  {&#39;cxe+mse&#39;: 35.172885258499996, &#39;cxe&#39;: 4.6685697843, &#39;mse&#39;: 30.5043154742}
Epoch:  789 -  {&#39;cxe+mse&#39;: 35.1531265897, &#39;cxe&#39;: 4.6684553337, &#39;mse&#39;: 30.484671256}
Epoch:  790 -  {&#39;cxe+mse&#39;: 35.1333905425, &#39;cxe&#39;: 4.6683408831, &#39;mse&#39;: 30.4650496594}
Epoch:  791 -  {&#39;cxe+mse&#39;: 35.1136770788, &#39;cxe&#39;: 4.6682264324, &#39;mse&#39;: 30.4454506464}
Epoch:  792 -  {&#39;cxe+mse&#39;: 35.0939861607, &#39;cxe&#39;: 4.6681119818, &#39;mse&#39;: 30.4258741789}
Epoch:  793 -  {&#39;cxe+mse&#39;: 35.0743177503, &#39;cxe&#39;: 4.6679975312, &#39;mse&#39;: 30.4063202191}
Epoch:  794 -  {&#39;cxe+mse&#39;: 35.0546718096, &#39;cxe&#39;: 4.6678830806, &#39;mse&#39;: 30.386788729}
Epoch:  795 -  {&#39;cxe+mse&#39;: 35.0350483008, &#39;cxe&#39;: 4.66776863, &#39;mse&#39;: 30.3672796708}
Epoch:  796 -  {&#39;cxe+mse&#39;: 35.0154471863, &#39;cxe&#39;: 4.6676541794, &#39;mse&#39;: 30.3477930069}
Epoch:  797 -  {&#39;cxe+mse&#39;: 34.9958684283, &#39;cxe&#39;: 4.6675397288, &#39;mse&#39;: 30.3283286995}
Epoch:  798 -  {&#39;cxe+mse&#39;: 34.9763119894, &#39;cxe&#39;: 4.6674252782, &#39;mse&#39;: 30.3088867112}
Epoch:  799 -  {&#39;cxe+mse&#39;: 34.956777832, &#39;cxe&#39;: 4.6673108276, &#39;mse&#39;: 30.2894670044}
Epoch:  800 -  {&#39;cxe+mse&#39;: 34.9372659187, &#39;cxe&#39;: 4.667196377, &#39;mse&#39;: 30.2700695417}
Epoch:  801 -  {&#39;cxe+mse&#39;: 34.9177762122, &#39;cxe&#39;: 4.6670819264, &#39;mse&#39;: 30.2506942858}
Epoch:  802 -  {&#39;cxe+mse&#39;: 34.8983086753, &#39;cxe&#39;: 4.6669674758, &#39;mse&#39;: 30.2313411995}
Epoch:  803 -  {&#39;cxe+mse&#39;: 34.878863270699995, &#39;cxe&#39;: 4.6668530253, &#39;mse&#39;: 30.2120102454}
Epoch:  804 -  {&#39;cxe+mse&#39;: 34.8594399613, &#39;cxe&#39;: 4.6667385747, &#39;mse&#39;: 30.1927013866}
Epoch:  805 -  {&#39;cxe+mse&#39;: 34.8400387101, &#39;cxe&#39;: 4.6666241241, &#39;mse&#39;: 30.173414586}
Epoch:  806 -  {&#39;cxe+mse&#39;: 34.8206594801, &#39;cxe&#39;: 4.6665096735, &#39;mse&#39;: 30.1541498066}
Epoch:  807 -  {&#39;cxe+mse&#39;: 34.8013022345, &#39;cxe&#39;: 4.666395223, &#39;mse&#39;: 30.1349070115}
Epoch:  808 -  {&#39;cxe+mse&#39;: 34.7819669363, &#39;cxe&#39;: 4.6662807724, &#39;mse&#39;: 30.1156861639}
Epoch:  809 -  {&#39;cxe+mse&#39;: 34.7626535488, &#39;cxe&#39;: 4.6661663218, &#39;mse&#39;: 30.096487227}
Epoch:  810 -  {&#39;cxe+mse&#39;: 34.7433620356, &#39;cxe&#39;: 4.6660518713, &#39;mse&#39;: 30.0773101643}
Epoch:  811 -  {&#39;cxe+mse&#39;: 34.7240923598, &#39;cxe&#39;: 4.6659374207, &#39;mse&#39;: 30.0581549391}
Epoch:  812 -  {&#39;cxe+mse&#39;: 34.7048444851, &#39;cxe&#39;: 4.6658229702, &#39;mse&#39;: 30.0390215149}
Epoch:  813 -  {&#39;cxe+mse&#39;: 34.6856183748, &#39;cxe&#39;: 4.6657085196, &#39;mse&#39;: 30.0199098552}
Epoch:  814 -  {&#39;cxe+mse&#39;: 34.6664139928, &#39;cxe&#39;: 4.6655940691, &#39;mse&#39;: 30.0008199237}
Epoch:  815 -  {&#39;cxe+mse&#39;: 34.647231302499996, &#39;cxe&#39;: 4.6654796185, &#39;mse&#39;: 29.981751684}
Epoch:  816 -  {&#39;cxe+mse&#39;: 34.628070268, &#39;cxe&#39;: 4.665365168, &#39;mse&#39;: 29.9627051}
Epoch:  817 -  {&#39;cxe+mse&#39;: 34.6089308528, &#39;cxe&#39;: 4.6652507174, &#39;mse&#39;: 29.9436801354}
Epoch:  818 -  {&#39;cxe+mse&#39;: 34.5898130212, &#39;cxe&#39;: 4.6651362669, &#39;mse&#39;: 29.9246767543}
Epoch:  819 -  {&#39;cxe+mse&#39;: 34.5707167369, &#39;cxe&#39;: 4.6650218164, &#39;mse&#39;: 29.9056949205}
Epoch:  820 -  {&#39;cxe+mse&#39;: 34.551641964, &#39;cxe&#39;: 4.6649073658, &#39;mse&#39;: 29.8867345982}
Epoch:  821 -  {&#39;cxe+mse&#39;: 34.5325886668, &#39;cxe&#39;: 4.6647929153, &#39;mse&#39;: 29.8677957515}
Epoch:  822 -  {&#39;cxe+mse&#39;: 34.5135568094, &#39;cxe&#39;: 4.6646784648, &#39;mse&#39;: 29.8488783446}
Epoch:  823 -  {&#39;cxe+mse&#39;: 34.494546356, &#39;cxe&#39;: 4.6645640143, &#39;mse&#39;: 29.8299823417}
Epoch:  824 -  {&#39;cxe+mse&#39;: 34.4755572711, &#39;cxe&#39;: 4.6644495638, &#39;mse&#39;: 29.8111077073}
Epoch:  825 -  {&#39;cxe+mse&#39;: 34.4565895189, &#39;cxe&#39;: 4.6643351132, &#39;mse&#39;: 29.7922544057}
Epoch:  826 -  {&#39;cxe+mse&#39;: 34.4376430642, &#39;cxe&#39;: 4.6642206627, &#39;mse&#39;: 29.7734224015}
Epoch:  827 -  {&#39;cxe+mse&#39;: 34.418717871300004, &#39;cxe&#39;: 4.6641062122, &#39;mse&#39;: 29.7546116591}
Epoch:  828 -  {&#39;cxe+mse&#39;: 34.399813905, &#39;cxe&#39;: 4.6639917617, &#39;mse&#39;: 29.7358221433}
Epoch:  829 -  {&#39;cxe+mse&#39;: 34.3809311299, &#39;cxe&#39;: 4.6638773112, &#39;mse&#39;: 29.7170538187}
Epoch:  830 -  {&#39;cxe+mse&#39;: 34.3620695109, &#39;cxe&#39;: 4.6637628607, &#39;mse&#39;: 29.6983066502}
Epoch:  831 -  {&#39;cxe+mse&#39;: 34.3432290127, &#39;cxe&#39;: 4.6636484102, &#39;mse&#39;: 29.6795806025}
Epoch:  832 -  {&#39;cxe+mse&#39;: 34.3244096003, &#39;cxe&#39;: 4.6635339597, &#39;mse&#39;: 29.6608756406}
Epoch:  833 -  {&#39;cxe+mse&#39;: 34.305611238699996, &#39;cxe&#39;: 4.6634195092, &#39;mse&#39;: 29.6421917295}
Epoch:  834 -  {&#39;cxe+mse&#39;: 34.2868338929, &#39;cxe&#39;: 4.6633050587, &#39;mse&#39;: 29.6235288342}
Epoch:  835 -  {&#39;cxe+mse&#39;: 34.2680775282, &#39;cxe&#39;: 4.6631906083, &#39;mse&#39;: 29.6048869199}
Epoch:  836 -  {&#39;cxe+mse&#39;: 34.2493421095, &#39;cxe&#39;: 4.6630761578, &#39;mse&#39;: 29.5862659517}
Epoch:  837 -  {&#39;cxe+mse&#39;: 34.230627602300004, &#39;cxe&#39;: 4.6629617073, &#39;mse&#39;: 29.567665895}
Epoch:  838 -  {&#39;cxe+mse&#39;: 34.2119339718, &#39;cxe&#39;: 4.6628472568, &#39;mse&#39;: 29.549086715}
Epoch:  839 -  {&#39;cxe+mse&#39;: 34.1932611835, &#39;cxe&#39;: 4.6627328063, &#39;mse&#39;: 29.5305283772}
Epoch:  840 -  {&#39;cxe+mse&#39;: 34.174609203, &#39;cxe&#39;: 4.6626183559, &#39;mse&#39;: 29.5119908471}
Epoch:  841 -  {&#39;cxe+mse&#39;: 34.1559779955, &#39;cxe&#39;: 4.6625039054, &#39;mse&#39;: 29.4934740901}
Epoch:  842 -  {&#39;cxe+mse&#39;: 34.1373675269, &#39;cxe&#39;: 4.6623894549, &#39;mse&#39;: 29.474978072}
Epoch:  843 -  {&#39;cxe+mse&#39;: 34.1187777628, &#39;cxe&#39;: 4.6622750045, &#39;mse&#39;: 29.4565027583}
Epoch:  844 -  {&#39;cxe+mse&#39;: 34.100208669, &#39;cxe&#39;: 4.662160554, &#39;mse&#39;: 29.438048115}
Epoch:  845 -  {&#39;cxe+mse&#39;: 34.0816602112, &#39;cxe&#39;: 4.6620461036, &#39;mse&#39;: 29.4196141076}
Epoch:  846 -  {&#39;cxe+mse&#39;: 34.0631323554, &#39;cxe&#39;: 4.6619316531, &#39;mse&#39;: 29.4012007023}
Epoch:  847 -  {&#39;cxe+mse&#39;: 34.0446250675, &#39;cxe&#39;: 4.6618172027, &#39;mse&#39;: 29.3828078648}
Epoch:  848 -  {&#39;cxe+mse&#39;: 34.0261383135, &#39;cxe&#39;: 4.6617027522, &#39;mse&#39;: 29.3644355613}
Epoch:  849 -  {&#39;cxe+mse&#39;: 34.0076720596, &#39;cxe&#39;: 4.6615883018, &#39;mse&#39;: 29.3460837578}
Epoch:  850 -  {&#39;cxe+mse&#39;: 33.9892262718, &#39;cxe&#39;: 4.6614738513, &#39;mse&#39;: 29.3277524205}
Epoch:  851 -  {&#39;cxe+mse&#39;: 33.970800916499996, &#39;cxe&#39;: 4.6613594009, &#39;mse&#39;: 29.3094415156}
Epoch:  852 -  {&#39;cxe+mse&#39;: 33.95239596, &#39;cxe&#39;: 4.6612449505, &#39;mse&#39;: 29.2911510095}
Epoch:  853 -  {&#39;cxe+mse&#39;: 33.9340113685, &#39;cxe&#39;: 4.6611305001, &#39;mse&#39;: 29.2728808684}
Epoch:  854 -  {&#39;cxe+mse&#39;: 33.9156471084, &#39;cxe&#39;: 4.6610160496, &#39;mse&#39;: 29.2546310588}
Epoch:  855 -  {&#39;cxe+mse&#39;: 33.8973031465, &#39;cxe&#39;: 4.6609015992, &#39;mse&#39;: 29.2364015473}
Epoch:  856 -  {&#39;cxe+mse&#39;: 33.8789794491, &#39;cxe&#39;: 4.6607871488, &#39;mse&#39;: 29.2181923003}
Epoch:  857 -  {&#39;cxe+mse&#39;: 33.860675983, &#39;cxe&#39;: 4.6606726984, &#39;mse&#39;: 29.2000032846}
Epoch:  858 -  {&#39;cxe+mse&#39;: 33.8423927146, &#39;cxe&#39;: 4.6605582479, &#39;mse&#39;: 29.1818344667}
Epoch:  859 -  {&#39;cxe+mse&#39;: 33.8241296111, &#39;cxe&#39;: 4.6604437975, &#39;mse&#39;: 29.1636858136}
Epoch:  860 -  {&#39;cxe+mse&#39;: 33.805886639, &#39;cxe&#39;: 4.6603293471, &#39;mse&#39;: 29.1455572919}
Epoch:  861 -  {&#39;cxe+mse&#39;: 33.787663765299996, &#39;cxe&#39;: 4.6602148967, &#39;mse&#39;: 29.1274488686}
Epoch:  862 -  {&#39;cxe+mse&#39;: 33.769460957, &#39;cxe&#39;: 4.6601004463, &#39;mse&#39;: 29.1093605107}
Epoch:  863 -  {&#39;cxe+mse&#39;: 33.7512781811, &#39;cxe&#39;: 4.6599859959, &#39;mse&#39;: 29.0912921852}
Epoch:  864 -  {&#39;cxe+mse&#39;: 33.7331154047, &#39;cxe&#39;: 4.6598715455, &#39;mse&#39;: 29.0732438592}
Epoch:  865 -  {&#39;cxe+mse&#39;: 33.7149725949, &#39;cxe&#39;: 4.6597570951, &#39;mse&#39;: 29.0552154998}
Epoch:  866 -  {&#39;cxe+mse&#39;: 33.696849719, &#39;cxe&#39;: 4.6596426447, &#39;mse&#39;: 29.0372070743}
Epoch:  867 -  {&#39;cxe+mse&#39;: 33.6787467444, &#39;cxe&#39;: 4.6595281944, &#39;mse&#39;: 29.01921855}
Epoch:  868 -  {&#39;cxe+mse&#39;: 33.6606636382, &#39;cxe&#39;: 4.659413744, &#39;mse&#39;: 29.0012498942}
Epoch:  869 -  {&#39;cxe+mse&#39;: 33.6426003679, &#39;cxe&#39;: 4.6592992936, &#39;mse&#39;: 28.9833010743}
Epoch:  870 -  {&#39;cxe+mse&#39;: 33.6245569011, &#39;cxe&#39;: 4.6591848432, &#39;mse&#39;: 28.9653720579}
Epoch:  871 -  {&#39;cxe+mse&#39;: 33.6065332052, &#39;cxe&#39;: 4.6590703928, &#39;mse&#39;: 28.9474628124}
Epoch:  872 -  {&#39;cxe+mse&#39;: 33.5885292481, &#39;cxe&#39;: 4.6589559425, &#39;mse&#39;: 28.9295733056}
Epoch:  873 -  {&#39;cxe+mse&#39;: 33.5705449972, &#39;cxe&#39;: 4.6588414921, &#39;mse&#39;: 28.9117035051}
Epoch:  874 -  {&#39;cxe+mse&#39;: 33.552580420299996, &#39;cxe&#39;: 4.6587270417, &#39;mse&#39;: 28.8938533786}
Epoch:  875 -  {&#39;cxe+mse&#39;: 33.5346354853, &#39;cxe&#39;: 4.6586125914, &#39;mse&#39;: 28.8760228939}
Epoch:  876 -  {&#39;cxe+mse&#39;: 33.5167101599, &#39;cxe&#39;: 4.658498141, &#39;mse&#39;: 28.8582120189}
Epoch:  877 -  {&#39;cxe+mse&#39;: 33.498804412300004, &#39;cxe&#39;: 4.6583836907, &#39;mse&#39;: 28.8404207216}
Epoch:  878 -  {&#39;cxe+mse&#39;: 33.4809182103, &#39;cxe&#39;: 4.6582692403, &#39;mse&#39;: 28.82264897}
Epoch:  879 -  {&#39;cxe+mse&#39;: 33.463051522, &#39;cxe&#39;: 4.6581547899, &#39;mse&#39;: 28.8048967321}
Epoch:  880 -  {&#39;cxe+mse&#39;: 33.4452043156, &#39;cxe&#39;: 4.6580403396, &#39;mse&#39;: 28.787163976}
Epoch:  881 -  {&#39;cxe+mse&#39;: 33.4273765592, &#39;cxe&#39;: 4.6579258893, &#39;mse&#39;: 28.7694506699}
Epoch:  882 -  {&#39;cxe+mse&#39;: 33.4095682211, &#39;cxe&#39;: 4.6578114389, &#39;mse&#39;: 28.7517567822}
Epoch:  883 -  {&#39;cxe+mse&#39;: 33.3917792697, &#39;cxe&#39;: 4.6576969886, &#39;mse&#39;: 28.7340822811}
Epoch:  884 -  {&#39;cxe+mse&#39;: 33.3740096732, &#39;cxe&#39;: 4.6575825382, &#39;mse&#39;: 28.716427135}
Epoch:  885 -  {&#39;cxe+mse&#39;: 33.3562594002, &#39;cxe&#39;: 4.6574680879, &#39;mse&#39;: 28.6987913123}
Epoch:  886 -  {&#39;cxe+mse&#39;: 33.3385284192, &#39;cxe&#39;: 4.6573536376, &#39;mse&#39;: 28.6811747816}
Epoch:  887 -  {&#39;cxe+mse&#39;: 33.3208166987, &#39;cxe&#39;: 4.6572391873, &#39;mse&#39;: 28.6635775114}
Epoch:  888 -  {&#39;cxe+mse&#39;: 33.3031242072, &#39;cxe&#39;: 4.6571247369, &#39;mse&#39;: 28.6459994703}
Epoch:  889 -  {&#39;cxe+mse&#39;: 33.285450913700004, &#39;cxe&#39;: 4.6570102866, &#39;mse&#39;: 28.6284406271}
Epoch:  890 -  {&#39;cxe+mse&#39;: 33.2677967868, &#39;cxe&#39;: 4.6568958363, &#39;mse&#39;: 28.6109009505}
Epoch:  891 -  {&#39;cxe+mse&#39;: 33.250161795400004, &#39;cxe&#39;: 4.656781386, &#39;mse&#39;: 28.5933804094}
Epoch:  892 -  {&#39;cxe+mse&#39;: 33.2325459082, &#39;cxe&#39;: 4.6566669357, &#39;mse&#39;: 28.5758789725}
Epoch:  893 -  {&#39;cxe+mse&#39;: 33.2149490944, &#39;cxe&#39;: 4.6565524854, &#39;mse&#39;: 28.558396609}
Epoch:  894 -  {&#39;cxe+mse&#39;: 33.1973713227, &#39;cxe&#39;: 4.6564380351, &#39;mse&#39;: 28.5409332876}
Epoch:  895 -  {&#39;cxe+mse&#39;: 33.1798125624, &#39;cxe&#39;: 4.6563235848, &#39;mse&#39;: 28.5234889776}
Epoch:  896 -  {&#39;cxe+mse&#39;: 33.1622727826, &#39;cxe&#39;: 4.6562091345, &#39;mse&#39;: 28.5060636481}
Epoch:  897 -  {&#39;cxe+mse&#39;: 33.1447519524, &#39;cxe&#39;: 4.6560946842, &#39;mse&#39;: 28.4886572682}
Epoch:  898 -  {&#39;cxe+mse&#39;: 33.127250041, &#39;cxe&#39;: 4.6559802339, &#39;mse&#39;: 28.4712698071}
Epoch:  899 -  {&#39;cxe+mse&#39;: 33.109767017900005, &#39;cxe&#39;: 4.6558657836, &#39;mse&#39;: 28.4539012343}
Epoch:  900 -  {&#39;cxe+mse&#39;: 33.092302852399996, &#39;cxe&#39;: 4.6557513333, &#39;mse&#39;: 28.4365515191}
Epoch:  901 -  {&#39;cxe+mse&#39;: 33.0748575139, &#39;cxe&#39;: 4.655636883, &#39;mse&#39;: 28.4192206309}
Epoch:  902 -  {&#39;cxe+mse&#39;: 33.057430971900004, &#39;cxe&#39;: 4.6555224327, &#39;mse&#39;: 28.4019085392}
Epoch:  903 -  {&#39;cxe+mse&#39;: 33.040023196, &#39;cxe&#39;: 4.6554079825, &#39;mse&#39;: 28.3846152135}
Epoch:  904 -  {&#39;cxe+mse&#39;: 33.0226341558, &#39;cxe&#39;: 4.6552935322, &#39;mse&#39;: 28.3673406236}
Epoch:  905 -  {&#39;cxe+mse&#39;: 33.0052638208, &#39;cxe&#39;: 4.6551790819, &#39;mse&#39;: 28.3500847389}
Epoch:  906 -  {&#39;cxe+mse&#39;: 32.9879121611, &#39;cxe&#39;: 4.6550646317, &#39;mse&#39;: 28.3328475294}
Epoch:  907 -  {&#39;cxe+mse&#39;: 32.970579146199995, &#39;cxe&#39;: 4.6549501814, &#39;mse&#39;: 28.3156289648}
Epoch:  908 -  {&#39;cxe+mse&#39;: 32.9532647459, &#39;cxe&#39;: 4.6548357311, &#39;mse&#39;: 28.2984290148}
Epoch:  909 -  {&#39;cxe+mse&#39;: 32.9359689305, &#39;cxe&#39;: 4.6547212809, &#39;mse&#39;: 28.2812476496}
Epoch:  910 -  {&#39;cxe+mse&#39;: 32.9186916696, &#39;cxe&#39;: 4.6546068306, &#39;mse&#39;: 28.264084839}
Epoch:  911 -  {&#39;cxe+mse&#39;: 32.9014329334, &#39;cxe&#39;: 4.6544923804, &#39;mse&#39;: 28.246940553}
Epoch:  912 -  {&#39;cxe+mse&#39;: 32.8841926919, &#39;cxe&#39;: 4.6543779301, &#39;mse&#39;: 28.2298147618}
Epoch:  913 -  {&#39;cxe+mse&#39;: 32.8669709154, &#39;cxe&#39;: 4.6542634799, &#39;mse&#39;: 28.2127074355}
Epoch:  914 -  {&#39;cxe+mse&#39;: 32.8497675739, &#39;cxe&#39;: 4.6541490296, &#39;mse&#39;: 28.1956185443}
Epoch:  915 -  {&#39;cxe+mse&#39;: 32.832582637899996, &#39;cxe&#39;: 4.6540345794, &#39;mse&#39;: 28.1785480585}
Epoch:  916 -  {&#39;cxe+mse&#39;: 32.8154160776, &#39;cxe&#39;: 4.6539201292, &#39;mse&#39;: 28.1614959484}
Epoch:  917 -  {&#39;cxe+mse&#39;: 32.7982678633, &#39;cxe&#39;: 4.6538056789, &#39;mse&#39;: 28.1444621844}
Epoch:  918 -  {&#39;cxe+mse&#39;: 32.7811379657, &#39;cxe&#39;: 4.6536912287, &#39;mse&#39;: 28.127446737}
Epoch:  919 -  {&#39;cxe+mse&#39;: 32.7640263552, &#39;cxe&#39;: 4.6535767785, &#39;mse&#39;: 28.1104495767}
Epoch:  920 -  {&#39;cxe+mse&#39;: 32.746933002199995, &#39;cxe&#39;: 4.6534623282, &#39;mse&#39;: 28.093470674}
Epoch:  921 -  {&#39;cxe+mse&#39;: 32.7298578775, &#39;cxe&#39;: 4.653347878, &#39;mse&#39;: 28.0765099995}
Epoch:  922 -  {&#39;cxe+mse&#39;: 32.7128009518, &#39;cxe&#39;: 4.6532334278, &#39;mse&#39;: 28.059567524}
Epoch:  923 -  {&#39;cxe+mse&#39;: 32.6957621957, &#39;cxe&#39;: 4.6531189776, &#39;mse&#39;: 28.0426432181}
Epoch:  924 -  {&#39;cxe+mse&#39;: 32.678741580099995, &#39;cxe&#39;: 4.6530045274, &#39;mse&#39;: 28.0257370527}
Epoch:  925 -  {&#39;cxe+mse&#39;: 32.6617390759, &#39;cxe&#39;: 4.6528900772, &#39;mse&#39;: 28.0088489987}
Epoch:  926 -  {&#39;cxe+mse&#39;: 32.6447546538, &#39;cxe&#39;: 4.652775627, &#39;mse&#39;: 27.9919790268}
Epoch:  927 -  {&#39;cxe+mse&#39;: 32.627788285, &#39;cxe&#39;: 4.6526611768, &#39;mse&#39;: 27.9751271082}
Epoch:  928 -  {&#39;cxe+mse&#39;: 32.610839940299996, &#39;cxe&#39;: 4.6525467266, &#39;mse&#39;: 27.9582932137}
Epoch:  929 -  {&#39;cxe+mse&#39;: 32.593909591, &#39;cxe&#39;: 4.6524322764, &#39;mse&#39;: 27.9414773146}
Epoch:  930 -  {&#39;cxe+mse&#39;: 32.5769972082, &#39;cxe&#39;: 4.6523178262, &#39;mse&#39;: 27.924679382}
Epoch:  931 -  {&#39;cxe+mse&#39;: 32.560102763, &#39;cxe&#39;: 4.652203376, &#39;mse&#39;: 27.907899387}
Epoch:  932 -  {&#39;cxe+mse&#39;: 32.5432262267, &#39;cxe&#39;: 4.6520889258, &#39;mse&#39;: 27.8911373009}
Epoch:  933 -  {&#39;cxe+mse&#39;: 32.5263675706, &#39;cxe&#39;: 4.6519744756, &#39;mse&#39;: 27.874393095}
Epoch:  934 -  {&#39;cxe+mse&#39;: 32.5095267661, &#39;cxe&#39;: 4.6518600254, &#39;mse&#39;: 27.8576667407}
Epoch:  935 -  {&#39;cxe+mse&#39;: 32.4927037847, &#39;cxe&#39;: 4.6517455753, &#39;mse&#39;: 27.8409582094}
Epoch:  936 -  {&#39;cxe+mse&#39;: 32.475898597699995, &#39;cxe&#39;: 4.6516311251, &#39;mse&#39;: 27.8242674726}
Epoch:  937 -  {&#39;cxe+mse&#39;: 32.4591111767, &#39;cxe&#39;: 4.6515166749, &#39;mse&#39;: 27.8075945018}
Epoch:  938 -  {&#39;cxe+mse&#39;: 32.4423414934, &#39;cxe&#39;: 4.6514022247, &#39;mse&#39;: 27.7909392687}
Epoch:  939 -  {&#39;cxe+mse&#39;: 32.4255895194, &#39;cxe&#39;: 4.6512877746, &#39;mse&#39;: 27.7743017448}
Epoch:  940 -  {&#39;cxe+mse&#39;: 32.4088552263, &#39;cxe&#39;: 4.6511733244, &#39;mse&#39;: 27.7576819019}
Epoch:  941 -  {&#39;cxe+mse&#39;: 32.392138586, &#39;cxe&#39;: 4.6510588743, &#39;mse&#39;: 27.7410797117}
Epoch:  942 -  {&#39;cxe+mse&#39;: 32.3754395702, &#39;cxe&#39;: 4.6509444241, &#39;mse&#39;: 27.7244951461}
Epoch:  943 -  {&#39;cxe+mse&#39;: 32.3587581509, &#39;cxe&#39;: 4.650829974, &#39;mse&#39;: 27.7079281769}
Epoch:  944 -  {&#39;cxe+mse&#39;: 32.3420942999, &#39;cxe&#39;: 4.6507155238, &#39;mse&#39;: 27.6913787761}
Epoch:  945 -  {&#39;cxe+mse&#39;: 32.325447989400004, &#39;cxe&#39;: 4.6506010737, &#39;mse&#39;: 27.6748469157}
Epoch:  946 -  {&#39;cxe+mse&#39;: 32.3088191911, &#39;cxe&#39;: 4.6504866235, &#39;mse&#39;: 27.6583325676}
Epoch:  947 -  {&#39;cxe+mse&#39;: 32.2922078773, &#39;cxe&#39;: 4.6503721734, &#39;mse&#39;: 27.6418357039}
Epoch:  948 -  {&#39;cxe+mse&#39;: 32.2756140202, &#39;cxe&#39;: 4.6502577232, &#39;mse&#39;: 27.625356297}
Epoch:  949 -  {&#39;cxe+mse&#39;: 32.259037591900004, &#39;cxe&#39;: 4.6501432731, &#39;mse&#39;: 27.6088943188}
Epoch:  950 -  {&#39;cxe+mse&#39;: 32.2424785647, &#39;cxe&#39;: 4.650028823, &#39;mse&#39;: 27.5924497417}
Epoch:  951 -  {&#39;cxe+mse&#39;: 32.2259369109, &#39;cxe&#39;: 4.6499143729, &#39;mse&#39;: 27.576022538}
Epoch:  952 -  {&#39;cxe+mse&#39;: 32.2094126028, &#39;cxe&#39;: 4.6497999227, &#39;mse&#39;: 27.5596126801}
Epoch:  953 -  {&#39;cxe+mse&#39;: 32.192905613, &#39;cxe&#39;: 4.6496854726, &#39;mse&#39;: 27.5432201404}
Epoch:  954 -  {&#39;cxe+mse&#39;: 32.1764159138, &#39;cxe&#39;: 4.6495710225, &#39;mse&#39;: 27.5268448913}
Epoch:  955 -  {&#39;cxe+mse&#39;: 32.1599434778, &#39;cxe&#39;: 4.6494565724, &#39;mse&#39;: 27.5104869054}
Epoch:  956 -  {&#39;cxe+mse&#39;: 32.1434882777, &#39;cxe&#39;: 4.6493421223, &#39;mse&#39;: 27.4941461554}
Epoch:  957 -  {&#39;cxe+mse&#39;: 32.1270502859, &#39;cxe&#39;: 4.6492276722, &#39;mse&#39;: 27.4778226137}
Epoch:  958 -  {&#39;cxe+mse&#39;: 32.1106294752, &#39;cxe&#39;: 4.6491132221, &#39;mse&#39;: 27.4615162531}
Epoch:  959 -  {&#39;cxe+mse&#39;: 32.094225818299996, &#39;cxe&#39;: 4.6489987719, &#39;mse&#39;: 27.4452270464}
Epoch:  960 -  {&#39;cxe+mse&#39;: 32.077839288199996, &#39;cxe&#39;: 4.6488843218, &#39;mse&#39;: 27.4289549664}
Epoch:  961 -  {&#39;cxe+mse&#39;: 32.061469857700004, &#39;cxe&#39;: 4.6487698718, &#39;mse&#39;: 27.4126999859}
Epoch:  962 -  {&#39;cxe+mse&#39;: 32.0451174994, &#39;cxe&#39;: 4.6486554217, &#39;mse&#39;: 27.3964620777}
Epoch:  963 -  {&#39;cxe+mse&#39;: 32.028782186600004, &#39;cxe&#39;: 4.6485409716, &#39;mse&#39;: 27.380241215}
Epoch:  964 -  {&#39;cxe+mse&#39;: 32.0124638922, &#39;cxe&#39;: 4.6484265215, &#39;mse&#39;: 27.3640373707}
Epoch:  965 -  {&#39;cxe+mse&#39;: 31.9961625892, &#39;cxe&#39;: 4.6483120714, &#39;mse&#39;: 27.3478505178}
Epoch:  966 -  {&#39;cxe+mse&#39;: 31.9798782507, &#39;cxe&#39;: 4.6481976213, &#39;mse&#39;: 27.3316806294}
Epoch:  967 -  {&#39;cxe+mse&#39;: 31.9636108501, &#39;cxe&#39;: 4.6480831712, &#39;mse&#39;: 27.3155276789}
Epoch:  968 -  {&#39;cxe+mse&#39;: 31.9473603605, &#39;cxe&#39;: 4.6479687212, &#39;mse&#39;: 27.2993916393}
Epoch:  969 -  {&#39;cxe+mse&#39;: 31.931126755, &#39;cxe&#39;: 4.6478542711, &#39;mse&#39;: 27.2832724839}
Epoch:  970 -  {&#39;cxe+mse&#39;: 31.914910007099998, &#39;cxe&#39;: 4.647739821, &#39;mse&#39;: 27.2671701861}
Epoch:  971 -  {&#39;cxe+mse&#39;: 31.8987100903, &#39;cxe&#39;: 4.647625371, &#39;mse&#39;: 27.2510847193}
Epoch:  972 -  {&#39;cxe+mse&#39;: 31.8825269778, &#39;cxe&#39;: 4.6475109209, &#39;mse&#39;: 27.2350160569}
Epoch:  973 -  {&#39;cxe+mse&#39;: 31.866360643100002, &#39;cxe&#39;: 4.6473964708, &#39;mse&#39;: 27.2189641723}
Epoch:  974 -  {&#39;cxe+mse&#39;: 31.85021106, &#39;cxe&#39;: 4.6472820208, &#39;mse&#39;: 27.2029290392}
Epoch:  975 -  {&#39;cxe+mse&#39;: 31.8340782017, &#39;cxe&#39;: 4.6471675707, &#39;mse&#39;: 27.186910631}
Epoch:  976 -  {&#39;cxe+mse&#39;: 31.8179620423, &#39;cxe&#39;: 4.6470531207, &#39;mse&#39;: 27.1709089216}
Epoch:  977 -  {&#39;cxe+mse&#39;: 31.801862555, &#39;cxe&#39;: 4.6469386706, &#39;mse&#39;: 27.1549238844}
Epoch:  978 -  {&#39;cxe+mse&#39;: 31.785779714, &#39;cxe&#39;: 4.6468242206, &#39;mse&#39;: 27.1389554934}
Epoch:  979 -  {&#39;cxe+mse&#39;: 31.7697134928, &#39;cxe&#39;: 4.6467097706, &#39;mse&#39;: 27.1230037222}
Epoch:  980 -  {&#39;cxe+mse&#39;: 31.753663865300002, &#39;cxe&#39;: 4.6465953205, &#39;mse&#39;: 27.1070685448}
Epoch:  981 -  {&#39;cxe+mse&#39;: 31.7376308055, &#39;cxe&#39;: 4.6464808705, &#39;mse&#39;: 27.091149935}
Epoch:  982 -  {&#39;cxe+mse&#39;: 31.721614287199998, &#39;cxe&#39;: 4.6463664205, &#39;mse&#39;: 27.0752478667}
Epoch:  983 -  {&#39;cxe+mse&#39;: 31.7056142845, &#39;cxe&#39;: 4.6462519704, &#39;mse&#39;: 27.0593623141}
Epoch:  984 -  {&#39;cxe+mse&#39;: 31.6896307715, &#39;cxe&#39;: 4.6461375204, &#39;mse&#39;: 27.0434932511}
Epoch:  985 -  {&#39;cxe+mse&#39;: 31.673663722199997, &#39;cxe&#39;: 4.6460230704, &#39;mse&#39;: 27.0276406518}
Epoch:  986 -  {&#39;cxe+mse&#39;: 31.6577131108, &#39;cxe&#39;: 4.6459086204, &#39;mse&#39;: 27.0118044904}
Epoch:  987 -  {&#39;cxe+mse&#39;: 31.6417789116, &#39;cxe&#39;: 4.6457941704, &#39;mse&#39;: 26.9959847412}
Epoch:  988 -  {&#39;cxe+mse&#39;: 31.6258610986, &#39;cxe&#39;: 4.6456797204, &#39;mse&#39;: 26.9801813782}
Epoch:  989 -  {&#39;cxe+mse&#39;: 31.609959646300002, &#39;cxe&#39;: 4.6455652703, &#39;mse&#39;: 26.964394376}
Epoch:  990 -  {&#39;cxe+mse&#39;: 31.594074529, &#39;cxe&#39;: 4.6454508203, &#39;mse&#39;: 26.9486237087}
Epoch:  991 -  {&#39;cxe+mse&#39;: 31.5782057212, &#39;cxe&#39;: 4.6453363703, &#39;mse&#39;: 26.9328693509}
Epoch:  992 -  {&#39;cxe+mse&#39;: 31.5623531972, &#39;cxe&#39;: 4.6452219203, &#39;mse&#39;: 26.9171312769}
Epoch:  993 -  {&#39;cxe+mse&#39;: 31.5465169316, &#39;cxe&#39;: 4.6451074703, &#39;mse&#39;: 26.9014094613}
Epoch:  994 -  {&#39;cxe+mse&#39;: 31.530696899000002, &#39;cxe&#39;: 4.6449930204, &#39;mse&#39;: 26.8857038786}
Epoch:  995 -  {&#39;cxe+mse&#39;: 31.514893073899998, &#39;cxe&#39;: 4.6448785704, &#39;mse&#39;: 26.8700145035}
Epoch:  996 -  {&#39;cxe+mse&#39;: 31.499105430999997, &#39;cxe&#39;: 4.6447641204, &#39;mse&#39;: 26.8543413106}
Epoch:  997 -  {&#39;cxe+mse&#39;: 31.483333945, &#39;cxe&#39;: 4.6446496704, &#39;mse&#39;: 26.8386842746}
Epoch:  998 -  {&#39;cxe+mse&#39;: 31.4675785906, &#39;cxe&#39;: 4.6445352204, &#39;mse&#39;: 26.8230433702}
Epoch:  999 -  {&#39;cxe+mse&#39;: 31.4518393427, &#39;cxe&#39;: 4.6444207704, &#39;mse&#39;: 26.8074185723}
Epoch:  1000 -  {&#39;cxe+mse&#39;: 31.4361161762, &#39;cxe&#39;: 4.6443063205, &#39;mse&#39;: 26.7918098557}
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="78" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="k7pkVmdnOMeB" data-outputId="e4289ac9-2e2c-4e95-8dc1-205c9ad51592">
<div class="sourceCode" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>model_linear_homegrown2 <span class="op">=</span> LinearRegressionHomegrown()</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>model_linear_homegrown2.fit(X_train_r, y_train_r, max_iter<span class="op">=</span><span class="dv">1000</span>, alpha<span class="op">=</span><span class="fl">0.00005</span>,val_data_r<span class="op">=</span>[X_valid_r,y_valid_r])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch:  1 -  {&#39;Reg_MSE&#39;: 466049.7914169696}
Epoch:  2 -  {&#39;Reg_MSE&#39;: 438189.4229102519}
Epoch:  3 -  {&#39;Reg_MSE&#39;: 411994.7118808954}
Epoch:  4 -  {&#39;Reg_MSE&#39;: 387366.0754906578}
Epoch:  5 -  {&#39;Reg_MSE&#39;: 364209.884547328}
Epoch:  6 -  {&#39;Reg_MSE&#39;: 342438.1075609724}
Epoch:  7 -  {&#39;Reg_MSE&#39;: 321967.9760805819}
Epoch:  8 -  {&#39;Reg_MSE&#39;: 302721.670038854}
Epoch:  9 -  {&#39;Reg_MSE&#39;: 284626.0219088817}
Epoch:  10 -  {&#39;Reg_MSE&#39;: 267612.2385480982}
Epoch:  11 -  {&#39;Reg_MSE&#39;: 251615.6396720016}
Epoch:  12 -  {&#39;Reg_MSE&#39;: 236575.4119634492}
Epoch:  13 -  {&#39;Reg_MSE&#39;: 222434.377882742}
Epoch:  14 -  {&#39;Reg_MSE&#39;: 209138.7782995748}
Epoch:  15 -  {&#39;Reg_MSE&#39;: 196638.0681205266}
Epoch:  16 -  {&#39;Reg_MSE&#39;: 184884.7241351374}
Epoch:  17 -  {&#39;Reg_MSE&#39;: 173834.0643500532}
Epoch:  18 -  {&#39;Reg_MSE&#39;: 163444.0781244442}
Epoch:  19 -  {&#39;Reg_MSE&#39;: 153675.2664609119}
Epoch:  20 -  {&#39;Reg_MSE&#39;: 144490.4918447381}
Epoch:  21 -  {&#39;Reg_MSE&#39;: 135854.8370606264}
Epoch:  22 -  {&#39;Reg_MSE&#39;: 127735.4724501942}
Epoch:  23 -  {&#39;Reg_MSE&#39;: 120101.5311055952}
Epoch:  24 -  {&#39;Reg_MSE&#39;: 112923.9915247894}
Epoch:  25 -  {&#39;Reg_MSE&#39;: 106175.5672823725}
Epoch:  26 -  {&#39;Reg_MSE&#39;: 99830.6032965204}
Epoch:  27 -  {&#39;Reg_MSE&#39;: 93864.9782977116}
Epoch:  28 -  {&#39;Reg_MSE&#39;: 88256.0131284265}
Epoch:  29 -  {&#39;Reg_MSE&#39;: 82982.3845252392}
Epoch:  30 -  {&#39;Reg_MSE&#39;: 78024.0440555103}
Epoch:  31 -  {&#39;Reg_MSE&#39;: 73362.1419005228}
Epoch:  32 -  {&#39;Reg_MSE&#39;: 68978.955195306}
Epoch:  33 -  {&#39;Reg_MSE&#39;: 64857.820652724}
Epoch:  34 -  {&#39;Reg_MSE&#39;: 60983.0712156904}
Epoch:  35 -  {&#39;Reg_MSE&#39;: 57339.9764966829}
Epoch:  36 -  {&#39;Reg_MSE&#39;: 53914.6867781333}
Epoch:  37 -  {&#39;Reg_MSE&#39;: 50694.1803608012}
Epoch:  38 -  {&#39;Reg_MSE&#39;: 47666.2140599701}
Epoch:  39 -  {&#39;Reg_MSE&#39;: 44819.2766612701}
Epoch:  40 -  {&#39;Reg_MSE&#39;: 42142.5451591842}
Epoch:  41 -  {&#39;Reg_MSE&#39;: 39625.8436118735}
Epoch:  42 -  {&#39;Reg_MSE&#39;: 37259.6044558995}
Epoch:  43 -  {&#39;Reg_MSE&#39;: 35034.8321337825}
Epoch:  44 -  {&#39;Reg_MSE&#39;: 32943.0688961134}
Epoch:  45 -  {&#39;Reg_MSE&#39;: 30976.3626482192}
Epoch:  46 -  {&#39;Reg_MSE&#39;: 29127.2367191408}
Epoch:  47 -  {&#39;Reg_MSE&#39;: 27388.661437999}
Epoch:  48 -  {&#39;Reg_MSE&#39;: 25754.0274096927}
Epoch:  49 -  {&#39;Reg_MSE&#39;: 24217.1203883318}
Epoch:  50 -  {&#39;Reg_MSE&#39;: 22772.0976528833}
Epoch:  51 -  {&#39;Reg_MSE&#39;: 21413.4657952207}
Epoch:  52 -  {&#39;Reg_MSE&#39;: 20136.0598361335}
Epoch:  53 -  {&#39;Reg_MSE&#39;: 18935.023589904}
Epoch:  54 -  {&#39;Reg_MSE&#39;: 17805.7912028058}
Epoch:  55 -  {&#39;Reg_MSE&#39;: 16744.0697953381}
Epoch:  56 -  {&#39;Reg_MSE&#39;: 15745.8231422098}
Epoch:  57 -  {&#39;Reg_MSE&#39;: 14807.2563280305}
Epoch:  58 -  {&#39;Reg_MSE&#39;: 13924.8013203728}
Epoch:  59 -  {&#39;Reg_MSE&#39;: 13095.1034053633}
Epoch:  60 -  {&#39;Reg_MSE&#39;: 12315.0084342333}
Epoch:  61 -  {&#39;Reg_MSE&#39;: 11581.5508323452}
Epoch:  62 -  {&#39;Reg_MSE&#39;: 10891.9423251101}
Epoch:  63 -  {&#39;Reg_MSE&#39;: 10243.5613379365}
Epoch:  64 -  {&#39;Reg_MSE&#39;: 9633.9430299127}
Epoch:  65 -  {&#39;Reg_MSE&#39;: 9060.7699233334}
Epoch:  66 -  {&#39;Reg_MSE&#39;: 8521.8630934492}
Epoch:  67 -  {&#39;Reg_MSE&#39;: 8015.173884945}
Epoch:  68 -  {&#39;Reg_MSE&#39;: 7538.7761236551}
Epoch:  69 -  {&#39;Reg_MSE&#39;: 7090.8587939089}
Epoch:  70 -  {&#39;Reg_MSE&#39;: 6669.7191536672}
Epoch:  71 -  {&#39;Reg_MSE&#39;: 6273.7562612776}
Epoch:  72 -  {&#39;Reg_MSE&#39;: 5901.464889237}
Epoch:  73 -  {&#39;Reg_MSE&#39;: 5551.4298018263}
Epoch:  74 -  {&#39;Reg_MSE&#39;: 5222.3203748622}
Epoch:  75 -  {&#39;Reg_MSE&#39;: 4912.885537111}
Epoch:  76 -  {&#39;Reg_MSE&#39;: 4621.9490141356}
Epoch:  77 -  {&#39;Reg_MSE&#39;: 4348.404856493}
Epoch:  78 -  {&#39;Reg_MSE&#39;: 4091.2132352824}
Epoch:  79 -  {&#39;Reg_MSE&#39;: 3849.3964890609}
Epoch:  80 -  {&#39;Reg_MSE&#39;: 3622.0354070977}
Epoch:  81 -  {&#39;Reg_MSE&#39;: 3408.2657348374}
Epoch:  82 -  {&#39;Reg_MSE&#39;: 3207.2748882874}
Epoch:  83 -  {&#39;Reg_MSE&#39;: 3018.2988648387}
Epoch:  84 -  {&#39;Reg_MSE&#39;: 2840.6193387766}
Epoch:  85 -  {&#39;Reg_MSE&#39;: 2673.5609304384}
Epoch:  86 -  {&#39;Reg_MSE&#39;: 2516.4886386377}
Epoch:  87 -  {&#39;Reg_MSE&#39;: 2368.8054265929}
Epoch:  88 -  {&#39;Reg_MSE&#39;: 2229.9499521841}
Epoch:  89 -  {&#39;Reg_MSE&#39;: 2099.3944339084}
Epoch:  90 -  {&#39;Reg_MSE&#39;: 1976.6426444209}
Epoch:  91 -  {&#39;Reg_MSE&#39;: 1861.2280240342}
Epoch:  92 -  {&#39;Reg_MSE&#39;: 1752.7119070038}
Epoch:  93 -  {&#39;Reg_MSE&#39;: 1650.6818538572}
Epoch:  94 -  {&#39;Reg_MSE&#39;: 1554.7500834258}
Epoch:  95 -  {&#39;Reg_MSE&#39;: 1464.5519986198}
Epoch:  96 -  {&#39;Reg_MSE&#39;: 1379.7448003409}
Epoch:  97 -  {&#39;Reg_MSE&#39;: 1300.0061842635}
Epoch:  98 -  {&#39;Reg_MSE&#39;: 1225.0331155304}
Epoch:  99 -  {&#39;Reg_MSE&#39;: 1154.5406767045}
Epoch:  100 -  {&#39;Reg_MSE&#39;: 1088.2609845966}
Epoch:  101 -  {&#39;Reg_MSE&#39;: 1025.9421718521}
Epoch:  102 -  {&#39;Reg_MSE&#39;: 967.3474294245}
Epoch:  103 -  {&#39;Reg_MSE&#39;: 912.2541062955}
Epoch:  104 -  {&#39;Reg_MSE&#39;: 860.4528630192}
Epoch:  105 -  {&#39;Reg_MSE&#39;: 811.746875873}
Epoch:  106 -  {&#39;Reg_MSE&#39;: 765.9510885885}
Epoch:  107 -  {&#39;Reg_MSE&#39;: 722.8915088191}
Epoch:  108 -  {&#39;Reg_MSE&#39;: 682.4045466687}
Epoch:  109 -  {&#39;Reg_MSE&#39;: 644.3363927672}
Epoch:  110 -  {&#39;Reg_MSE&#39;: 608.5424335283}
Epoch:  111 -  {&#39;Reg_MSE&#39;: 574.8867013673}
Epoch:  112 -  {&#39;Reg_MSE&#39;: 543.2413577876}
Epoch:  113 -  {&#39;Reg_MSE&#39;: 513.4862073716}
Epoch:  114 -  {&#39;Reg_MSE&#39;: 485.5082408287}
Epoch:  115 -  {&#39;Reg_MSE&#39;: 459.2012053619}
Epoch:  116 -  {&#39;Reg_MSE&#39;: 434.465200721}
Epoch:  117 -  {&#39;Reg_MSE&#39;: 411.2062994064}
Epoch:  118 -  {&#39;Reg_MSE&#39;: 389.3361895788}
Epoch:  119 -  {&#39;Reg_MSE&#39;: 368.7718393186}
Epoch:  120 -  {&#39;Reg_MSE&#39;: 349.4351809579}
Epoch:  121 -  {&#39;Reg_MSE&#39;: 331.2528142843}
Epoch:  122 -  {&#39;Reg_MSE&#39;: 314.1557274902}
Epoch:  123 -  {&#39;Reg_MSE&#39;: 298.0790348047}
Epoch:  124 -  {&#39;Reg_MSE&#39;: 282.9617298114}
Epoch:  125 -  {&#39;Reg_MSE&#39;: 268.7464535154}
Epoch:  126 -  {&#39;Reg_MSE&#39;: 255.3792762751}
Epoch:  127 -  {&#39;Reg_MSE&#39;: 242.8094927732}
Epoch:  128 -  {&#39;Reg_MSE&#39;: 230.9894292444}
Epoch:  129 -  {&#39;Reg_MSE&#39;: 219.8742622287}
Epoch:  130 -  {&#39;Reg_MSE&#39;: 209.4218481606}
Epoch:  131 -  {&#39;Reg_MSE&#39;: 199.5925631471}
Epoch:  132 -  {&#39;Reg_MSE&#39;: 190.3491523238}
Epoch:  133 -  {&#39;Reg_MSE&#39;: 181.6565882183}
Epoch:  134 -  {&#39;Reg_MSE&#39;: 173.4819375814}
Epoch:  135 -  {&#39;Reg_MSE&#39;: 165.7942361794}
Epoch:  136 -  {&#39;Reg_MSE&#39;: 158.5643710728}
Epoch:  137 -  {&#39;Reg_MSE&#39;: 151.7649699327}
Epoch:  138 -  {&#39;Reg_MSE&#39;: 145.3702969751}
Epoch:  139 -  {&#39;Reg_MSE&#39;: 139.3561551162}
Epoch:  140 -  {&#39;Reg_MSE&#39;: 133.699793978}
Epoch:  141 -  {&#39;Reg_MSE&#39;: 128.3798233938}
Epoch:  142 -  {&#39;Reg_MSE&#39;: 123.3761320851}
Epoch:  143 -  {&#39;Reg_MSE&#39;: 118.6698111998}
Epoch:  144 -  {&#39;Reg_MSE&#39;: 114.2430824228}
Epoch:  145 -  {&#39;Reg_MSE&#39;: 110.0792303839}
Epoch:  146 -  {&#39;Reg_MSE&#39;: 106.1625391073}
Epoch:  147 -  {&#39;Reg_MSE&#39;: 102.4782322598}
Epoch:  148 -  {&#39;Reg_MSE&#39;: 99.0124169725}
Epoch:  149 -  {&#39;Reg_MSE&#39;: 95.7520310199}
Epoch:  150 -  {&#39;Reg_MSE&#39;: 92.6847931584}
Epoch:  151 -  {&#39;Reg_MSE&#39;: 89.7991564327}
Epoch:  152 -  {&#39;Reg_MSE&#39;: 87.0842642743}
Epoch:  153 -  {&#39;Reg_MSE&#39;: 84.5299092251}
Epoch:  154 -  {&#39;Reg_MSE&#39;: 82.1264941283}
Epoch:  155 -  {&#39;Reg_MSE&#39;: 79.8649956397}
Epoch:  156 -  {&#39;Reg_MSE&#39;: 77.7369299203}
Epoch:  157 -  {&#39;Reg_MSE&#39;: 75.7343203809}
Epoch:  158 -  {&#39;Reg_MSE&#39;: 73.8496673543}
Epoch:  159 -  {&#39;Reg_MSE&#39;: 72.0759195805}
Epoch:  160 -  {&#39;Reg_MSE&#39;: 70.4064473981}
Epoch:  161 -  {&#39;Reg_MSE&#39;: 68.8350175369}
Epoch:  162 -  {&#39;Reg_MSE&#39;: 67.3557694183}
Epoch:  163 -  {&#39;Reg_MSE&#39;: 65.963192873}
Epoch:  164 -  {&#39;Reg_MSE&#39;: 64.6521071903}
Epoch:  165 -  {&#39;Reg_MSE&#39;: 63.41764142}
Epoch:  166 -  {&#39;Reg_MSE&#39;: 62.2552158526}
Epoch:  167 -  {&#39;Reg_MSE&#39;: 61.1605246058}
Epoch:  168 -  {&#39;Reg_MSE&#39;: 60.1295192532}
Epoch:  169 -  {&#39;Reg_MSE&#39;: 59.1583934308}
Epoch:  170 -  {&#39;Reg_MSE&#39;: 58.2435683646}
Epoch:  171 -  {&#39;Reg_MSE&#39;: 57.3816792627}
Epoch:  172 -  {&#39;Reg_MSE&#39;: 56.5695625222}
Epoch:  173 -  {&#39;Reg_MSE&#39;: 55.8042436993}
Epoch:  174 -  {&#39;Reg_MSE&#39;: 55.0829262002}
Epoch:  175 -  {&#39;Reg_MSE&#39;: 54.4029806472}
Epoch:  176 -  {&#39;Reg_MSE&#39;: 53.761934881}
Epoch:  177 -  {&#39;Reg_MSE&#39;: 53.1574645604}
Epoch:  178 -  {&#39;Reg_MSE&#39;: 52.5873843245}
Epoch:  179 -  {&#39;Reg_MSE&#39;: 52.0496394829}
Epoch:  180 -  {&#39;Reg_MSE&#39;: 51.5422982028}
Epoch:  181 -  {&#39;Reg_MSE&#39;: 51.0635441632}
Epoch:  182 -  {&#39;Reg_MSE&#39;: 50.6116696488}
Epoch:  183 -  {&#39;Reg_MSE&#39;: 50.1850690559}
Epoch:  184 -  {&#39;Reg_MSE&#39;: 49.782232787}
Epoch:  185 -  {&#39;Reg_MSE&#39;: 49.4017415111}
Epoch:  186 -  {&#39;Reg_MSE&#39;: 49.0422607657}
Epoch:  187 -  {&#39;Reg_MSE&#39;: 48.7025358832}
Epoch:  188 -  {&#39;Reg_MSE&#39;: 48.3813872191}
Epoch:  189 -  {&#39;Reg_MSE&#39;: 48.0777056669}
Epoch:  190 -  {&#39;Reg_MSE&#39;: 47.7904484397}
Epoch:  191 -  {&#39;Reg_MSE&#39;: 47.5186351057}
Epoch:  192 -  {&#39;Reg_MSE&#39;: 47.2613438591}
Epoch:  193 -  {&#39;Reg_MSE&#39;: 47.017708015}
Epoch:  194 -  {&#39;Reg_MSE&#39;: 46.7869127138}
Epoch:  195 -  {&#39;Reg_MSE&#39;: 46.5681918219}
Epoch:  196 -  {&#39;Reg_MSE&#39;: 46.3608250183}
Epoch:  197 -  {&#39;Reg_MSE&#39;: 46.164135056}
Epoch:  198 -  {&#39;Reg_MSE&#39;: 45.9774851853}
Epoch:  199 -  {&#39;Reg_MSE&#39;: 45.8002767333}
Epoch:  200 -  {&#39;Reg_MSE&#39;: 45.6319468266}
Epoch:  201 -  {&#39;Reg_MSE&#39;: 45.4719662507}
Epoch:  202 -  {&#39;Reg_MSE&#39;: 45.3198374378}
Epoch:  203 -  {&#39;Reg_MSE&#39;: 45.1750925738}
Epoch:  204 -  {&#39;Reg_MSE&#39;: 45.0372918197}
Epoch:  205 -  {&#39;Reg_MSE&#39;: 44.9060216387}
Epoch:  206 -  {&#39;Reg_MSE&#39;: 44.7808932232}
Epoch:  207 -  {&#39;Reg_MSE&#39;: 44.6615410166}
Epoch:  208 -  {&#39;Reg_MSE&#39;: 44.5476213222}
Epoch:  209 -  {&#39;Reg_MSE&#39;: 44.4388109967}
Epoch:  210 -  {&#39;Reg_MSE&#39;: 44.334806221}
Epoch:  211 -  {&#39;Reg_MSE&#39;: 44.2353213445}
Epoch:  212 -  {&#39;Reg_MSE&#39;: 44.1400877987}
Epoch:  213 -  {&#39;Reg_MSE&#39;: 44.048853076}
Epoch:  214 -  {&#39;Reg_MSE&#39;: 43.9613797687}
Epoch:  215 -  {&#39;Reg_MSE&#39;: 43.8774446667}
Epoch:  216 -  {&#39;Reg_MSE&#39;: 43.7968379081}
Epoch:  217 -  {&#39;Reg_MSE&#39;: 43.7193621809}
Epoch:  218 -  {&#39;Reg_MSE&#39;: 43.644831973}
Epoch:  219 -  {&#39;Reg_MSE&#39;: 43.5730728659}
Epoch:  220 -  {&#39;Reg_MSE&#39;: 43.5039208717}
Epoch:  221 -  {&#39;Reg_MSE&#39;: 43.4372218094}
Epoch:  222 -  {&#39;Reg_MSE&#39;: 43.372830718}
Epoch:  223 -  {&#39;Reg_MSE&#39;: 43.3106113057}
Epoch:  224 -  {&#39;Reg_MSE&#39;: 43.250435431}
Epoch:  225 -  {&#39;Reg_MSE&#39;: 43.1921826153}
Epoch:  226 -  {&#39;Reg_MSE&#39;: 43.135739585}
Epoch:  227 -  {&#39;Reg_MSE&#39;: 43.08099984}
Epoch:  228 -  {&#39;Reg_MSE&#39;: 43.0278632494}
Epoch:  229 -  {&#39;Reg_MSE&#39;: 42.9762356699}
Epoch:  230 -  {&#39;Reg_MSE&#39;: 42.9260285879}
Epoch:  231 -  {&#39;Reg_MSE&#39;: 42.8771587829}
Epoch:  232 -  {&#39;Reg_MSE&#39;: 42.8295480109}
Epoch:  233 -  {&#39;Reg_MSE&#39;: 42.7831227069}
Epoch:  234 -  {&#39;Reg_MSE&#39;: 42.7378137046}
Epoch:  235 -  {&#39;Reg_MSE&#39;: 42.6935559738}
Epoch:  236 -  {&#39;Reg_MSE&#39;: 42.6502883728}
Epoch:  237 -  {&#39;Reg_MSE&#39;: 42.6079534158}
Epoch:  238 -  {&#39;Reg_MSE&#39;: 42.5664970543}
Epoch:  239 -  {&#39;Reg_MSE&#39;: 42.5258684715}
Epoch:  240 -  {&#39;Reg_MSE&#39;: 42.486019889}
Epoch:  241 -  {&#39;Reg_MSE&#39;: 42.446906385}
Epoch:  242 -  {&#39;Reg_MSE&#39;: 42.4084857235}
Epoch:  243 -  {&#39;Reg_MSE&#39;: 42.3707181936}
Epoch:  244 -  {&#39;Reg_MSE&#39;: 42.3335664586}
Epoch:  245 -  {&#39;Reg_MSE&#39;: 42.2969954137}
Epoch:  246 -  {&#39;Reg_MSE&#39;: 42.2609720527}
Epoch:  247 -  {&#39;Reg_MSE&#39;: 42.2254653423}
Epoch:  248 -  {&#39;Reg_MSE&#39;: 42.1904461045}
Epoch:  249 -  {&#39;Reg_MSE&#39;: 42.155886905}
Epoch:  250 -  {&#39;Reg_MSE&#39;: 42.1217619492}
Epoch:  251 -  {&#39;Reg_MSE&#39;: 42.0880469843}
Epoch:  252 -  {&#39;Reg_MSE&#39;: 42.0547192066}
Epoch:  253 -  {&#39;Reg_MSE&#39;: 42.0217571753}
Epoch:  254 -  {&#39;Reg_MSE&#39;: 41.9891407305}
Epoch:  255 -  {&#39;Reg_MSE&#39;: 41.956850917}
Epoch:  256 -  {&#39;Reg_MSE&#39;: 41.9248699117}
Epoch:  257 -  {&#39;Reg_MSE&#39;: 41.8931809565}
Epoch:  258 -  {&#39;Reg_MSE&#39;: 41.8617682941}
Epoch:  259 -  {&#39;Reg_MSE&#39;: 41.8306171082}
Epoch:  260 -  {&#39;Reg_MSE&#39;: 41.7997134673}
Epoch:  261 -  {&#39;Reg_MSE&#39;: 41.7690442719}
Epoch:  262 -  {&#39;Reg_MSE&#39;: 41.7385972043}
Epoch:  263 -  {&#39;Reg_MSE&#39;: 41.7083606821}
Epoch:  264 -  {&#39;Reg_MSE&#39;: 41.6783238142}
Epoch:  265 -  {&#39;Reg_MSE&#39;: 41.6484763594}
Epoch:  266 -  {&#39;Reg_MSE&#39;: 41.6188086875}
Epoch:  267 -  {&#39;Reg_MSE&#39;: 41.5893117425}
Epoch:  268 -  {&#39;Reg_MSE&#39;: 41.5599770087}
Epoch:  269 -  {&#39;Reg_MSE&#39;: 41.5307964781}
Epoch:  270 -  {&#39;Reg_MSE&#39;: 41.50176262}
Epoch:  271 -  {&#39;Reg_MSE&#39;: 41.4728683524}
Epoch:  272 -  {&#39;Reg_MSE&#39;: 41.4441070152}
Epoch:  273 -  {&#39;Reg_MSE&#39;: 41.415472345}
Epoch:  274 -  {&#39;Reg_MSE&#39;: 41.3869584515}
Epoch:  275 -  {&#39;Reg_MSE&#39;: 41.3585597946}
Epoch:  276 -  {&#39;Reg_MSE&#39;: 41.3302711641}
Epoch:  277 -  {&#39;Reg_MSE&#39;: 41.3020876595}
Epoch:  278 -  {&#39;Reg_MSE&#39;: 41.2740046718}
Epoch:  279 -  {&#39;Reg_MSE&#39;: 41.2460178658}
Epoch:  280 -  {&#39;Reg_MSE&#39;: 41.2181231635}
Epoch:  281 -  {&#39;Reg_MSE&#39;: 41.1903167295}
Epoch:  282 -  {&#39;Reg_MSE&#39;: 41.1625949555}
Epoch:  283 -  {&#39;Reg_MSE&#39;: 41.1349544475}
Epoch:  284 -  {&#39;Reg_MSE&#39;: 41.1073920123}
Epoch:  285 -  {&#39;Reg_MSE&#39;: 41.079904646}
Epoch:  286 -  {&#39;Reg_MSE&#39;: 41.0524895225}
Epoch:  287 -  {&#39;Reg_MSE&#39;: 41.0251439826}
Epoch:  288 -  {&#39;Reg_MSE&#39;: 40.9978655245}
Epoch:  289 -  {&#39;Reg_MSE&#39;: 40.970651794}
Epoch:  290 -  {&#39;Reg_MSE&#39;: 40.9435005755}
Epoch:  291 -  {&#39;Reg_MSE&#39;: 40.9164097843}
Epoch:  292 -  {&#39;Reg_MSE&#39;: 40.8893774583}
Epoch:  293 -  {&#39;Reg_MSE&#39;: 40.8624017507}
Epoch:  294 -  {&#39;Reg_MSE&#39;: 40.8354809232}
Epoch:  295 -  {&#39;Reg_MSE&#39;: 40.8086133394}
Epoch:  296 -  {&#39;Reg_MSE&#39;: 40.781797459}
Epoch:  297 -  {&#39;Reg_MSE&#39;: 40.7550318315}
Epoch:  298 -  {&#39;Reg_MSE&#39;: 40.7283150912}
Epoch:  299 -  {&#39;Reg_MSE&#39;: 40.7016459523}
Epoch:  300 -  {&#39;Reg_MSE&#39;: 40.6750232034}
Epoch:  301 -  {&#39;Reg_MSE&#39;: 40.6484457039}
Epoch:  302 -  {&#39;Reg_MSE&#39;: 40.621912379}
Epoch:  303 -  {&#39;Reg_MSE&#39;: 40.5954222165}
Epoch:  304 -  {&#39;Reg_MSE&#39;: 40.5689742623}
Epoch:  305 -  {&#39;Reg_MSE&#39;: 40.5425676175}
Epoch:  306 -  {&#39;Reg_MSE&#39;: 40.5162014348}
Epoch:  307 -  {&#39;Reg_MSE&#39;: 40.4898749154}
Epoch:  308 -  {&#39;Reg_MSE&#39;: 40.4635873063}
Epoch:  309 -  {&#39;Reg_MSE&#39;: 40.4373378972}
Epoch:  310 -  {&#39;Reg_MSE&#39;: 40.4111260186}
Epoch:  311 -  {&#39;Reg_MSE&#39;: 40.3849510384}
Epoch:  312 -  {&#39;Reg_MSE&#39;: 40.3588123604}
Epoch:  313 -  {&#39;Reg_MSE&#39;: 40.3327094221}
Epoch:  314 -  {&#39;Reg_MSE&#39;: 40.3066416923}
Epoch:  315 -  {&#39;Reg_MSE&#39;: 40.2806086694}
Epoch:  316 -  {&#39;Reg_MSE&#39;: 40.2546098797}
Epoch:  317 -  {&#39;Reg_MSE&#39;: 40.2286448758}
Epoch:  318 -  {&#39;Reg_MSE&#39;: 40.2027132348}
Epoch:  319 -  {&#39;Reg_MSE&#39;: 40.1768145568}
Epoch:  320 -  {&#39;Reg_MSE&#39;: 40.1509484639}
Epoch:  321 -  {&#39;Reg_MSE&#39;: 40.1251145986}
Epoch:  322 -  {&#39;Reg_MSE&#39;: 40.0993126224}
Epoch:  323 -  {&#39;Reg_MSE&#39;: 40.0735422151}
Epoch:  324 -  {&#39;Reg_MSE&#39;: 40.0478030735}
Epoch:  325 -  {&#39;Reg_MSE&#39;: 40.0220949101}
Epoch:  326 -  {&#39;Reg_MSE&#39;: 39.9964174526}
Epoch:  327 -  {&#39;Reg_MSE&#39;: 39.9707704429}
Epoch:  328 -  {&#39;Reg_MSE&#39;: 39.945153636}
Epoch:  329 -  {&#39;Reg_MSE&#39;: 39.9195667994}
Epoch:  330 -  {&#39;Reg_MSE&#39;: 39.8940097124}
Epoch:  331 -  {&#39;Reg_MSE&#39;: 39.8684821652}
Epoch:  332 -  {&#39;Reg_MSE&#39;: 39.8429839584}
Epoch:  333 -  {&#39;Reg_MSE&#39;: 39.8175149025}
Epoch:  334 -  {&#39;Reg_MSE&#39;: 39.7920748169}
Epoch:  335 -  {&#39;Reg_MSE&#39;: 39.7666635297}
Epoch:  336 -  {&#39;Reg_MSE&#39;: 39.7412808772}
Epoch:  337 -  {&#39;Reg_MSE&#39;: 39.7159267032}
Epoch:  338 -  {&#39;Reg_MSE&#39;: 39.6906008586}
Epoch:  339 -  {&#39;Reg_MSE&#39;: 39.6653032012}
Epoch:  340 -  {&#39;Reg_MSE&#39;: 39.6400335951}
Epoch:  341 -  {&#39;Reg_MSE&#39;: 39.6147919101}
Epoch:  342 -  {&#39;Reg_MSE&#39;: 39.5895780218}
Epoch:  343 -  {&#39;Reg_MSE&#39;: 39.5643918111}
Epoch:  344 -  {&#39;Reg_MSE&#39;: 39.5392331637}
Epoch:  345 -  {&#39;Reg_MSE&#39;: 39.51410197}
Epoch:  346 -  {&#39;Reg_MSE&#39;: 39.4889981247}
Epoch:  347 -  {&#39;Reg_MSE&#39;: 39.4639215269}
Epoch:  348 -  {&#39;Reg_MSE&#39;: 39.4388720791}
Epoch:  349 -  {&#39;Reg_MSE&#39;: 39.4138496878}
Epoch:  350 -  {&#39;Reg_MSE&#39;: 39.3888542628}
Epoch:  351 -  {&#39;Reg_MSE&#39;: 39.3638857171}
Epoch:  352 -  {&#39;Reg_MSE&#39;: 39.3389439667}
Epoch:  353 -  {&#39;Reg_MSE&#39;: 39.3140289305}
Epoch:  354 -  {&#39;Reg_MSE&#39;: 39.2891405301}
Epoch:  355 -  {&#39;Reg_MSE&#39;: 39.2642786895}
Epoch:  356 -  {&#39;Reg_MSE&#39;: 39.2394433351}
Epoch:  357 -  {&#39;Reg_MSE&#39;: 39.2146343957}
Epoch:  358 -  {&#39;Reg_MSE&#39;: 39.1898518019}
Epoch:  359 -  {&#39;Reg_MSE&#39;: 39.1650954865}
Epoch:  360 -  {&#39;Reg_MSE&#39;: 39.1403653841}
Epoch:  361 -  {&#39;Reg_MSE&#39;: 39.1156614311}
Epoch:  362 -  {&#39;Reg_MSE&#39;: 39.0909835653}
Epoch:  363 -  {&#39;Reg_MSE&#39;: 39.0663317264}
Epoch:  364 -  {&#39;Reg_MSE&#39;: 39.0417058552}
Epoch:  365 -  {&#39;Reg_MSE&#39;: 39.0171058942}
Epoch:  366 -  {&#39;Reg_MSE&#39;: 38.992531787}
Epoch:  367 -  {&#39;Reg_MSE&#39;: 38.9679834785}
Epoch:  368 -  {&#39;Reg_MSE&#39;: 38.9434609146}
Epoch:  369 -  {&#39;Reg_MSE&#39;: 38.9189640425}
Epoch:  370 -  {&#39;Reg_MSE&#39;: 38.8944928103}
Epoch:  371 -  {&#39;Reg_MSE&#39;: 38.870047167}
Epoch:  372 -  {&#39;Reg_MSE&#39;: 38.8456270626}
Epoch:  373 -  {&#39;Reg_MSE&#39;: 38.8212324479}
Epoch:  374 -  {&#39;Reg_MSE&#39;: 38.7968632745}
Epoch:  375 -  {&#39;Reg_MSE&#39;: 38.7725194949}
Epoch:  376 -  {&#39;Reg_MSE&#39;: 38.7482010621}
Epoch:  377 -  {&#39;Reg_MSE&#39;: 38.7239079299}
Epoch:  378 -  {&#39;Reg_MSE&#39;: 38.6996400528}
Epoch:  379 -  {&#39;Reg_MSE&#39;: 38.6753973856}
Epoch:  380 -  {&#39;Reg_MSE&#39;: 38.6511798841}
Epoch:  381 -  {&#39;Reg_MSE&#39;: 38.6269875043}
Epoch:  382 -  {&#39;Reg_MSE&#39;: 38.6028202028}
Epoch:  383 -  {&#39;Reg_MSE&#39;: 38.5786779369}
Epoch:  384 -  {&#39;Reg_MSE&#39;: 38.5545606639}
Epoch:  385 -  {&#39;Reg_MSE&#39;: 38.530468342}
Epoch:  386 -  {&#39;Reg_MSE&#39;: 38.5064009295}
Epoch:  387 -  {&#39;Reg_MSE&#39;: 38.4823583852}
Epoch:  388 -  {&#39;Reg_MSE&#39;: 38.4583406682}
Epoch:  389 -  {&#39;Reg_MSE&#39;: 38.4343477382}
Epoch:  390 -  {&#39;Reg_MSE&#39;: 38.4103795548}
Epoch:  391 -  {&#39;Reg_MSE&#39;: 38.3864360782}
Epoch:  392 -  {&#39;Reg_MSE&#39;: 38.3625172688}
Epoch:  393 -  {&#39;Reg_MSE&#39;: 38.3386230874}
Epoch:  394 -  {&#39;Reg_MSE&#39;: 38.314753495}
Epoch:  395 -  {&#39;Reg_MSE&#39;: 38.2909084528}
Epoch:  396 -  {&#39;Reg_MSE&#39;: 38.2670879222}
Epoch:  397 -  {&#39;Reg_MSE&#39;: 38.243291865}
Epoch:  398 -  {&#39;Reg_MSE&#39;: 38.2195202431}
Epoch:  399 -  {&#39;Reg_MSE&#39;: 38.1957730187}
Epoch:  400 -  {&#39;Reg_MSE&#39;: 38.172050154}
Epoch:  401 -  {&#39;Reg_MSE&#39;: 38.1483516116}
Epoch:  402 -  {&#39;Reg_MSE&#39;: 38.1246773543}
Epoch:  403 -  {&#39;Reg_MSE&#39;: 38.101027345}
Epoch:  404 -  {&#39;Reg_MSE&#39;: 38.0774015466}
Epoch:  405 -  {&#39;Reg_MSE&#39;: 38.0537999224}
Epoch:  406 -  {&#39;Reg_MSE&#39;: 38.0302224358}
Epoch:  407 -  {&#39;Reg_MSE&#39;: 38.0066690503}
Epoch:  408 -  {&#39;Reg_MSE&#39;: 37.9831397296}
Epoch:  409 -  {&#39;Reg_MSE&#39;: 37.9596344374}
Epoch:  410 -  {&#39;Reg_MSE&#39;: 37.9361531378}
Epoch:  411 -  {&#39;Reg_MSE&#39;: 37.9126957948}
Epoch:  412 -  {&#39;Reg_MSE&#39;: 37.8892623726}
Epoch:  413 -  {&#39;Reg_MSE&#39;: 37.8658528354}
Epoch:  414 -  {&#39;Reg_MSE&#39;: 37.8424671477}
Epoch:  415 -  {&#39;Reg_MSE&#39;: 37.8191052741}
Epoch:  416 -  {&#39;Reg_MSE&#39;: 37.7957671792}
Epoch:  417 -  {&#39;Reg_MSE&#39;: 37.7724528276}
Epoch:  418 -  {&#39;Reg_MSE&#39;: 37.7491621844}
Epoch:  419 -  {&#39;Reg_MSE&#39;: 37.7258952144}
Epoch:  420 -  {&#39;Reg_MSE&#39;: 37.7026518827}
Epoch:  421 -  {&#39;Reg_MSE&#39;: 37.6794321544}
Epoch:  422 -  {&#39;Reg_MSE&#39;: 37.6562359947}
Epoch:  423 -  {&#39;Reg_MSE&#39;: 37.633063369}
Epoch:  424 -  {&#39;Reg_MSE&#39;: 37.6099142426}
Epoch:  425 -  {&#39;Reg_MSE&#39;: 37.5867885812}
Epoch:  426 -  {&#39;Reg_MSE&#39;: 37.5636863501}
Epoch:  427 -  {&#39;Reg_MSE&#39;: 37.5406075152}
Epoch:  428 -  {&#39;Reg_MSE&#39;: 37.5175520421}
Epoch:  429 -  {&#39;Reg_MSE&#39;: 37.4945198967}
Epoch:  430 -  {&#39;Reg_MSE&#39;: 37.4715110448}
Epoch:  431 -  {&#39;Reg_MSE&#39;: 37.4485254524}
Epoch:  432 -  {&#39;Reg_MSE&#39;: 37.4255630856}
Epoch:  433 -  {&#39;Reg_MSE&#39;: 37.4026239104}
Epoch:  434 -  {&#39;Reg_MSE&#39;: 37.3797078931}
Epoch:  435 -  {&#39;Reg_MSE&#39;: 37.356815}
Epoch:  436 -  {&#39;Reg_MSE&#39;: 37.3339451973}
Epoch:  437 -  {&#39;Reg_MSE&#39;: 37.3110984515}
Epoch:  438 -  {&#39;Reg_MSE&#39;: 37.288274729}
Epoch:  439 -  {&#39;Reg_MSE&#39;: 37.2654739964}
Epoch:  440 -  {&#39;Reg_MSE&#39;: 37.2426962202}
Epoch:  441 -  {&#39;Reg_MSE&#39;: 37.2199413672}
Epoch:  442 -  {&#39;Reg_MSE&#39;: 37.1972094041}
Epoch:  443 -  {&#39;Reg_MSE&#39;: 37.1745002976}
Epoch:  444 -  {&#39;Reg_MSE&#39;: 37.1518140147}
Epoch:  445 -  {&#39;Reg_MSE&#39;: 37.1291505223}
Epoch:  446 -  {&#39;Reg_MSE&#39;: 37.1065097873}
Epoch:  447 -  {&#39;Reg_MSE&#39;: 37.0838917768}
Epoch:  448 -  {&#39;Reg_MSE&#39;: 37.061296458}
Epoch:  449 -  {&#39;Reg_MSE&#39;: 37.038723798}
Epoch:  450 -  {&#39;Reg_MSE&#39;: 37.0161737641}
Epoch:  451 -  {&#39;Reg_MSE&#39;: 36.9936463235}
Epoch:  452 -  {&#39;Reg_MSE&#39;: 36.9711414436}
Epoch:  453 -  {&#39;Reg_MSE&#39;: 36.9486590918}
Epoch:  454 -  {&#39;Reg_MSE&#39;: 36.9261992357}
Epoch:  455 -  {&#39;Reg_MSE&#39;: 36.9037618427}
Epoch:  456 -  {&#39;Reg_MSE&#39;: 36.8813468805}
Epoch:  457 -  {&#39;Reg_MSE&#39;: 36.8589543168}
Epoch:  458 -  {&#39;Reg_MSE&#39;: 36.8365841191}
Epoch:  459 -  {&#39;Reg_MSE&#39;: 36.8142362554}
Epoch:  460 -  {&#39;Reg_MSE&#39;: 36.7919106934}
Epoch:  461 -  {&#39;Reg_MSE&#39;: 36.769607401}
Epoch:  462 -  {&#39;Reg_MSE&#39;: 36.7473263463}
Epoch:  463 -  {&#39;Reg_MSE&#39;: 36.7250674971}
Epoch:  464 -  {&#39;Reg_MSE&#39;: 36.7028308216}
Epoch:  465 -  {&#39;Reg_MSE&#39;: 36.6806162879}
Epoch:  466 -  {&#39;Reg_MSE&#39;: 36.6584238641}
Epoch:  467 -  {&#39;Reg_MSE&#39;: 36.6362535186}
Epoch:  468 -  {&#39;Reg_MSE&#39;: 36.6141052195}
Epoch:  469 -  {&#39;Reg_MSE&#39;: 36.5919789352}
Epoch:  470 -  {&#39;Reg_MSE&#39;: 36.5698746342}
Epoch:  471 -  {&#39;Reg_MSE&#39;: 36.5477922849}
Epoch:  472 -  {&#39;Reg_MSE&#39;: 36.5257318558}
Epoch:  473 -  {&#39;Reg_MSE&#39;: 36.5036933155}
Epoch:  474 -  {&#39;Reg_MSE&#39;: 36.4816766326}
Epoch:  475 -  {&#39;Reg_MSE&#39;: 36.4596817758}
Epoch:  476 -  {&#39;Reg_MSE&#39;: 36.4377087138}
Epoch:  477 -  {&#39;Reg_MSE&#39;: 36.4157574154}
Epoch:  478 -  {&#39;Reg_MSE&#39;: 36.3938278495}
Epoch:  479 -  {&#39;Reg_MSE&#39;: 36.371919985}
Epoch:  480 -  {&#39;Reg_MSE&#39;: 36.3500337908}
Epoch:  481 -  {&#39;Reg_MSE&#39;: 36.328169236}
Epoch:  482 -  {&#39;Reg_MSE&#39;: 36.3063262896}
Epoch:  483 -  {&#39;Reg_MSE&#39;: 36.2845049207}
Epoch:  484 -  {&#39;Reg_MSE&#39;: 36.2627050985}
Epoch:  485 -  {&#39;Reg_MSE&#39;: 36.2409267922}
Epoch:  486 -  {&#39;Reg_MSE&#39;: 36.2191699712}
Epoch:  487 -  {&#39;Reg_MSE&#39;: 36.1974346047}
Epoch:  488 -  {&#39;Reg_MSE&#39;: 36.1757206621}
Epoch:  489 -  {&#39;Reg_MSE&#39;: 36.154028113}
Epoch:  490 -  {&#39;Reg_MSE&#39;: 36.1323569267}
Epoch:  491 -  {&#39;Reg_MSE&#39;: 36.1107070729}
Epoch:  492 -  {&#39;Reg_MSE&#39;: 36.0890785212}
Epoch:  493 -  {&#39;Reg_MSE&#39;: 36.0674712411}
Epoch:  494 -  {&#39;Reg_MSE&#39;: 36.0458852025}
Epoch:  495 -  {&#39;Reg_MSE&#39;: 36.024320375}
Epoch:  496 -  {&#39;Reg_MSE&#39;: 36.0027767286}
Epoch:  497 -  {&#39;Reg_MSE&#39;: 35.981254233}
Epoch:  498 -  {&#39;Reg_MSE&#39;: 35.9597528582}
Epoch:  499 -  {&#39;Reg_MSE&#39;: 35.9382725743}
Epoch:  500 -  {&#39;Reg_MSE&#39;: 35.9168133511}
Epoch:  501 -  {&#39;Reg_MSE&#39;: 35.8953751588}
Epoch:  502 -  {&#39;Reg_MSE&#39;: 35.8739579675}
Epoch:  503 -  {&#39;Reg_MSE&#39;: 35.8525617475}
Epoch:  504 -  {&#39;Reg_MSE&#39;: 35.8311864689}
Epoch:  505 -  {&#39;Reg_MSE&#39;: 35.809832102}
Epoch:  506 -  {&#39;Reg_MSE&#39;: 35.7884986173}
Epoch:  507 -  {&#39;Reg_MSE&#39;: 35.767185985}
Epoch:  508 -  {&#39;Reg_MSE&#39;: 35.7458941757}
Epoch:  509 -  {&#39;Reg_MSE&#39;: 35.7246231598}
Epoch:  510 -  {&#39;Reg_MSE&#39;: 35.7033729079}
Epoch:  511 -  {&#39;Reg_MSE&#39;: 35.6821433905}
Epoch:  512 -  {&#39;Reg_MSE&#39;: 35.6609345785}
Epoch:  513 -  {&#39;Reg_MSE&#39;: 35.6397464423}
Epoch:  514 -  {&#39;Reg_MSE&#39;: 35.6185789529}
Epoch:  515 -  {&#39;Reg_MSE&#39;: 35.597432081}
Epoch:  516 -  {&#39;Reg_MSE&#39;: 35.5763057975}
Epoch:  517 -  {&#39;Reg_MSE&#39;: 35.5552000733}
Epoch:  518 -  {&#39;Reg_MSE&#39;: 35.5341148793}
Epoch:  519 -  {&#39;Reg_MSE&#39;: 35.5130501866}
Epoch:  520 -  {&#39;Reg_MSE&#39;: 35.4920059662}
Epoch:  521 -  {&#39;Reg_MSE&#39;: 35.4709821893}
Epoch:  522 -  {&#39;Reg_MSE&#39;: 35.449978827}
Epoch:  523 -  {&#39;Reg_MSE&#39;: 35.4289958505}
Epoch:  524 -  {&#39;Reg_MSE&#39;: 35.4080332312}
Epoch:  525 -  {&#39;Reg_MSE&#39;: 35.3870909402}
Epoch:  526 -  {&#39;Reg_MSE&#39;: 35.366168949}
Epoch:  527 -  {&#39;Reg_MSE&#39;: 35.3452672291}
Epoch:  528 -  {&#39;Reg_MSE&#39;: 35.3243857518}
Epoch:  529 -  {&#39;Reg_MSE&#39;: 35.3035244887}
Epoch:  530 -  {&#39;Reg_MSE&#39;: 35.2826834113}
Epoch:  531 -  {&#39;Reg_MSE&#39;: 35.2618624914}
Epoch:  532 -  {&#39;Reg_MSE&#39;: 35.2410617005}
Epoch:  533 -  {&#39;Reg_MSE&#39;: 35.2202810103}
Epoch:  534 -  {&#39;Reg_MSE&#39;: 35.1995203927}
Epoch:  535 -  {&#39;Reg_MSE&#39;: 35.1787798194}
Epoch:  536 -  {&#39;Reg_MSE&#39;: 35.1580592624}
Epoch:  537 -  {&#39;Reg_MSE&#39;: 35.1373586935}
Epoch:  538 -  {&#39;Reg_MSE&#39;: 35.1166780846}
Epoch:  539 -  {&#39;Reg_MSE&#39;: 35.0960174079}
Epoch:  540 -  {&#39;Reg_MSE&#39;: 35.0753766354}
Epoch:  541 -  {&#39;Reg_MSE&#39;: 35.0547557392}
Epoch:  542 -  {&#39;Reg_MSE&#39;: 35.0341546914}
Epoch:  543 -  {&#39;Reg_MSE&#39;: 35.0135734642}
Epoch:  544 -  {&#39;Reg_MSE&#39;: 34.99301203}
Epoch:  545 -  {&#39;Reg_MSE&#39;: 34.972470361}
Epoch:  546 -  {&#39;Reg_MSE&#39;: 34.9519484296}
Epoch:  547 -  {&#39;Reg_MSE&#39;: 34.9314462082}
Epoch:  548 -  {&#39;Reg_MSE&#39;: 34.9109636693}
Epoch:  549 -  {&#39;Reg_MSE&#39;: 34.8905007852}
Epoch:  550 -  {&#39;Reg_MSE&#39;: 34.8700575287}
Epoch:  551 -  {&#39;Reg_MSE&#39;: 34.8496338723}
Epoch:  552 -  {&#39;Reg_MSE&#39;: 34.8292297886}
Epoch:  553 -  {&#39;Reg_MSE&#39;: 34.8088452503}
Epoch:  554 -  {&#39;Reg_MSE&#39;: 34.7884802302}
Epoch:  555 -  {&#39;Reg_MSE&#39;: 34.7681347011}
Epoch:  556 -  {&#39;Reg_MSE&#39;: 34.7478086357}
Epoch:  557 -  {&#39;Reg_MSE&#39;: 34.7275020071}
Epoch:  558 -  {&#39;Reg_MSE&#39;: 34.707214788}
Epoch:  559 -  {&#39;Reg_MSE&#39;: 34.6869469516}
Epoch:  560 -  {&#39;Reg_MSE&#39;: 34.6666984708}
Epoch:  561 -  {&#39;Reg_MSE&#39;: 34.6464693186}
Epoch:  562 -  {&#39;Reg_MSE&#39;: 34.6262594683}
Epoch:  563 -  {&#39;Reg_MSE&#39;: 34.606068893}
Epoch:  564 -  {&#39;Reg_MSE&#39;: 34.5858975659}
Epoch:  565 -  {&#39;Reg_MSE&#39;: 34.5657454602}
Epoch:  566 -  {&#39;Reg_MSE&#39;: 34.5456125494}
Epoch:  567 -  {&#39;Reg_MSE&#39;: 34.5254988066}
Epoch:  568 -  {&#39;Reg_MSE&#39;: 34.5054042054}
Epoch:  569 -  {&#39;Reg_MSE&#39;: 34.4853287191}
Epoch:  570 -  {&#39;Reg_MSE&#39;: 34.4652723214}
Epoch:  571 -  {&#39;Reg_MSE&#39;: 34.4452349856}
Epoch:  572 -  {&#39;Reg_MSE&#39;: 34.4252166854}
Epoch:  573 -  {&#39;Reg_MSE&#39;: 34.4052173945}
Epoch:  574 -  {&#39;Reg_MSE&#39;: 34.3852370865}
Epoch:  575 -  {&#39;Reg_MSE&#39;: 34.3652757352}
Epoch:  576 -  {&#39;Reg_MSE&#39;: 34.3453333142}
Epoch:  577 -  {&#39;Reg_MSE&#39;: 34.3254097975}
Epoch:  578 -  {&#39;Reg_MSE&#39;: 34.3055051589}
Epoch:  579 -  {&#39;Reg_MSE&#39;: 34.2856193723}
Epoch:  580 -  {&#39;Reg_MSE&#39;: 34.2657524117}
Epoch:  581 -  {&#39;Reg_MSE&#39;: 34.245904251}
Epoch:  582 -  {&#39;Reg_MSE&#39;: 34.2260748644}
Epoch:  583 -  {&#39;Reg_MSE&#39;: 34.2062642258}
Epoch:  584 -  {&#39;Reg_MSE&#39;: 34.1864723095}
Epoch:  585 -  {&#39;Reg_MSE&#39;: 34.1666990895}
Epoch:  586 -  {&#39;Reg_MSE&#39;: 34.1469445403}
Epoch:  587 -  {&#39;Reg_MSE&#39;: 34.1272086359}
Epoch:  588 -  {&#39;Reg_MSE&#39;: 34.1074913508}
Epoch:  589 -  {&#39;Reg_MSE&#39;: 34.0877926593}
Epoch:  590 -  {&#39;Reg_MSE&#39;: 34.0681125357}
Epoch:  591 -  {&#39;Reg_MSE&#39;: 34.0484509546}
Epoch:  592 -  {&#39;Reg_MSE&#39;: 34.0288078905}
Epoch:  593 -  {&#39;Reg_MSE&#39;: 34.0091833178}
Epoch:  594 -  {&#39;Reg_MSE&#39;: 33.9895772112}
Epoch:  595 -  {&#39;Reg_MSE&#39;: 33.9699895453}
Epoch:  596 -  {&#39;Reg_MSE&#39;: 33.9504202948}
Epoch:  597 -  {&#39;Reg_MSE&#39;: 33.9308694343}
Epoch:  598 -  {&#39;Reg_MSE&#39;: 33.9113369387}
Epoch:  599 -  {&#39;Reg_MSE&#39;: 33.8918227827}
Epoch:  600 -  {&#39;Reg_MSE&#39;: 33.8723269413}
Epoch:  601 -  {&#39;Reg_MSE&#39;: 33.8528493892}
Epoch:  602 -  {&#39;Reg_MSE&#39;: 33.8333901014}
Epoch:  603 -  {&#39;Reg_MSE&#39;: 33.813949053}
Epoch:  604 -  {&#39;Reg_MSE&#39;: 33.7945262189}
Epoch:  605 -  {&#39;Reg_MSE&#39;: 33.7751215741}
Epoch:  606 -  {&#39;Reg_MSE&#39;: 33.7557350939}
Epoch:  607 -  {&#39;Reg_MSE&#39;: 33.7363667533}
Epoch:  608 -  {&#39;Reg_MSE&#39;: 33.7170165276}
Epoch:  609 -  {&#39;Reg_MSE&#39;: 33.697684392}
Epoch:  610 -  {&#39;Reg_MSE&#39;: 33.6783703217}
Epoch:  611 -  {&#39;Reg_MSE&#39;: 33.6590742921}
Epoch:  612 -  {&#39;Reg_MSE&#39;: 33.6397962786}
Epoch:  613 -  {&#39;Reg_MSE&#39;: 33.6205362566}
Epoch:  614 -  {&#39;Reg_MSE&#39;: 33.6012942015}
Epoch:  615 -  {&#39;Reg_MSE&#39;: 33.5820700889}
Epoch:  616 -  {&#39;Reg_MSE&#39;: 33.5628638942}
Epoch:  617 -  {&#39;Reg_MSE&#39;: 33.543675593}
Epoch:  618 -  {&#39;Reg_MSE&#39;: 33.524505161}
Epoch:  619 -  {&#39;Reg_MSE&#39;: 33.5053525739}
Epoch:  620 -  {&#39;Reg_MSE&#39;: 33.4862178073}
Epoch:  621 -  {&#39;Reg_MSE&#39;: 33.467100837}
Epoch:  622 -  {&#39;Reg_MSE&#39;: 33.4480016388}
Epoch:  623 -  {&#39;Reg_MSE&#39;: 33.4289201885}
Epoch:  624 -  {&#39;Reg_MSE&#39;: 33.4098564619}
Epoch:  625 -  {&#39;Reg_MSE&#39;: 33.3908104352}
Epoch:  626 -  {&#39;Reg_MSE&#39;: 33.371782084}
Epoch:  627 -  {&#39;Reg_MSE&#39;: 33.3527713846}
Epoch:  628 -  {&#39;Reg_MSE&#39;: 33.3337783129}
Epoch:  629 -  {&#39;Reg_MSE&#39;: 33.3148028449}
Epoch:  630 -  {&#39;Reg_MSE&#39;: 33.295844957}
Epoch:  631 -  {&#39;Reg_MSE&#39;: 33.276904625}
Epoch:  632 -  {&#39;Reg_MSE&#39;: 33.2579818255}
Epoch:  633 -  {&#39;Reg_MSE&#39;: 33.2390765344}
Epoch:  634 -  {&#39;Reg_MSE&#39;: 33.2201887282}
Epoch:  635 -  {&#39;Reg_MSE&#39;: 33.2013183832}
Epoch:  636 -  {&#39;Reg_MSE&#39;: 33.1824654757}
Epoch:  637 -  {&#39;Reg_MSE&#39;: 33.1636299822}
Epoch:  638 -  {&#39;Reg_MSE&#39;: 33.1448118791}
Epoch:  639 -  {&#39;Reg_MSE&#39;: 33.1260111429}
Epoch:  640 -  {&#39;Reg_MSE&#39;: 33.1072277501}
Epoch:  641 -  {&#39;Reg_MSE&#39;: 33.0884616774}
Epoch:  642 -  {&#39;Reg_MSE&#39;: 33.0697129013}
Epoch:  643 -  {&#39;Reg_MSE&#39;: 33.0509813985}
Epoch:  644 -  {&#39;Reg_MSE&#39;: 33.0322671456}
Epoch:  645 -  {&#39;Reg_MSE&#39;: 33.0135701195}
Epoch:  646 -  {&#39;Reg_MSE&#39;: 32.994890297}
Epoch:  647 -  {&#39;Reg_MSE&#39;: 32.9762276547}
Epoch:  648 -  {&#39;Reg_MSE&#39;: 32.9575821696}
Epoch:  649 -  {&#39;Reg_MSE&#39;: 32.9389538186}
Epoch:  650 -  {&#39;Reg_MSE&#39;: 32.9203425786}
Epoch:  651 -  {&#39;Reg_MSE&#39;: 32.9017484266}
Epoch:  652 -  {&#39;Reg_MSE&#39;: 32.8831713396}
Epoch:  653 -  {&#39;Reg_MSE&#39;: 32.8646112946}
Epoch:  654 -  {&#39;Reg_MSE&#39;: 32.8460682689}
Epoch:  655 -  {&#39;Reg_MSE&#39;: 32.8275422394}
Epoch:  656 -  {&#39;Reg_MSE&#39;: 32.8090331834}
Epoch:  657 -  {&#39;Reg_MSE&#39;: 32.790541078}
Epoch:  658 -  {&#39;Reg_MSE&#39;: 32.7720659006}
Epoch:  659 -  {&#39;Reg_MSE&#39;: 32.7536076285}
Epoch:  660 -  {&#39;Reg_MSE&#39;: 32.7351662388}
Epoch:  661 -  {&#39;Reg_MSE&#39;: 32.7167417092}
Epoch:  662 -  {&#39;Reg_MSE&#39;: 32.6983340168}
Epoch:  663 -  {&#39;Reg_MSE&#39;: 32.6799431392}
Epoch:  664 -  {&#39;Reg_MSE&#39;: 32.661569054}
Epoch:  665 -  {&#39;Reg_MSE&#39;: 32.6432117385}
Epoch:  666 -  {&#39;Reg_MSE&#39;: 32.6248711703}
Epoch:  667 -  {&#39;Reg_MSE&#39;: 32.6065473272}
Epoch:  668 -  {&#39;Reg_MSE&#39;: 32.5882401866}
Epoch:  669 -  {&#39;Reg_MSE&#39;: 32.5699497263}
Epoch:  670 -  {&#39;Reg_MSE&#39;: 32.5516759241}
Epoch:  671 -  {&#39;Reg_MSE&#39;: 32.5334187576}
Epoch:  672 -  {&#39;Reg_MSE&#39;: 32.5151782046}
Epoch:  673 -  {&#39;Reg_MSE&#39;: 32.4969542431}
Epoch:  674 -  {&#39;Reg_MSE&#39;: 32.4787468507}
Epoch:  675 -  {&#39;Reg_MSE&#39;: 32.4605560056}
Epoch:  676 -  {&#39;Reg_MSE&#39;: 32.4423816856}
Epoch:  677 -  {&#39;Reg_MSE&#39;: 32.4242238686}
Epoch:  678 -  {&#39;Reg_MSE&#39;: 32.4060825328}
Epoch:  679 -  {&#39;Reg_MSE&#39;: 32.3879576562}
Epoch:  680 -  {&#39;Reg_MSE&#39;: 32.3698492168}
Epoch:  681 -  {&#39;Reg_MSE&#39;: 32.3517571928}
Epoch:  682 -  {&#39;Reg_MSE&#39;: 32.3336815624}
Epoch:  683 -  {&#39;Reg_MSE&#39;: 32.3156223039}
Epoch:  684 -  {&#39;Reg_MSE&#39;: 32.2975793953}
Epoch:  685 -  {&#39;Reg_MSE&#39;: 32.2795528151}
Epoch:  686 -  {&#39;Reg_MSE&#39;: 32.2615425415}
Epoch:  687 -  {&#39;Reg_MSE&#39;: 32.2435485529}
Epoch:  688 -  {&#39;Reg_MSE&#39;: 32.2255708277}
Epoch:  689 -  {&#39;Reg_MSE&#39;: 32.2076093443}
Epoch:  690 -  {&#39;Reg_MSE&#39;: 32.1896640812}
Epoch:  691 -  {&#39;Reg_MSE&#39;: 32.171735017}
Epoch:  692 -  {&#39;Reg_MSE&#39;: 32.15382213}
Epoch:  693 -  {&#39;Reg_MSE&#39;: 32.135925399}
Epoch:  694 -  {&#39;Reg_MSE&#39;: 32.1180448026}
Epoch:  695 -  {&#39;Reg_MSE&#39;: 32.1001803193}
Epoch:  696 -  {&#39;Reg_MSE&#39;: 32.0823319279}
Epoch:  697 -  {&#39;Reg_MSE&#39;: 32.0644996071}
Epoch:  698 -  {&#39;Reg_MSE&#39;: 32.0466833357}
Epoch:  699 -  {&#39;Reg_MSE&#39;: 32.0288830925}
Epoch:  700 -  {&#39;Reg_MSE&#39;: 32.0110988562}
Epoch:  701 -  {&#39;Reg_MSE&#39;: 31.9933306058}
Epoch:  702 -  {&#39;Reg_MSE&#39;: 31.9755783202}
Epoch:  703 -  {&#39;Reg_MSE&#39;: 31.9578419783}
Epoch:  704 -  {&#39;Reg_MSE&#39;: 31.9401215591}
Epoch:  705 -  {&#39;Reg_MSE&#39;: 31.9224170416}
Epoch:  706 -  {&#39;Reg_MSE&#39;: 31.9047284049}
Epoch:  707 -  {&#39;Reg_MSE&#39;: 31.887055628}
Epoch:  708 -  {&#39;Reg_MSE&#39;: 31.8693986901}
Epoch:  709 -  {&#39;Reg_MSE&#39;: 31.8517575703}
Epoch:  710 -  {&#39;Reg_MSE&#39;: 31.8341322478}
Epoch:  711 -  {&#39;Reg_MSE&#39;: 31.8165227018}
Epoch:  712 -  {&#39;Reg_MSE&#39;: 31.7989289117}
Epoch:  713 -  {&#39;Reg_MSE&#39;: 31.7813508566}
Epoch:  714 -  {&#39;Reg_MSE&#39;: 31.763788516}
Epoch:  715 -  {&#39;Reg_MSE&#39;: 31.7462418692}
Epoch:  716 -  {&#39;Reg_MSE&#39;: 31.7287108956}
Epoch:  717 -  {&#39;Reg_MSE&#39;: 31.7111955746}
Epoch:  718 -  {&#39;Reg_MSE&#39;: 31.6936958857}
Epoch:  719 -  {&#39;Reg_MSE&#39;: 31.6762118085}
Epoch:  720 -  {&#39;Reg_MSE&#39;: 31.6587433224}
Epoch:  721 -  {&#39;Reg_MSE&#39;: 31.6412904071}
Epoch:  722 -  {&#39;Reg_MSE&#39;: 31.6238530421}
Epoch:  723 -  {&#39;Reg_MSE&#39;: 31.6064312072}
Epoch:  724 -  {&#39;Reg_MSE&#39;: 31.5890248819}
Epoch:  725 -  {&#39;Reg_MSE&#39;: 31.571634046}
Epoch:  726 -  {&#39;Reg_MSE&#39;: 31.5542586793}
Epoch:  727 -  {&#39;Reg_MSE&#39;: 31.5368987615}
Epoch:  728 -  {&#39;Reg_MSE&#39;: 31.5195542724}
Epoch:  729 -  {&#39;Reg_MSE&#39;: 31.502225192}
Epoch:  730 -  {&#39;Reg_MSE&#39;: 31.4849115001}
Epoch:  731 -  {&#39;Reg_MSE&#39;: 31.4676131765}
Epoch:  732 -  {&#39;Reg_MSE&#39;: 31.4503302014}
Epoch:  733 -  {&#39;Reg_MSE&#39;: 31.4330625546}
Epoch:  734 -  {&#39;Reg_MSE&#39;: 31.4158102162}
Epoch:  735 -  {&#39;Reg_MSE&#39;: 31.3985731662}
Epoch:  736 -  {&#39;Reg_MSE&#39;: 31.3813513848}
Epoch:  737 -  {&#39;Reg_MSE&#39;: 31.364144852}
Epoch:  738 -  {&#39;Reg_MSE&#39;: 31.346953548}
Epoch:  739 -  {&#39;Reg_MSE&#39;: 31.3297774531}
Epoch:  740 -  {&#39;Reg_MSE&#39;: 31.3126165473}
Epoch:  741 -  {&#39;Reg_MSE&#39;: 31.2954708111}
Epoch:  742 -  {&#39;Reg_MSE&#39;: 31.2783402246}
Epoch:  743 -  {&#39;Reg_MSE&#39;: 31.2612247683}
Epoch:  744 -  {&#39;Reg_MSE&#39;: 31.2441244224}
Epoch:  745 -  {&#39;Reg_MSE&#39;: 31.2270391673}
Epoch:  746 -  {&#39;Reg_MSE&#39;: 31.2099689836}
Epoch:  747 -  {&#39;Reg_MSE&#39;: 31.1929138516}
Epoch:  748 -  {&#39;Reg_MSE&#39;: 31.1758737518}
Epoch:  749 -  {&#39;Reg_MSE&#39;: 31.1588486648}
Epoch:  750 -  {&#39;Reg_MSE&#39;: 31.141838571}
Epoch:  751 -  {&#39;Reg_MSE&#39;: 31.1248434512}
Epoch:  752 -  {&#39;Reg_MSE&#39;: 31.1078632859}
Epoch:  753 -  {&#39;Reg_MSE&#39;: 31.0908980558}
Epoch:  754 -  {&#39;Reg_MSE&#39;: 31.0739477415}
Epoch:  755 -  {&#39;Reg_MSE&#39;: 31.0570123238}
Epoch:  756 -  {&#39;Reg_MSE&#39;: 31.0400917835}
Epoch:  757 -  {&#39;Reg_MSE&#39;: 31.0231861012}
Epoch:  758 -  {&#39;Reg_MSE&#39;: 31.0062952579}
Epoch:  759 -  {&#39;Reg_MSE&#39;: 30.9894192344}
Epoch:  760 -  {&#39;Reg_MSE&#39;: 30.9725580116}
Epoch:  761 -  {&#39;Reg_MSE&#39;: 30.9557115703}
Epoch:  762 -  {&#39;Reg_MSE&#39;: 30.9388798916}
Epoch:  763 -  {&#39;Reg_MSE&#39;: 30.9220629564}
Epoch:  764 -  {&#39;Reg_MSE&#39;: 30.9052607457}
Epoch:  765 -  {&#39;Reg_MSE&#39;: 30.8884732405}
Epoch:  766 -  {&#39;Reg_MSE&#39;: 30.871700422}
Epoch:  767 -  {&#39;Reg_MSE&#39;: 30.8549422712}
Epoch:  768 -  {&#39;Reg_MSE&#39;: 30.8381987693}
Epoch:  769 -  {&#39;Reg_MSE&#39;: 30.8214698974}
Epoch:  770 -  {&#39;Reg_MSE&#39;: 30.8047556368}
Epoch:  771 -  {&#39;Reg_MSE&#39;: 30.7880559686}
Epoch:  772 -  {&#39;Reg_MSE&#39;: 30.7713708742}
Epoch:  773 -  {&#39;Reg_MSE&#39;: 30.7547003348}
Epoch:  774 -  {&#39;Reg_MSE&#39;: 30.7380443318}
Epoch:  775 -  {&#39;Reg_MSE&#39;: 30.7214028465}
Epoch:  776 -  {&#39;Reg_MSE&#39;: 30.7047758603}
Epoch:  777 -  {&#39;Reg_MSE&#39;: 30.6881633547}
Epoch:  778 -  {&#39;Reg_MSE&#39;: 30.671565311}
Epoch:  779 -  {&#39;Reg_MSE&#39;: 30.6549817108}
Epoch:  780 -  {&#39;Reg_MSE&#39;: 30.6384125355}
Epoch:  781 -  {&#39;Reg_MSE&#39;: 30.6218577668}
Epoch:  782 -  {&#39;Reg_MSE&#39;: 30.6053173862}
Epoch:  783 -  {&#39;Reg_MSE&#39;: 30.5887913752}
Epoch:  784 -  {&#39;Reg_MSE&#39;: 30.5722797156}
Epoch:  785 -  {&#39;Reg_MSE&#39;: 30.555782389}
Epoch:  786 -  {&#39;Reg_MSE&#39;: 30.5392993772}
Epoch:  787 -  {&#39;Reg_MSE&#39;: 30.5228306617}
Epoch:  788 -  {&#39;Reg_MSE&#39;: 30.5063762245}
Epoch:  789 -  {&#39;Reg_MSE&#39;: 30.4899360472}
Epoch:  790 -  {&#39;Reg_MSE&#39;: 30.4735101117}
Epoch:  791 -  {&#39;Reg_MSE&#39;: 30.4570983999}
Epoch:  792 -  {&#39;Reg_MSE&#39;: 30.4407008936}
Epoch:  793 -  {&#39;Reg_MSE&#39;: 30.4243175748}
Epoch:  794 -  {&#39;Reg_MSE&#39;: 30.4079484253}
Epoch:  795 -  {&#39;Reg_MSE&#39;: 30.3915934272}
Epoch:  796 -  {&#39;Reg_MSE&#39;: 30.3752525625}
Epoch:  797 -  {&#39;Reg_MSE&#39;: 30.3589258132}
Epoch:  798 -  {&#39;Reg_MSE&#39;: 30.3426131613}
Epoch:  799 -  {&#39;Reg_MSE&#39;: 30.326314589}
Epoch:  800 -  {&#39;Reg_MSE&#39;: 30.3100300783}
Epoch:  801 -  {&#39;Reg_MSE&#39;: 30.2937596115}
Epoch:  802 -  {&#39;Reg_MSE&#39;: 30.2775031707}
Epoch:  803 -  {&#39;Reg_MSE&#39;: 30.2612607381}
Epoch:  804 -  {&#39;Reg_MSE&#39;: 30.2450322959}
Epoch:  805 -  {&#39;Reg_MSE&#39;: 30.2288178265}
Epoch:  806 -  {&#39;Reg_MSE&#39;: 30.212617312}
Epoch:  807 -  {&#39;Reg_MSE&#39;: 30.196430735}
Epoch:  808 -  {&#39;Reg_MSE&#39;: 30.1802580776}
Epoch:  809 -  {&#39;Reg_MSE&#39;: 30.1640993224}
Epoch:  810 -  {&#39;Reg_MSE&#39;: 30.1479544516}
Epoch:  811 -  {&#39;Reg_MSE&#39;: 30.1318234479}
Epoch:  812 -  {&#39;Reg_MSE&#39;: 30.1157062935}
Epoch:  813 -  {&#39;Reg_MSE&#39;: 30.0996029711}
Epoch:  814 -  {&#39;Reg_MSE&#39;: 30.0835134632}
Epoch:  815 -  {&#39;Reg_MSE&#39;: 30.0674377524}
Epoch:  816 -  {&#39;Reg_MSE&#39;: 30.0513758211}
Epoch:  817 -  {&#39;Reg_MSE&#39;: 30.0353276521}
Epoch:  818 -  {&#39;Reg_MSE&#39;: 30.019293228}
Epoch:  819 -  {&#39;Reg_MSE&#39;: 30.0032725315}
Epoch:  820 -  {&#39;Reg_MSE&#39;: 29.9872655453}
Epoch:  821 -  {&#39;Reg_MSE&#39;: 29.9712722521}
Epoch:  822 -  {&#39;Reg_MSE&#39;: 29.9552926347}
Epoch:  823 -  {&#39;Reg_MSE&#39;: 29.9393266759}
Epoch:  824 -  {&#39;Reg_MSE&#39;: 29.9233743585}
Epoch:  825 -  {&#39;Reg_MSE&#39;: 29.9074356653}
Epoch:  826 -  {&#39;Reg_MSE&#39;: 29.8915105792}
Epoch:  827 -  {&#39;Reg_MSE&#39;: 29.8755990832}
Epoch:  828 -  {&#39;Reg_MSE&#39;: 29.8597011602}
Epoch:  829 -  {&#39;Reg_MSE&#39;: 29.8438167931}
Epoch:  830 -  {&#39;Reg_MSE&#39;: 29.8279459649}
Epoch:  831 -  {&#39;Reg_MSE&#39;: 29.8120886587}
Epoch:  832 -  {&#39;Reg_MSE&#39;: 29.7962448575}
Epoch:  833 -  {&#39;Reg_MSE&#39;: 29.7804145443}
Epoch:  834 -  {&#39;Reg_MSE&#39;: 29.7645977024}
Epoch:  835 -  {&#39;Reg_MSE&#39;: 29.7487943147}
Epoch:  836 -  {&#39;Reg_MSE&#39;: 29.7330043645}
Epoch:  837 -  {&#39;Reg_MSE&#39;: 29.7172278349}
Epoch:  838 -  {&#39;Reg_MSE&#39;: 29.7014647093}
Epoch:  839 -  {&#39;Reg_MSE&#39;: 29.6857149707}
Epoch:  840 -  {&#39;Reg_MSE&#39;: 29.6699786025}
Epoch:  841 -  {&#39;Reg_MSE&#39;: 29.654255588}
Epoch:  842 -  {&#39;Reg_MSE&#39;: 29.6385459105}
Epoch:  843 -  {&#39;Reg_MSE&#39;: 29.6228495534}
Epoch:  844 -  {&#39;Reg_MSE&#39;: 29.6071665}
Epoch:  845 -  {&#39;Reg_MSE&#39;: 29.5914967337}
Epoch:  846 -  {&#39;Reg_MSE&#39;: 29.5758402381}
Epoch:  847 -  {&#39;Reg_MSE&#39;: 29.5601969965}
Epoch:  848 -  {&#39;Reg_MSE&#39;: 29.5445669924}
Epoch:  849 -  {&#39;Reg_MSE&#39;: 29.5289502094}
Epoch:  850 -  {&#39;Reg_MSE&#39;: 29.513346631}
Epoch:  851 -  {&#39;Reg_MSE&#39;: 29.4977562407}
Epoch:  852 -  {&#39;Reg_MSE&#39;: 29.4821790222}
Epoch:  853 -  {&#39;Reg_MSE&#39;: 29.4666149592}
Epoch:  854 -  {&#39;Reg_MSE&#39;: 29.4510640351}
Epoch:  855 -  {&#39;Reg_MSE&#39;: 29.4355262339}
Epoch:  856 -  {&#39;Reg_MSE&#39;: 29.420001539}
Epoch:  857 -  {&#39;Reg_MSE&#39;: 29.4044899343}
Epoch:  858 -  {&#39;Reg_MSE&#39;: 29.3889914035}
Epoch:  859 -  {&#39;Reg_MSE&#39;: 29.3735059305}
Epoch:  860 -  {&#39;Reg_MSE&#39;: 29.358033499}
Epoch:  861 -  {&#39;Reg_MSE&#39;: 29.3425740928}
Epoch:  862 -  {&#39;Reg_MSE&#39;: 29.3271276959}
Epoch:  863 -  {&#39;Reg_MSE&#39;: 29.3116942921}
Epoch:  864 -  {&#39;Reg_MSE&#39;: 29.2962738654}
Epoch:  865 -  {&#39;Reg_MSE&#39;: 29.2808663996}
Epoch:  866 -  {&#39;Reg_MSE&#39;: 29.2654718789}
Epoch:  867 -  {&#39;Reg_MSE&#39;: 29.250090287}
Epoch:  868 -  {&#39;Reg_MSE&#39;: 29.2347216082}
Epoch:  869 -  {&#39;Reg_MSE&#39;: 29.2193658264}
Epoch:  870 -  {&#39;Reg_MSE&#39;: 29.2040229258}
Epoch:  871 -  {&#39;Reg_MSE&#39;: 29.1886928903}
Epoch:  872 -  {&#39;Reg_MSE&#39;: 29.1733757042}
Epoch:  873 -  {&#39;Reg_MSE&#39;: 29.1580713516}
Epoch:  874 -  {&#39;Reg_MSE&#39;: 29.1427798167}
Epoch:  875 -  {&#39;Reg_MSE&#39;: 29.1275010836}
Epoch:  876 -  {&#39;Reg_MSE&#39;: 29.1122351367}
Epoch:  877 -  {&#39;Reg_MSE&#39;: 29.0969819602}
Epoch:  878 -  {&#39;Reg_MSE&#39;: 29.0817415384}
Epoch:  879 -  {&#39;Reg_MSE&#39;: 29.0665138555}
Epoch:  880 -  {&#39;Reg_MSE&#39;: 29.0512988959}
Epoch:  881 -  {&#39;Reg_MSE&#39;: 29.0360966441}
Epoch:  882 -  {&#39;Reg_MSE&#39;: 29.0209070842}
Epoch:  883 -  {&#39;Reg_MSE&#39;: 29.0057302009}
Epoch:  884 -  {&#39;Reg_MSE&#39;: 28.9905659784}
Epoch:  885 -  {&#39;Reg_MSE&#39;: 28.9754144014}
Epoch:  886 -  {&#39;Reg_MSE&#39;: 28.9602754542}
Epoch:  887 -  {&#39;Reg_MSE&#39;: 28.9451491214}
Epoch:  888 -  {&#39;Reg_MSE&#39;: 28.9300353875}
Epoch:  889 -  {&#39;Reg_MSE&#39;: 28.914934237}
Epoch:  890 -  {&#39;Reg_MSE&#39;: 28.8998456547}
Epoch:  891 -  {&#39;Reg_MSE&#39;: 28.884769625}
Epoch:  892 -  {&#39;Reg_MSE&#39;: 28.8697061327}
Epoch:  893 -  {&#39;Reg_MSE&#39;: 28.8546551623}
Epoch:  894 -  {&#39;Reg_MSE&#39;: 28.8396166987}
Epoch:  895 -  {&#39;Reg_MSE&#39;: 28.8245907264}
Epoch:  896 -  {&#39;Reg_MSE&#39;: 28.8095772303}
Epoch:  897 -  {&#39;Reg_MSE&#39;: 28.794576195}
Epoch:  898 -  {&#39;Reg_MSE&#39;: 28.7795876055}
Epoch:  899 -  {&#39;Reg_MSE&#39;: 28.7646114464}
Epoch:  900 -  {&#39;Reg_MSE&#39;: 28.7496477027}
Epoch:  901 -  {&#39;Reg_MSE&#39;: 28.7346963592}
Epoch:  902 -  {&#39;Reg_MSE&#39;: 28.7197574008}
Epoch:  903 -  {&#39;Reg_MSE&#39;: 28.7048308124}
Epoch:  904 -  {&#39;Reg_MSE&#39;: 28.689916579}
Epoch:  905 -  {&#39;Reg_MSE&#39;: 28.6750146854}
Epoch:  906 -  {&#39;Reg_MSE&#39;: 28.6601251168}
Epoch:  907 -  {&#39;Reg_MSE&#39;: 28.645247858}
Epoch:  908 -  {&#39;Reg_MSE&#39;: 28.6303828942}
Epoch:  909 -  {&#39;Reg_MSE&#39;: 28.6155302104}
Epoch:  910 -  {&#39;Reg_MSE&#39;: 28.6006897916}
Epoch:  911 -  {&#39;Reg_MSE&#39;: 28.5858616231}
Epoch:  912 -  {&#39;Reg_MSE&#39;: 28.5710456898}
Epoch:  913 -  {&#39;Reg_MSE&#39;: 28.5562419771}
Epoch:  914 -  {&#39;Reg_MSE&#39;: 28.54145047}
Epoch:  915 -  {&#39;Reg_MSE&#39;: 28.5266711537}
Epoch:  916 -  {&#39;Reg_MSE&#39;: 28.5119040136}
Epoch:  917 -  {&#39;Reg_MSE&#39;: 28.4971490347}
Epoch:  918 -  {&#39;Reg_MSE&#39;: 28.4824062025}
Epoch:  919 -  {&#39;Reg_MSE&#39;: 28.4676755022}
Epoch:  920 -  {&#39;Reg_MSE&#39;: 28.4529569192}
Epoch:  921 -  {&#39;Reg_MSE&#39;: 28.4382504387}
Epoch:  922 -  {&#39;Reg_MSE&#39;: 28.4235560462}
Epoch:  923 -  {&#39;Reg_MSE&#39;: 28.408873727}
Epoch:  924 -  {&#39;Reg_MSE&#39;: 28.3942034666}
Epoch:  925 -  {&#39;Reg_MSE&#39;: 28.3795452504}
Epoch:  926 -  {&#39;Reg_MSE&#39;: 28.3648990638}
Epoch:  927 -  {&#39;Reg_MSE&#39;: 28.3502648925}
Epoch:  928 -  {&#39;Reg_MSE&#39;: 28.3356427218}
Epoch:  929 -  {&#39;Reg_MSE&#39;: 28.3210325373}
Epoch:  930 -  {&#39;Reg_MSE&#39;: 28.3064343246}
Epoch:  931 -  {&#39;Reg_MSE&#39;: 28.2918480692}
Epoch:  932 -  {&#39;Reg_MSE&#39;: 28.2772737568}
Epoch:  933 -  {&#39;Reg_MSE&#39;: 28.262711373}
Epoch:  934 -  {&#39;Reg_MSE&#39;: 28.2481609034}
Epoch:  935 -  {&#39;Reg_MSE&#39;: 28.2336223337}
Epoch:  936 -  {&#39;Reg_MSE&#39;: 28.2190956497}
Epoch:  937 -  {&#39;Reg_MSE&#39;: 28.2045808369}
Epoch:  938 -  {&#39;Reg_MSE&#39;: 28.1900778813}
Epoch:  939 -  {&#39;Reg_MSE&#39;: 28.1755867685}
Epoch:  940 -  {&#39;Reg_MSE&#39;: 28.1611074843}
Epoch:  941 -  {&#39;Reg_MSE&#39;: 28.1466400145}
Epoch:  942 -  {&#39;Reg_MSE&#39;: 28.1321843451}
Epoch:  943 -  {&#39;Reg_MSE&#39;: 28.1177404618}
Epoch:  944 -  {&#39;Reg_MSE&#39;: 28.1033083504}
Epoch:  945 -  {&#39;Reg_MSE&#39;: 28.0888879971}
Epoch:  946 -  {&#39;Reg_MSE&#39;: 28.0744793875}
Epoch:  947 -  {&#39;Reg_MSE&#39;: 28.0600825078}
Epoch:  948 -  {&#39;Reg_MSE&#39;: 28.0456973439}
Epoch:  949 -  {&#39;Reg_MSE&#39;: 28.0313238817}
Epoch:  950 -  {&#39;Reg_MSE&#39;: 28.0169621072}
Epoch:  951 -  {&#39;Reg_MSE&#39;: 28.0026120067}
Epoch:  952 -  {&#39;Reg_MSE&#39;: 27.988273566}
Epoch:  953 -  {&#39;Reg_MSE&#39;: 27.9739467712}
Epoch:  954 -  {&#39;Reg_MSE&#39;: 27.9596316085}
Epoch:  955 -  {&#39;Reg_MSE&#39;: 27.9453280641}
Epoch:  956 -  {&#39;Reg_MSE&#39;: 27.931036124}
Epoch:  957 -  {&#39;Reg_MSE&#39;: 27.9167557744}
Epoch:  958 -  {&#39;Reg_MSE&#39;: 27.9024870015}
Epoch:  959 -  {&#39;Reg_MSE&#39;: 27.8882297916}
Epoch:  960 -  {&#39;Reg_MSE&#39;: 27.8739841309}
Epoch:  961 -  {&#39;Reg_MSE&#39;: 27.8597500055}
Epoch:  962 -  {&#39;Reg_MSE&#39;: 27.845527402}
Epoch:  963 -  {&#39;Reg_MSE&#39;: 27.8313163064}
Epoch:  964 -  {&#39;Reg_MSE&#39;: 27.8171167052}
Epoch:  965 -  {&#39;Reg_MSE&#39;: 27.8029285847}
Epoch:  966 -  {&#39;Reg_MSE&#39;: 27.7887519313}
Epoch:  967 -  {&#39;Reg_MSE&#39;: 27.7745867313}
Epoch:  968 -  {&#39;Reg_MSE&#39;: 27.7604329713}
Epoch:  969 -  {&#39;Reg_MSE&#39;: 27.7462906375}
Epoch:  970 -  {&#39;Reg_MSE&#39;: 27.7321597166}
Epoch:  971 -  {&#39;Reg_MSE&#39;: 27.7180401948}
Epoch:  972 -  {&#39;Reg_MSE&#39;: 27.7039320589}
Epoch:  973 -  {&#39;Reg_MSE&#39;: 27.6898352952}
Epoch:  974 -  {&#39;Reg_MSE&#39;: 27.6757498904}
Epoch:  975 -  {&#39;Reg_MSE&#39;: 27.6616758309}
Epoch:  976 -  {&#39;Reg_MSE&#39;: 27.6476131034}
Epoch:  977 -  {&#39;Reg_MSE&#39;: 27.6335616945}
Epoch:  978 -  {&#39;Reg_MSE&#39;: 27.6195215909}
Epoch:  979 -  {&#39;Reg_MSE&#39;: 27.6054927791}
Epoch:  980 -  {&#39;Reg_MSE&#39;: 27.5914752458}
Epoch:  981 -  {&#39;Reg_MSE&#39;: 27.5774689777}
Epoch:  982 -  {&#39;Reg_MSE&#39;: 27.5634739617}
Epoch:  983 -  {&#39;Reg_MSE&#39;: 27.5494901842}
Epoch:  984 -  {&#39;Reg_MSE&#39;: 27.5355176323}
Epoch:  985 -  {&#39;Reg_MSE&#39;: 27.5215562925}
Epoch:  986 -  {&#39;Reg_MSE&#39;: 27.5076061518}
Epoch:  987 -  {&#39;Reg_MSE&#39;: 27.4936671969}
Epoch:  988 -  {&#39;Reg_MSE&#39;: 27.4797394147}
Epoch:  989 -  {&#39;Reg_MSE&#39;: 27.4658227921}
Epoch:  990 -  {&#39;Reg_MSE&#39;: 27.4519173158}
Epoch:  991 -  {&#39;Reg_MSE&#39;: 27.4380229729}
Epoch:  992 -  {&#39;Reg_MSE&#39;: 27.4241397502}
Epoch:  993 -  {&#39;Reg_MSE&#39;: 27.4102676348}
Epoch:  994 -  {&#39;Reg_MSE&#39;: 27.3964066135}
Epoch:  995 -  {&#39;Reg_MSE&#39;: 27.3825566733}
Epoch:  996 -  {&#39;Reg_MSE&#39;: 27.3687178013}
Epoch:  997 -  {&#39;Reg_MSE&#39;: 27.3548899845}
Epoch:  998 -  {&#39;Reg_MSE&#39;: 27.34107321}
Epoch:  999 -  {&#39;Reg_MSE&#39;: 27.3272674647}
Epoch:  1000 -  {&#39;Reg_MSE&#39;: 27.3134727359}
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="79" data-colab="{&quot;height&quot;:531,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="JELwA5eWYK5c" data-outputId="82ce8219-7427-4dd7-e2e0-321d2bd00290">
<div class="sourceCode" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(main_loss))</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="co"># loss</span></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>plt.plot(main_loss)</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy</span></span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>plt.plot(main_loss_1)</span>
<span id="cb102-8"><a href="#cb102-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>1000
</code></pre>
</div>
<div class="output display_data">
<p><img src="assets/img_10.png" /></p>
</div>
<div class="output display_data">
<p><img src="assets/img_11.png" /></p>
</div>
</div>
<div class="cell markdown" id="WqkYDseWBtR-">
<p>We have got 53.4 percent class accuracy while implementing Homegrown logistic regression. We have used our homework class notebook code to implement homegrown logistic and linear regression. For cxe_mxe we have done 1000 epochs and at 1000th epoch we got cxe+mse as 31.49, cxe as 4.7, and mse as 26.791.</p>
</div>
<section id="multilayer-perceptron" class="cell markdown" id="loW9ywRntwdA">
<h1>Multilayer perceptron</h1>
</section>
<section id="preprocess" class="cell markdown" id="eyeWTvGZ8_Ob">
<h2>preprocess</h2>
</section>
<div class="cell code" data-execution_count="79" id="NMZQOcOE8-p8">
<div class="sourceCode" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code" data-execution_count="81" id="QDIfRJMLtv9x">
<div class="sourceCode" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.image <span class="im">as</span> mpimg</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.exceptions <span class="im">import</span> ConvergenceWarning</span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier, SGDRegressor</span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, mean_squared_error, roc_auc_score</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tarfile</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="83" id="UvVytcjhwqUu">
<div class="sourceCode" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_tar(<span class="bu">file</span>, path):</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="co">    function to extract tar.gz files to specified location</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a><span class="co">        file (str): path where the file is located</span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a><span class="co">        path (str): path where you want to extract</span></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> tarfile.<span class="bu">open</span>(<span class="bu">file</span>) <span class="im">as</span> tar:</span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a>        files_extracted <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> member <span class="kw">in</span> tqdm(tar.getmembers()):</span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> os.path.isfile(path <span class="op">+</span> member.name[<span class="dv">1</span>:]):</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>                tar.extract(member, path)</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>                files_extracted <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a>        tar.close()</span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> files_extracted <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Files already exist&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="84" id="d6v4dJiqj6-E">
<div class="sourceCode" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>extract_path <span class="op">=</span> <span class="st">&#39;images/&#39;</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>image_file_name <span class="op">=</span> <span class="st">&#39;cadod.tar.gz&#39;</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>bounding_box_file_name <span class="op">=</span> <span class="st">&#39;cadod.csv&#39;</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>image_path <span class="op">=</span> os.path.join(DATA_DIR, image_file_name)</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>bounding_box_path <span class="op">=</span> os.path.join(DATA_DIR, bounding_box_file_name)</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>resize_path <span class="op">=</span> os.path.join(extract_path, <span class="st">&quot;resized&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="85" id="FyCDRxyVj5NE">
<div class="sourceCode" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p $resize_path</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="86" data-colab="{&quot;height&quot;:66,&quot;referenced_widgets&quot;:[&quot;487051ecd3af4ab8aa6ec00939499426&quot;,&quot;2edf57322e68439bb756b19c6c966c22&quot;,&quot;e4203447614b47f99f1465ef1e16eb44&quot;,&quot;71e91fac519e4d7980ab634bb1e9e4ba&quot;,&quot;6b59100965f84d16ae8d52c821c40543&quot;,&quot;235b51365a2d40be984e289963d87106&quot;,&quot;092b7db3c89340649f47438ad898b2c0&quot;,&quot;42f24a9b41fb4571ad394f45561d8814&quot;,&quot;e033c822ff3f476b982461153adb2aca&quot;,&quot;45ecfe23188e4bb289100b82955e9454&quot;,&quot;d211a1932e4341959f76dcb26d96923d&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="9mubNMmnwqUu" data-outputId="99545547-4538-4f52-9bbb-eb341b0fa93f">
<div class="sourceCode" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>extract_tar(image_path, extract_path)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb110"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;487051ecd3af4ab8aa6ec00939499426&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Files already exist
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="87" id="3Uqf27lewqUv">
<div class="sourceCode" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(bounding_box_path)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="88" data-colab="{&quot;height&quot;:299,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="hI2v56TSwqUv" data-outputId="519b65cc-63aa-48d2-b27c-5b1f76ed5865">
<div class="sourceCode" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="88">

  <div id="df-22992fa1-6ad9-4068-b53b-4e55d6f507b7">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ImageID</th>
      <th>Source</th>
      <th>LabelName</th>
      <th>Confidence</th>
      <th>XMin</th>
      <th>XMax</th>
      <th>YMin</th>
      <th>YMax</th>
      <th>IsOccluded</th>
      <th>IsTruncated</th>
      <th>...</th>
      <th>IsDepiction</th>
      <th>IsInside</th>
      <th>XClick1X</th>
      <th>XClick2X</th>
      <th>XClick3X</th>
      <th>XClick4X</th>
      <th>XClick1Y</th>
      <th>XClick2Y</th>
      <th>XClick3Y</th>
      <th>XClick4Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0000b9fcba019d36</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.165000</td>
      <td>0.903750</td>
      <td>0.268333</td>
      <td>0.998333</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.636250</td>
      <td>0.903750</td>
      <td>0.748750</td>
      <td>0.165000</td>
      <td>0.268333</td>
      <td>0.506667</td>
      <td>0.998333</td>
      <td>0.661667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0000cb13febe0138</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.000000</td>
      <td>0.651875</td>
      <td>0.000000</td>
      <td>0.999062</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.312500</td>
      <td>0.000000</td>
      <td>0.317500</td>
      <td>0.651875</td>
      <td>0.000000</td>
      <td>0.410882</td>
      <td>0.999062</td>
      <td>0.999062</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0005a9520eb22c19</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.094167</td>
      <td>0.611667</td>
      <td>0.055626</td>
      <td>0.998736</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.487500</td>
      <td>0.611667</td>
      <td>0.243333</td>
      <td>0.094167</td>
      <td>0.055626</td>
      <td>0.226296</td>
      <td>0.998736</td>
      <td>0.305942</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0006303f02219b07</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.000000</td>
      <td>0.999219</td>
      <td>0.000000</td>
      <td>0.998824</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.508594</td>
      <td>0.999219</td>
      <td>0.000000</td>
      <td>0.478906</td>
      <td>0.000000</td>
      <td>0.375294</td>
      <td>0.720000</td>
      <td>0.998824</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00064d23bf997652</td>
      <td>xclick</td>
      <td>/m/0bt9lr</td>
      <td>1</td>
      <td>0.240938</td>
      <td>0.906183</td>
      <td>0.000000</td>
      <td>0.694286</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0.678038</td>
      <td>0.906183</td>
      <td>0.240938</td>
      <td>0.522388</td>
      <td>0.000000</td>
      <td>0.370000</td>
      <td>0.424286</td>
      <td>0.694286</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-22992fa1-6ad9-4068-b53b-4e55d6f507b7')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-22992fa1-6ad9-4068-b53b-4e55d6f507b7 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-22992fa1-6ad9-4068-b53b-4e55d6f507b7');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<div class="cell code" data-execution_count="89" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="2VdkQ009x7q7" data-outputId="d08d2cb3-0c55-43e9-b3bc-0eaf1ad1c7dc">
<div class="sourceCode" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>df.LabelName.unique()</span></code></pre></div>
<div class="output execute_result" data-execution_count="89">
<pre><code>array([&#39;/m/0bt9lr&#39;, &#39;/m/01yrx&#39;], dtype=object)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="90" id="ZVDRo0XVx3YM">
<div class="sourceCode" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>df.LabelName.replace({<span class="st">&#39;/m/01yrx&#39;</span>:<span class="st">&#39;cat&#39;</span>, <span class="st">&#39;/m/0bt9lr&#39;</span>:<span class="st">&#39;dog&#39;</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="91" id="vbPbUIHxzhNv">
<div class="sourceCode" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> datasets</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="92" id="nwtunevvwQim">
<div class="sourceCode" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="93" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="UZy6NJrruCNZ" data-outputId="783f9274-66bb-45cb-c0ef-59e7cdb476a5">
<div class="sourceCode" id="cb119"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>df.shape[<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="93">
<pre><code>12966</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="94" data-colab="{&quot;height&quot;:49,&quot;referenced_widgets&quot;:[&quot;aa679f6a7dc44715816875605679f216&quot;,&quot;126cf1bde1354389a790a4450a32a061&quot;,&quot;5c1228343f64431eb6a9483b3974ad01&quot;,&quot;f236386079a14f5bb42aeae826c99b38&quot;,&quot;1230a23e08e84eddb080c6c91072dc52&quot;,&quot;fb268bfdcf2843358839df50be84474c&quot;,&quot;1d2601ba04964d2cac9474b2fe03cd1d&quot;,&quot;a09209d0569e40ca8869e300b5d5d75d&quot;,&quot;563c4d06a1fd4d59aaee81e4416dffad&quot;,&quot;90b3e150e42b41f99675e927fadad45c&quot;,&quot;293ff5fa69194454ac96150c942e1c53&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="howFxmHXrLhG" data-outputId="eb71166d-0d73-44b2-adc1-54fd945ba134">
<div class="sourceCode" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Getting and resizing images</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> np.zeros((df.shape[<span class="dv">0</span>],<span class="dv">32</span><span class="op">*</span><span class="dv">32</span><span class="op">*</span><span class="dv">3</span>)) </span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, <span class="bu">id</span> <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(df.ImageID)):</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(extract_path<span class="op">+</span><span class="bu">id</span><span class="op">+</span><span class="st">&#39;.jpg&#39;</span>)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    images[i] <span class="op">=</span> np.asarray(img.resize((<span class="dv">32</span>,<span class="dv">32</span>))).flatten()</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb122"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;aa679f6a7dc44715816875605679f216&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell code" data-execution_count="95" id="jS-qPQpCAAPR">
<div class="sourceCode" id="cb123"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Normalization</span></span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>mean<span class="op">=</span>[]</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>std<span class="op">=</span>[]</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(images)):</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>  mean.append(np.array(images[i], dtype<span class="op">=</span>np.uint8).flatten().mean()<span class="op">/</span><span class="dv">255</span>)</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>  std.append(np.array(images[i], dtype<span class="op">=</span>np.uint8).flatten().std()<span class="op">/</span><span class="dv">255</span>)</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>images_tensor <span class="op">=</span> [np.<span class="bu">round</span>((((images[i]<span class="op">/</span><span class="dv">255</span>)<span class="op">-</span>mean[i])<span class="op">/</span>std[i]),<span class="dv">5</span>).astype(np.float32) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(images))]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="96" id="n79616GDxsff">
<div class="sourceCode" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="97" id="vubCXUCivQgc">
<div class="sourceCode" id="cb125"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;type&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;LabelName&#39;</span>].<span class="bu">map</span>( {<span class="st">&#39;dog&#39;</span>: <span class="dv">1</span>, <span class="st">&#39;cat&#39;</span>: <span class="dv">0</span>})</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="98" id="Y-Jy9OUg8KOI">
<div class="sourceCode" id="cb126"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> df[<span class="st">&#39;type&#39;</span>].to_numpy()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="99" id="CNsorxVmtGrf">
<div class="sourceCode" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(images_tensor, labels, test_size<span class="op">=</span><span class="fl">0.33</span>,random_state<span class="op">=</span><span class="dv">25</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="100" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="68DLE2tKweWZ" data-outputId="395e5af2-1aea-48d1-fa9d-254b88857496">
<div class="sourceCode" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>y_train.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="100">
<pre><code>(8687,)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="101" id="WrKQnCpwxv3I">
<div class="sourceCode" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader([ [X_train[i], y_train[i]] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y_train))],shuffle <span class="op">=</span> <span class="va">True</span>, batch_size <span class="op">=</span> <span class="dv">300</span>)</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> torch.utils.data.DataLoader([ [X_test[i], y_test[i]] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y_test))],shuffle <span class="op">=</span> <span class="va">True</span>, batch_size <span class="op">=</span> <span class="dv">300</span>)</span></code></pre></div>
</div>
<section id="classification-using-multilayer-perceptron" class="cell markdown" id="uDNUDXENzCZC">
<h2>Classification using multilayer perceptron</h2>
</section>
<div class="cell code" data-execution_count="102" id="M8aPVnJOypBM">
<div class="sourceCode" id="cb131"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> classifier(nn.Module):</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()        </span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_layer <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">32</span> <span class="op">*</span><span class="dv">3</span>, <span class="dv">250</span>)</span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layer <span class="op">=</span> nn.Linear(<span class="dv">250</span>, <span class="dv">100</span>)</span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(<span class="dv">100</span>, <span class="dv">2</span>)</span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):                       </span>
<span id="cb131-9"><a href="#cb131-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.input_layer(x)</span>
<span id="cb131-10"><a href="#cb131-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)     </span>
<span id="cb131-11"><a href="#cb131-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.hidden_layer(x)</span>
<span id="cb131-12"><a href="#cb131-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)     </span>
<span id="cb131-13"><a href="#cb131-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output_layer(x)</span>
<span id="cb131-14"><a href="#cb131-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="103" id="ofNtGqjP0cRP">
<div class="sourceCode" id="cb132"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> classifier().to(device)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="104" id="13STzyu30ub4">
<div class="sourceCode" id="cb133"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="105" id="SPOUB1DP6KoR">
<div class="sourceCode" id="cb134"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(net, device, trainSet,testSet, optimizer,epoch,criterion):</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>    totalLoss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>    correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x,y <span class="kw">in</span> trainSet:</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> x.to(device)</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>      y <span class="op">=</span> y.to(device)</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>      pred <span class="op">=</span> net(x)</span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> criterion(pred, y)</span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb134-12"><a href="#cb134-12" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb134-13"><a href="#cb134-13" aria-hidden="true" tabindex="-1"></a>      totalLoss<span class="op">+=</span>loss.item()</span>
<span id="cb134-14"><a href="#cb134-14" aria-hidden="true" tabindex="-1"></a>      predictedLabels <span class="op">=</span> pred.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb134-15"><a href="#cb134-15" aria-hidden="true" tabindex="-1"></a>      correct <span class="op">+=</span> predictedLabels.eq(y.view_as(predictedLabels)).<span class="bu">sum</span>().item()</span>
<span id="cb134-16"><a href="#cb134-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-17"><a href="#cb134-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">  Train Average Loss: </span><span class="sc">{</span>(totalLoss<span class="op">/</span>(<span class="bu">len</span>(trainSet.dataset)<span class="op">/</span><span class="dv">300</span>))<span class="sc">:.4f}</span><span class="ss">  Train Accuracy: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(trainSet.dataset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(trainSet.dataset)<span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb134-18"><a href="#cb134-18" aria-hidden="true" tabindex="-1"></a>    correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb134-19"><a href="#cb134-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb134-20"><a href="#cb134-20" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> x_test,y_test <span class="kw">in</span> testSet:</span>
<span id="cb134-21"><a href="#cb134-21" aria-hidden="true" tabindex="-1"></a>          x_test <span class="op">=</span> x_test.to(device)</span>
<span id="cb134-22"><a href="#cb134-22" aria-hidden="true" tabindex="-1"></a>          y_test <span class="op">=</span> y_test.to(device)</span>
<span id="cb134-23"><a href="#cb134-23" aria-hidden="true" tabindex="-1"></a>          pred <span class="op">=</span> net(x_test)</span>
<span id="cb134-24"><a href="#cb134-24" aria-hidden="true" tabindex="-1"></a>          predictedLabels <span class="op">=</span> pred.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb134-25"><a href="#cb134-25" aria-hidden="true" tabindex="-1"></a>          correct <span class="op">+=</span> predictedLabels.eq(y_test.view_as(predictedLabels)).<span class="bu">sum</span>().item()</span>
<span id="cb134-26"><a href="#cb134-26" aria-hidden="true" tabindex="-1"></a>          testAccuracy<span class="op">=</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(testSet.dataset)</span>
<span id="cb134-27"><a href="#cb134-27" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">  Validation Accuracy: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(testSet.dataset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>testAccuracy<span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="106" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="N1lRpV-O1Sqb" data-outputId="b1e6674c-469a-4a1f-d2dd-dd0a914471da">
<div class="sourceCode" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>epochs<span class="op">=</span><span class="dv">30</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>  train(model,device,train_loader,test_loader,optimizer,epoch,criterion)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Epoch: 1  Train Average Loss: 0.6898  Train Accuracy: 4787/8687 (55.11%)

Epoch: 1  Validation Accuracy: 2441/4279 (57.05%)

Epoch: 2  Train Average Loss: 0.6517  Train Accuracy: 5331/8687 (61.37%)

Epoch: 2  Validation Accuracy: 2425/4279 (56.67%)

Epoch: 3  Train Average Loss: 0.6178  Train Accuracy: 5697/8687 (65.58%)

Epoch: 3  Validation Accuracy: 2478/4279 (57.91%)

Epoch: 4  Train Average Loss: 0.5714  Train Accuracy: 6139/8687 (70.67%)

Epoch: 4  Validation Accuracy: 2405/4279 (56.20%)

Epoch: 5  Train Average Loss: 0.5213  Train Accuracy: 6494/8687 (74.76%)

Epoch: 5  Validation Accuracy: 2372/4279 (55.43%)

Epoch: 6  Train Average Loss: 0.4514  Train Accuracy: 6898/8687 (79.41%)

Epoch: 6  Validation Accuracy: 2420/4279 (56.56%)

Epoch: 7  Train Average Loss: 0.3743  Train Accuracy: 7304/8687 (84.08%)

Epoch: 7  Validation Accuracy: 2436/4279 (56.93%)

Epoch: 8  Train Average Loss: 0.2977  Train Accuracy: 7671/8687 (88.30%)

Epoch: 8  Validation Accuracy: 2404/4279 (56.18%)

Epoch: 9  Train Average Loss: 0.2407  Train Accuracy: 7911/8687 (91.07%)

Epoch: 9  Validation Accuracy: 2438/4279 (56.98%)

Epoch: 10  Train Average Loss: 0.1770  Train Accuracy: 8192/8687 (94.30%)

Epoch: 10  Validation Accuracy: 2452/4279 (57.30%)

Epoch: 11  Train Average Loss: 0.1209  Train Accuracy: 8376/8687 (96.42%)

Epoch: 11  Validation Accuracy: 2431/4279 (56.81%)

Epoch: 12  Train Average Loss: 0.0950  Train Accuracy: 8456/8687 (97.34%)

Epoch: 12  Validation Accuracy: 2421/4279 (56.58%)

Epoch: 13  Train Average Loss: 0.0679  Train Accuracy: 8557/8687 (98.50%)

Epoch: 13  Validation Accuracy: 2431/4279 (56.81%)

Epoch: 14  Train Average Loss: 0.0518  Train Accuracy: 8582/8687 (98.79%)

Epoch: 14  Validation Accuracy: 2414/4279 (56.42%)

Epoch: 15  Train Average Loss: 0.0540  Train Accuracy: 8561/8687 (98.55%)

Epoch: 15  Validation Accuracy: 2405/4279 (56.20%)

Epoch: 16  Train Average Loss: 0.0315  Train Accuracy: 8644/8687 (99.51%)

Epoch: 16  Validation Accuracy: 2410/4279 (56.32%)

Epoch: 17  Train Average Loss: 0.0180  Train Accuracy: 8670/8687 (99.80%)

Epoch: 17  Validation Accuracy: 2394/4279 (55.95%)

Epoch: 18  Train Average Loss: 0.0156  Train Accuracy: 8665/8687 (99.75%)

Epoch: 18  Validation Accuracy: 2407/4279 (56.25%)

Epoch: 19  Train Average Loss: 0.0110  Train Accuracy: 8682/8687 (99.94%)

Epoch: 19  Validation Accuracy: 2434/4279 (56.88%)

Epoch: 20  Train Average Loss: 0.0053  Train Accuracy: 8687/8687 (100.00%)

Epoch: 20  Validation Accuracy: 2420/4279 (56.56%)

Epoch: 21  Train Average Loss: 0.0031  Train Accuracy: 8687/8687 (100.00%)

Epoch: 21  Validation Accuracy: 2420/4279 (56.56%)

Epoch: 22  Train Average Loss: 0.0021  Train Accuracy: 8687/8687 (100.00%)

Epoch: 22  Validation Accuracy: 2429/4279 (56.77%)

Epoch: 23  Train Average Loss: 0.0016  Train Accuracy: 8687/8687 (100.00%)

Epoch: 23  Validation Accuracy: 2429/4279 (56.77%)

Epoch: 24  Train Average Loss: 0.0014  Train Accuracy: 8687/8687 (100.00%)

Epoch: 24  Validation Accuracy: 2426/4279 (56.70%)

Epoch: 25  Train Average Loss: 0.0012  Train Accuracy: 8687/8687 (100.00%)

Epoch: 25  Validation Accuracy: 2426/4279 (56.70%)

Epoch: 26  Train Average Loss: 0.0011  Train Accuracy: 8687/8687 (100.00%)

Epoch: 26  Validation Accuracy: 2425/4279 (56.67%)

Epoch: 27  Train Average Loss: 0.0010  Train Accuracy: 8687/8687 (100.00%)

Epoch: 27  Validation Accuracy: 2427/4279 (56.72%)

Epoch: 28  Train Average Loss: 0.0009  Train Accuracy: 8687/8687 (100.00%)

Epoch: 28  Validation Accuracy: 2420/4279 (56.56%)

Epoch: 29  Train Average Loss: 0.0008  Train Accuracy: 8687/8687 (100.00%)

Epoch: 29  Validation Accuracy: 2425/4279 (56.67%)

Epoch: 30  Train Average Loss: 0.0008  Train Accuracy: 8687/8687 (100.00%)

Epoch: 30  Validation Accuracy: 2422/4279 (56.60%)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="107" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="dlRj4AucI4oF" data-outputId="15675d72-f67b-41eb-a87d-cdb01be1d482">
<div class="sourceCode" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>model.parameters</span></code></pre></div>
<div class="output execute_result" data-execution_count="107">
<pre><code>&lt;bound method Module.parameters of classifier(
  (input_layer): Linear(in_features=3072, out_features=250, bias=True)
  (hidden_layer): Linear(in_features=250, out_features=100, bias=True)
  (output_layer): Linear(in_features=100, out_features=2, bias=True)
)&gt;</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="108" id="Frm6ZQN8C86I">
<div class="sourceCode" id="cb139"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>    correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>    total_loss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x_test,y_test <span class="kw">in</span> test_loader:</span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>        x_test <span class="op">=</span> x_test.to(device)</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>        y_test <span class="op">=</span> y_test.to(device)</span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> model(x_test)</span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">=</span> criterion(pred, y_test)</span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>        predictedLabels <span class="op">=</span> pred.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> predictedLabels.eq(y_test.view_as(predictedLabels)).<span class="bu">sum</span>().item()</span>
<span id="cb139-11"><a href="#cb139-11" aria-hidden="true" tabindex="-1"></a>        total_loss<span class="op">+=</span>test_loss.item()</span>
<span id="cb139-12"><a href="#cb139-12" aria-hidden="true" tabindex="-1"></a>    testAccuracy<span class="op">=</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(test_loader.dataset)</span>
<span id="cb139-13"><a href="#cb139-13" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> total_loss<span class="op">/</span>(<span class="bu">len</span>(test_loader.dataset)<span class="op">/</span><span class="dv">300</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="109" id="HIIPIpw4DkJd">
<div class="sourceCode" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">&quot;Model_name&quot;</span>,<span class="st">&quot;Test_Accuracy&quot;</span>,<span class="st">&quot;Test_Loss&quot;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="110" id="tZCtrDYvCT73">
<div class="sourceCode" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>results.loc[<span class="dv">0</span>,:<span class="dv">10</span>]  <span class="op">=</span> [<span class="ss">f&quot;Classification using multilayer perceptron&quot;</span>]<span class="op">+</span><span class="bu">list</span>([np.<span class="bu">round</span>(testAccuracy,<span class="dv">3</span>),np.<span class="bu">round</span>(total_loss,<span class="dv">3</span>)])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="111" data-colab="{&quot;height&quot;:81,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="hdRocJ4-EMTh" data-outputId="0b858efa-6ecf-42b3-9faf-9ea2838d0612">
<div class="sourceCode" id="cb142"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<div class="output execute_result" data-execution_count="111">

  <div id="df-99750086-8df0-4cd2-b888-cae05e823f91">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model_name</th>
      <th>Test_Accuracy</th>
      <th>Test_Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Classification using multilayer perceptron</td>
      <td>56.602</td>
      <td>2.357</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-99750086-8df0-4cd2-b888-cae05e823f91')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-99750086-8df0-4cd2-b888-cae05e823f91 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-99750086-8df0-4cd2-b888-cae05e823f91');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<section id="regression-using-mlp" class="cell markdown" id="BNWwHO9cKGBa">
<h2>Regression using MLP</h2>
</section>
<div class="cell code" data-execution_count="112" id="G2WaLN0ZKK39">
<div class="sourceCode" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RegressionModel(nn.Module):</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()        </span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_layer <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">32</span> <span class="op">*</span><span class="dv">3</span>, <span class="dv">250</span>)</span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layer <span class="op">=</span> nn.Linear(<span class="dv">250</span>, <span class="dv">100</span>)</span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer <span class="op">=</span> nn.Linear(<span class="dv">100</span>, <span class="dv">4</span>)</span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):                       </span>
<span id="cb143-9"><a href="#cb143-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.input_layer(x)</span>
<span id="cb143-10"><a href="#cb143-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)     </span>
<span id="cb143-11"><a href="#cb143-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.hidden_layer(x)</span>
<span id="cb143-12"><a href="#cb143-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(x)     </span>
<span id="cb143-13"><a href="#cb143-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output_layer(x)</span>
<span id="cb143-14"><a href="#cb143-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="113" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="WcZZ8yL6KKd7" data-outputId="52805dda-49ad-4d49-f980-b95ebb72ecb3">
<div class="sourceCode" id="cb144"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>df.columns</span></code></pre></div>
<div class="output execute_result" data-execution_count="113">
<pre><code>Index([&#39;ImageID&#39;, &#39;Source&#39;, &#39;LabelName&#39;, &#39;Confidence&#39;, &#39;XMin&#39;, &#39;XMax&#39;, &#39;YMin&#39;,
       &#39;YMax&#39;, &#39;IsOccluded&#39;, &#39;IsTruncated&#39;, &#39;IsGroupOf&#39;, &#39;IsDepiction&#39;,
       &#39;IsInside&#39;, &#39;XClick1X&#39;, &#39;XClick2X&#39;, &#39;XClick3X&#39;, &#39;XClick4X&#39;, &#39;XClick1Y&#39;,
       &#39;XClick2Y&#39;, &#39;XClick3Y&#39;, &#39;XClick4Y&#39;, &#39;type&#39;],
      dtype=&#39;object&#39;)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="114" id="wQuAWrZpOkn3">
<div class="sourceCode" id="cb146"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>lables_box<span class="op">=</span> df[[<span class="st">&#39;XMin&#39;</span>, <span class="st">&#39;YMin&#39;</span>, <span class="st">&#39;XMax&#39;</span>, <span class="st">&#39;YMax&#39;</span>]].to_numpy(dtype <span class="op">=</span><span class="st">&#39;float32&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="115" id="ujRasEF152PG">
<div class="sourceCode" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Custom dataset for binding box labels</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> data(torch.utils.data.Dataset):</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y, scale_data<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> torch.is_tensor(X) <span class="kw">and</span> <span class="kw">not</span> torch.is_tensor(y):</span>
<span id="cb147-5"><a href="#cb147-5" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.X <span class="op">=</span> torch.from_numpy(X)</span>
<span id="cb147-6"><a href="#cb147-6" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.y <span class="op">=</span> torch.from_numpy(y)</span>
<span id="cb147-7"><a href="#cb147-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-8"><a href="#cb147-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb147-9"><a href="#cb147-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb147-10"><a href="#cb147-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-11"><a href="#cb147-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i):</span>
<span id="cb147-12"><a href="#cb147-12" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="va">self</span>.X[i], <span class="va">self</span>.y[i]</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="116" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="KyxaGsODE1l0" data-outputId="99a4c7b6-c363-4ff3-cfc9-1b612786c5b4">
<div class="sourceCode" id="cb148"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>lables_box.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="116">
<pre><code>(12966, 4)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="117" id="pmqouue46ggZ">
<div class="sourceCode" id="cb150"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using first 10000 images for train and rest for test out of 12966 images</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>train_dataSet<span class="op">=</span> data(np.array(images_tensor[:<span class="dv">10000</span>]), np.array(lables_box[:<span class="dv">10000</span>]))</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>test_dataSet<span class="op">=</span> data(np.array(images_tensor[<span class="dv">10000</span>:]), np.array(lables_box[<span class="dv">10000</span>:]))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="118" id="__d3hEft7Xr7">
<div class="sourceCode" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>train_loader_new <span class="op">=</span> torch.utils.data.DataLoader(train_dataSet, batch_size<span class="op">=</span><span class="dv">300</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>test_loader_new <span class="op">=</span> torch.utils.data.DataLoader(test_dataSet, batch_size<span class="op">=</span><span class="dv">300</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="119" id="pm-hpUmw7iRM">
<div class="sourceCode" id="cb152"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>model2<span class="op">=</span> RegressionModel().to(device)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="120" id="20mIGzju7oZI">
<div class="sourceCode" id="cb153"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.L1Loss()</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model2.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="121" id="52Z4w0ou7zty">
<div class="sourceCode" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_reg(net,device,trainSet,optimizer,epoch,criterion):</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    totalLoss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x,y <span class="kw">in</span> trainSet:</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> x.to(device)</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>      y <span class="op">=</span> y.to(device)</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>      loss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x)):</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>        pred<span class="op">=</span>net(x[i].flatten())</span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> criterion(pred, y[i])<span class="op">/</span> <span class="bu">len</span>(x)</span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb154-13"><a href="#cb154-13" aria-hidden="true" tabindex="-1"></a>      totalLoss<span class="op">+=</span>loss.item()</span>
<span id="cb154-14"><a href="#cb154-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">  Train Average Loss: </span><span class="sc">{</span>(totalLoss<span class="op">/</span>(<span class="bu">len</span>(trainSet.dataset)<span class="op">/</span><span class="dv">300</span>))<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb154-15"><a href="#cb154-15" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="122" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Mg69kRwF7wvy" data-outputId="605c4b05-a97e-4777-c28c-41f9150b3239">
<div class="sourceCode" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>epochs<span class="op">=</span><span class="dv">20</span></span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>  train_reg(model2,device,train_loader_new,optimizer,epoch,criterion)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Epoch: 1  Train Average Loss: 0.2425

Epoch: 2  Train Average Loss: 0.1184

Epoch: 3  Train Average Loss: 0.0962

Epoch: 4  Train Average Loss: 0.0856

Epoch: 5  Train Average Loss: 0.0784

Epoch: 6  Train Average Loss: 0.0731

Epoch: 7  Train Average Loss: 0.0692

Epoch: 8  Train Average Loss: 0.0660

Epoch: 9  Train Average Loss: 0.0631

Epoch: 10  Train Average Loss: 0.0606

Epoch: 11  Train Average Loss: 0.0588

Epoch: 12  Train Average Loss: 0.0564

Epoch: 13  Train Average Loss: 0.0551

Epoch: 14  Train Average Loss: 0.0530

Epoch: 15  Train Average Loss: 0.0515

Epoch: 16  Train Average Loss: 0.0507

Epoch: 17  Train Average Loss: 0.0493

Epoch: 18  Train Average Loss: 0.0478

Epoch: 19  Train Average Loss: 0.0465

Epoch: 20  Train Average Loss: 0.0457
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="123" id="4r0SgCllAYr7">
<div class="sourceCode" id="cb157"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>  totalLoss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> x,y <span class="kw">in</span> test_loader_new:</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> x.to(device)</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>      y <span class="op">=</span> y.to(device)</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>      loss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x)):</span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>        pred<span class="op">=</span>model2(x[i].flatten())</span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> criterion(pred, y[i])<span class="op">/</span> <span class="bu">len</span>(x)</span>
<span id="cb157-10"><a href="#cb157-10" aria-hidden="true" tabindex="-1"></a>      totalLoss<span class="op">+=</span>loss.item()</span>
<span id="cb157-11"><a href="#cb157-11" aria-hidden="true" tabindex="-1"></a>  totalLoss <span class="op">=</span> totalLoss<span class="op">/</span>(<span class="bu">len</span>(test_loader_new.dataset)<span class="op">/</span><span class="dv">300</span>)</span>
<span id="cb157-12"><a href="#cb157-12" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="124" id="a7ZwmiMvGwhu">
<div class="sourceCode" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>results.loc[<span class="dv">1</span>,:<span class="dv">10</span>]  <span class="op">=</span> [<span class="ss">f&quot;Regression using multilayer perceptron&quot;</span>]<span class="op">+</span><span class="bu">list</span>([<span class="st">&quot;-&quot;</span>,np.<span class="bu">round</span>(totalLoss,<span class="dv">3</span>)])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="125" data-colab="{&quot;height&quot;:112,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="E7lEXtVEIlfE" data-outputId="0c400751-7f4d-427b-bd59-176465475f28">
<div class="sourceCode" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<div class="output execute_result" data-execution_count="125">

  <div id="df-391beb39-b9b5-4baf-9fb2-853cc2e8e19a">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model_name</th>
      <th>Test_Accuracy</th>
      <th>Test_Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Classification using multilayer perceptron</td>
      <td>56.602</td>
      <td>2.357</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Regression using multilayer perceptron</td>
      <td>-</td>
      <td>0.081</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-391beb39-b9b5-4baf-9fb2-853cc2e8e19a')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-391beb39-b9b5-4baf-9fb2-853cc2e8e19a button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-391beb39-b9b5-4baf-9fb2-853cc2e8e19a');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<section id="multi-head" class="cell markdown" id="RIk4E9J2JJC-">
<h2>Multi Head</h2>
</section>
<div class="cell code" data-execution_count="126" id="mQsxvAC1OMma">
<div class="sourceCode" id="cb160"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Custom dataset for multihead</span></span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> data_mh(torch.utils.data.Dataset):</span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y1,y2, scale_data<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> torch.is_tensor(X) <span class="kw">and</span> <span class="kw">not</span> torch.is_tensor(y):</span>
<span id="cb160-5"><a href="#cb160-5" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.X <span class="op">=</span> torch.from_numpy(X)</span>
<span id="cb160-6"><a href="#cb160-6" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.y1 <span class="op">=</span> torch.from_numpy(y)</span>
<span id="cb160-7"><a href="#cb160-7" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.y2 <span class="op">=</span> torch.from_numpy(y)</span>
<span id="cb160-8"><a href="#cb160-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-9"><a href="#cb160-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-10"><a href="#cb160-10" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb160-11"><a href="#cb160-11" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb160-12"><a href="#cb160-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-13"><a href="#cb160-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i):</span>
<span id="cb160-14"><a href="#cb160-14" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="va">self</span>.X[i], {<span class="st">&#39;label_c&#39;</span>:<span class="va">self</span>.y1[i],<span class="st">&#39;label_r&#39;</span>: <span class="va">self</span>.y2[i]}</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="127" id="SVVNUUBDPEC6">
<div class="sourceCode" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using first 10000 images for train and rest for test out of 12966 images</span></span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>train_dataSet<span class="op">=</span> data_mh(np.array(images_tensor[:<span class="dv">10000</span>]), np.array(labels[:<span class="dv">10000</span>]), np.array(lables_box[:<span class="dv">10000</span>]))</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>test_dataSet<span class="op">=</span> data_mh(np.array(images_tensor[<span class="dv">10000</span>:]),  np.array(labels[<span class="dv">10000</span>:]), np.array(lables_box[<span class="dv">10000</span>:]))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="128" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="GNFdgfURVsJL" data-outputId="99237b21-dc65-492d-c6c8-baa7cfc22acb">
<div class="sourceCode" id="cb162"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(images_tensor)</span></code></pre></div>
<div class="output execute_result" data-execution_count="128">
<pre><code>12966</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="129" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="tSAXKJwIVwQ7" data-outputId="9dcbd3fa-124f-48cf-f03c-23cafd77d221">
<div class="sourceCode" id="cb164"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(labels)</span></code></pre></div>
<div class="output execute_result" data-execution_count="129">
<pre><code>12966</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="130" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="2b_jxkfBV0LM" data-outputId="dfe4413c-7ab8-449e-9f7d-0199360ea804">
<div class="sourceCode" id="cb166"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(lables_box)</span></code></pre></div>
<div class="output execute_result" data-execution_count="130">
<pre><code>12966</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="131" id="g0IIAw5GPl6J">
<div class="sourceCode" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>train_loader_mh <span class="op">=</span> torch.utils.data.DataLoader([ [images_tensor[i], labels[i],lables_box[i]] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>)], batch_size<span class="op">=</span><span class="dv">300</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>test_loader_mh <span class="op">=</span> torch.utils.data.DataLoader([ [images_tensor[i], labels[i],lables_box[i]] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>,<span class="bu">len</span>(labels))], batch_size<span class="op">=</span><span class="dv">300</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="132" id="w5IceV_3blwB">
<div class="sourceCode" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Multihead(nn.Module):</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()           </span>
<span id="cb169-4"><a href="#cb169-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_layer <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">32</span> <span class="op">*</span><span class="dv">3</span>, <span class="dv">250</span>)</span>
<span id="cb169-5"><a href="#cb169-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_layer <span class="op">=</span> nn.Linear(<span class="dv">250</span>, <span class="dv">100</span>)</span>
<span id="cb169-6"><a href="#cb169-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer_classifcation <span class="op">=</span> nn.Linear(<span class="dv">100</span>, <span class="dv">2</span>)</span>
<span id="cb169-7"><a href="#cb169-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_layer_regression <span class="op">=</span> nn.Linear(<span class="dv">100</span>, <span class="dv">4</span>)</span>
<span id="cb169-8"><a href="#cb169-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb169-9"><a href="#cb169-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):        </span>
<span id="cb169-10"><a href="#cb169-10" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb169-11"><a href="#cb169-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(batch_size, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb169-12"><a href="#cb169-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.input_layer(x))</span>
<span id="cb169-13"><a href="#cb169-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.hidden_layer(x))</span>
<span id="cb169-14"><a href="#cb169-14" aria-hidden="true" tabindex="-1"></a>        out_classifcation<span class="op">=</span><span class="va">self</span>.output_layer_classifcation(x)</span>
<span id="cb169-15"><a href="#cb169-15" aria-hidden="true" tabindex="-1"></a>        out_regression<span class="op">=</span><span class="va">self</span>.output_layer_regression(x)</span>
<span id="cb169-16"><a href="#cb169-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-17"><a href="#cb169-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out_classifcation,out_regression, x</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="133" id="PLWuPR2AMUmu">
<div class="sourceCode" id="cb170"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>criterion_c <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>criterion_r <span class="op">=</span> nn.MSELoss()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="134" id="gPw58EuKQrJj">
<div class="sourceCode" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>model_mh <span class="op">=</span> Multihead().to(device)</span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model_mh.parameters())</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="135" id="Umri7pUqQLT3">
<div class="sourceCode" id="cb172"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_mh(net, device, trainSet,testSet, optimizer,epoch):</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>    totalLoss<span class="op">=</span><span class="dv">0</span></span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>    correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb172-5"><a href="#cb172-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x,y_c,y_r <span class="kw">in</span> trainSet:</span>
<span id="cb172-6"><a href="#cb172-6" aria-hidden="true" tabindex="-1"></a>      x <span class="op">=</span> x.to(device)</span>
<span id="cb172-7"><a href="#cb172-7" aria-hidden="true" tabindex="-1"></a>      y_c <span class="op">=</span> y_c.to(device)</span>
<span id="cb172-8"><a href="#cb172-8" aria-hidden="true" tabindex="-1"></a>      y_r <span class="op">=</span> y_r.to(device)</span>
<span id="cb172-9"><a href="#cb172-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-10"><a href="#cb172-10" aria-hidden="true" tabindex="-1"></a>      pred_c,pred_r,_ <span class="op">=</span> net(x)</span>
<span id="cb172-11"><a href="#cb172-11" aria-hidden="true" tabindex="-1"></a>      loss_c <span class="op">=</span> criterion_c(pred_c, y_c)</span>
<span id="cb172-12"><a href="#cb172-12" aria-hidden="true" tabindex="-1"></a>      loss_r <span class="op">=</span> criterion_r(pred_r, y_r)</span>
<span id="cb172-13"><a href="#cb172-13" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_c<span class="op">+</span>loss_r</span>
<span id="cb172-14"><a href="#cb172-14" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb172-15"><a href="#cb172-15" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb172-16"><a href="#cb172-16" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb172-17"><a href="#cb172-17" aria-hidden="true" tabindex="-1"></a>      totalLoss<span class="op">+=</span>loss.item()</span>
<span id="cb172-18"><a href="#cb172-18" aria-hidden="true" tabindex="-1"></a>      predictedLabels <span class="op">=</span> pred_c.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb172-19"><a href="#cb172-19" aria-hidden="true" tabindex="-1"></a>      correct <span class="op">+=</span> predictedLabels.eq(y_c.view_as(predictedLabels)).<span class="bu">sum</span>().item()</span>
<span id="cb172-20"><a href="#cb172-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-21"><a href="#cb172-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">  Train Loss: </span><span class="sc">{</span>(totalLoss<span class="op">/</span>(<span class="bu">len</span>(trainSet.dataset)<span class="op">/</span><span class="dv">300</span>))<span class="sc">:.4f}</span><span class="ss">  Train Accuracy for classification: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(trainSet.dataset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(trainSet.dataset)<span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span>
<span id="cb172-22"><a href="#cb172-22" aria-hidden="true" tabindex="-1"></a>    correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb172-23"><a href="#cb172-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb172-24"><a href="#cb172-24" aria-hidden="true" tabindex="-1"></a>      total_test_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb172-25"><a href="#cb172-25" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> x_test,y_test_c,y_test_r <span class="kw">in</span> testSet:</span>
<span id="cb172-26"><a href="#cb172-26" aria-hidden="true" tabindex="-1"></a>          x_test <span class="op">=</span> x_test.to(device)</span>
<span id="cb172-27"><a href="#cb172-27" aria-hidden="true" tabindex="-1"></a>          y_test_c <span class="op">=</span> y_test_c.to(device)</span>
<span id="cb172-28"><a href="#cb172-28" aria-hidden="true" tabindex="-1"></a>          y_test_r <span class="op">=</span> y_test_r.to(device)</span>
<span id="cb172-29"><a href="#cb172-29" aria-hidden="true" tabindex="-1"></a>          pred_c,pred_r,_ <span class="op">=</span>  net(x_test)</span>
<span id="cb172-30"><a href="#cb172-30" aria-hidden="true" tabindex="-1"></a>          loss_c <span class="op">=</span> criterion_c(pred_c, y_test_c)</span>
<span id="cb172-31"><a href="#cb172-31" aria-hidden="true" tabindex="-1"></a>          loss_r <span class="op">=</span> criterion_r(pred_r, y_test_r)</span>
<span id="cb172-32"><a href="#cb172-32" aria-hidden="true" tabindex="-1"></a>          test_loss<span class="op">=</span>loss_c<span class="op">+</span>loss_r</span>
<span id="cb172-33"><a href="#cb172-33" aria-hidden="true" tabindex="-1"></a>          total_test_loss<span class="op">+=</span>test_loss.item()</span>
<span id="cb172-34"><a href="#cb172-34" aria-hidden="true" tabindex="-1"></a>          predictedLabels <span class="op">=</span> pred_c.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb172-35"><a href="#cb172-35" aria-hidden="true" tabindex="-1"></a>          correct <span class="op">+=</span> predictedLabels.eq(y_test_c.view_as(predictedLabels)).<span class="bu">sum</span>().item()</span>
<span id="cb172-36"><a href="#cb172-36" aria-hidden="true" tabindex="-1"></a>          testAccuracy<span class="op">=</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(testSet.dataset)</span>
<span id="cb172-37"><a href="#cb172-37" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">  Validation Loss: </span><span class="sc">{</span>(total_test_loss<span class="op">/</span>(<span class="bu">len</span>(testSet.dataset)<span class="op">/</span><span class="dv">300</span>))<span class="sc">:.4f}</span><span class="ss"> Validation Accuracy for classification: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(testSet.dataset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>testAccuracy<span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="136" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="T8SujvAdSZPp" data-outputId="cc730976-bb51-48cc-88d8-bf5f7adb061a">
<div class="sourceCode" id="cb173"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>epochs<span class="op">=</span><span class="dv">20</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>  train_mh(model_mh,device,train_loader_mh,test_loader_mh,optimizer,epoch)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>
Epoch: 1  Train Loss: 0.6938  Train Accuracy for classification: 6652/10000 (66.52%)

Epoch: 1  Validation Loss: 1.1822 Validation Accuracy for classification: 221/2966 (7.45%)

Epoch: 2  Train Loss: 0.6206  Train Accuracy for classification: 6952/10000 (69.52%)

Epoch: 2  Validation Loss: 1.2562 Validation Accuracy for classification: 196/2966 (6.61%)

Epoch: 3  Train Loss: 0.5943  Train Accuracy for classification: 7092/10000 (70.92%)

Epoch: 3  Validation Loss: 1.0795 Validation Accuracy for classification: 798/2966 (26.90%)

Epoch: 4  Train Loss: 0.5566  Train Accuracy for classification: 7375/10000 (73.75%)

Epoch: 4  Validation Loss: 1.2469 Validation Accuracy for classification: 583/2966 (19.66%)

Epoch: 5  Train Loss: 0.5071  Train Accuracy for classification: 7708/10000 (77.08%)

Epoch: 5  Validation Loss: 1.1461 Validation Accuracy for classification: 930/2966 (31.36%)

Epoch: 6  Train Loss: 0.4713  Train Accuracy for classification: 7897/10000 (78.97%)

Epoch: 6  Validation Loss: 1.1263 Validation Accuracy for classification: 1152/2966 (38.84%)

Epoch: 7  Train Loss: 0.4232  Train Accuracy for classification: 8190/10000 (81.90%)

Epoch: 7  Validation Loss: 1.0452 Validation Accuracy for classification: 1350/2966 (45.52%)

Epoch: 8  Train Loss: 0.3623  Train Accuracy for classification: 8525/10000 (85.25%)

Epoch: 8  Validation Loss: 1.9893 Validation Accuracy for classification: 655/2966 (22.08%)

Epoch: 9  Train Loss: 0.2929  Train Accuracy for classification: 8892/10000 (88.92%)

Epoch: 9  Validation Loss: 1.5563 Validation Accuracy for classification: 1180/2966 (39.78%)

Epoch: 10  Train Loss: 0.2439  Train Accuracy for classification: 9122/10000 (91.22%)

Epoch: 10  Validation Loss: 1.7762 Validation Accuracy for classification: 1156/2966 (38.98%)

Epoch: 11  Train Loss: 0.1981  Train Accuracy for classification: 9326/10000 (93.26%)

Epoch: 11  Validation Loss: 2.3614 Validation Accuracy for classification: 878/2966 (29.60%)

Epoch: 12  Train Loss: 0.1503  Train Accuracy for classification: 9532/10000 (95.32%)

Epoch: 12  Validation Loss: 2.1094 Validation Accuracy for classification: 1131/2966 (38.13%)

Epoch: 13  Train Loss: 0.1107  Train Accuracy for classification: 9705/10000 (97.05%)

Epoch: 13  Validation Loss: 2.1702 Validation Accuracy for classification: 1236/2966 (41.67%)

Epoch: 14  Train Loss: 0.0834  Train Accuracy for classification: 9800/10000 (98.00%)

Epoch: 14  Validation Loss: 3.1459 Validation Accuracy for classification: 909/2966 (30.65%)

Epoch: 15  Train Loss: 0.0720  Train Accuracy for classification: 9839/10000 (98.39%)

Epoch: 15  Validation Loss: 3.0864 Validation Accuracy for classification: 1064/2966 (35.87%)

Epoch: 16  Train Loss: 0.0620  Train Accuracy for classification: 9855/10000 (98.55%)

Epoch: 16  Validation Loss: 3.1610 Validation Accuracy for classification: 1023/2966 (34.49%)

Epoch: 17  Train Loss: 0.0563  Train Accuracy for classification: 9884/10000 (98.84%)

Epoch: 17  Validation Loss: 3.0998 Validation Accuracy for classification: 1078/2966 (36.35%)

Epoch: 18  Train Loss: 0.0360  Train Accuracy for classification: 9959/10000 (99.59%)

Epoch: 18  Validation Loss: 3.1387 Validation Accuracy for classification: 1136/2966 (38.30%)

Epoch: 19  Train Loss: 0.0244  Train Accuracy for classification: 9988/10000 (99.88%)

Epoch: 19  Validation Loss: 3.5131 Validation Accuracy for classification: 1067/2966 (35.97%)

Epoch: 20  Train Loss: 0.0174  Train Accuracy for classification: 10000/10000 (100.00%)

Epoch: 20  Validation Loss: 3.6829 Validation Accuracy for classification: 1076/2966 (36.28%)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="137" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="or4AKf2eWd8p" data-outputId="c9f70088-6ba4-40e3-c026-00be5651ad2e">
<div class="sourceCode" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>      total_test_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a>      correct<span class="op">=</span><span class="dv">0</span></span>
<span id="cb175-4"><a href="#cb175-4" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> x_test,y_test_c,y_test_r <span class="kw">in</span> test_loader_mh:</span>
<span id="cb175-5"><a href="#cb175-5" aria-hidden="true" tabindex="-1"></a>          x_test <span class="op">=</span> x_test.to(device)</span>
<span id="cb175-6"><a href="#cb175-6" aria-hidden="true" tabindex="-1"></a>          y_test_c <span class="op">=</span> y_test_c.to(device)</span>
<span id="cb175-7"><a href="#cb175-7" aria-hidden="true" tabindex="-1"></a>          y_test_r <span class="op">=</span> y_test_r.to(device)</span>
<span id="cb175-8"><a href="#cb175-8" aria-hidden="true" tabindex="-1"></a>          pred_c,pred_r,_ <span class="op">=</span>  model_mh(x_test)</span>
<span id="cb175-9"><a href="#cb175-9" aria-hidden="true" tabindex="-1"></a>          loss_c <span class="op">=</span> criterion_c(pred_c, y_test_c)</span>
<span id="cb175-10"><a href="#cb175-10" aria-hidden="true" tabindex="-1"></a>          loss_r <span class="op">=</span> criterion_r(pred_r, y_test_r)</span>
<span id="cb175-11"><a href="#cb175-11" aria-hidden="true" tabindex="-1"></a>          test_loss<span class="op">=</span>loss_c<span class="op">+</span>loss_r</span>
<span id="cb175-12"><a href="#cb175-12" aria-hidden="true" tabindex="-1"></a>          total_test_loss<span class="op">+=</span>test_loss.item()</span>
<span id="cb175-13"><a href="#cb175-13" aria-hidden="true" tabindex="-1"></a>          predictedLabels <span class="op">=</span> pred_c.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb175-14"><a href="#cb175-14" aria-hidden="true" tabindex="-1"></a>          correct <span class="op">+=</span> predictedLabels.eq(y_test_c.view_as(predictedLabels)).<span class="bu">sum</span>().item()</span>
<span id="cb175-15"><a href="#cb175-15" aria-hidden="true" tabindex="-1"></a>      testAccuracy<span class="op">=</span><span class="fl">100.</span> <span class="op">*</span> correct <span class="op">/</span> <span class="bu">len</span>(test_loader_mh.dataset)</span>
<span id="cb175-16"><a href="#cb175-16" aria-hidden="true" tabindex="-1"></a>      test_loss<span class="op">=</span> total_test_loss<span class="op">/</span>(<span class="bu">len</span>(test_loader_mh.dataset)<span class="op">/</span><span class="dv">300</span>)</span>
<span id="cb175-17"><a href="#cb175-17" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f&quot;Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss"> Test Accuracy for classification: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(test_loader_mh.dataset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>testAccuracy<span class="sc">:.2f}</span><span class="ss">%)&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Test Loss: 3.6849 Test Accuracy for classification: 1076/2966 (36.28%)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="138" id="59END4Y8W8Mb">
<div class="sourceCode" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>results.loc[<span class="dv">2</span>,:<span class="dv">10</span>]  <span class="op">=</span> [<span class="ss">f&quot;Multi Head &quot;</span>]<span class="op">+</span><span class="bu">list</span>([np.<span class="bu">round</span>(testAccuracy,<span class="dv">2</span>),np.<span class="bu">round</span>(test_loss,<span class="dv">3</span>)])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="139" data-colab="{&quot;height&quot;:143,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="8Gn0nUCuXoNp" data-outputId="b3ecba63-5d9f-4e0a-c08e-ac4f23a2a2f8">
<div class="sourceCode" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<div class="output execute_result" data-execution_count="139">

  <div id="df-a536e6a9-7738-4c8e-9b4c-a65bc6242aea">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model_name</th>
      <th>Test_Accuracy</th>
      <th>Test_Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Classification using multilayer perceptron</td>
      <td>56.602</td>
      <td>2.357</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Regression using multilayer perceptron</td>
      <td>-</td>
      <td>0.081</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Multi Head</td>
      <td>36.28</td>
      <td>3.685</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a536e6a9-7738-4c8e-9b4c-a65bc6242aea')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a536e6a9-7738-4c8e-9b4c-a65bc6242aea button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a536e6a9-7738-4c8e-9b4c-a65bc6242aea');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

</div>
</div>
<div class="cell markdown" id="SOcG-BS-DRkb">
<p><strong>Results</strong></p>
</div>
<div class="cell markdown" id="_ZX9fVI7DU8z">
<p>In above phase1 we got highest accuracy for stochastic gradient which is 57 percent. In phase2 using Homegrown logistic and linear regression we got a class accuracy of 53 percent which is not bad and using classification with Multilayer perceptron we got 56 percent which created wonders. Multi Head API did not worked well for this classification. We have also used relu and leakyrelu but even this did not worked well. In Home grown Linear regression we obtained a loss of 27. In Home grown logistic regression we obtained a loss of 31.43 using CXE+MSE</p>
</div>
<div class="cell markdown" id="EjaDhx0ulX-R">
<p><strong>Challenges</strong></p>
</div>
<div class="cell markdown" id="COf3Iwq-lajS">
<p>In Home grown we faced issues of resusing the code so many times but using same objects in the class are so confusing and so many errors arised.</p>
</div>
<div class="cell markdown" id="YqlRjmzYu8HY">
<p><strong>Conclusion</strong></p>
</div>
<div class="cell markdown" id="CtQS4Zvju-JF">
<p>We focused on the SKLearn Baseline models for Logistic Regression, SGDClassifier to classify the images into cats and dogs, and Linear Regression to mark the bounding boxes around the cats and dogs inside the image in phase 1. We have also implemented the Homegrown Logistic Regression and Homegrown Linear Regression to compare the results. The homegrown implementation of logistic regression to do both classification and regression. In addition, we devised MLPs for classification and regression without dropout, using PyTorch's Sequential and OOP APIs. The number of hidden layers, drop out, learning rate, number of epochs, and other variables were all tested, and the results were tabulated.</p>
</div>
</body>
</html>
